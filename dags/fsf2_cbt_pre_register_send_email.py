import logging
import pandas as pd
import os
import json
from airflow.models import Variable
from google.oauth2 import service_account

import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

import gspread
from datetime import datetime, timedelta, timezone
from sqlalchemy import create_engine

from airflow import DAG, Dataset
from airflow.operators.python import PythonOperator

fsf2_cbt_pre_register_etl = Dataset('fsf2_cbt_pre_register_etl')

def get_var(key: str, default: str = None) -> str:
    """í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Airflow Variable ì¡°íšŒ"""
    return os.environ.get(key) or Variable.get(key, default_var=default)

# ==========================================
# 1. ì„¤ì •
# ==========================================
# DB ì ‘ì† ì •ë³´
DATABASE_URL = "postgresql://airflow:airflow@postgres:5432/airflow"

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
CREDENTIALS_JSON = get_var('GOOGLE_CREDENTIAL_JSON')

GOOGLE_SHEET_ID = "1wB6_RhpTPanaONtqQD93Kd1PCWvpIv7MCfq7JCypc5k" # ì‹œíŠ¸ URL ì¤‘ê°„ì˜ ê¸´ ë¬¸ìì—´
TARGET_SHEET_NAME = "Sheet1" # ë°ì´í„°ë¥¼ ë„£ì„ ì‹œíŠ¸ íƒ­ ì´ë¦„

# ì´ë©”ì¼ ìˆ˜ì‹ ì
EMAIL_RECIPIENT = ["seongin@joycity.com"]

# SMTP ì„¤ì •
SMTP_SERVER = "61.43.45.137"
SMTP_PORT = 25
SENDER_EMAIL = 'ds_bi@joycity.com'
SENDER_PASSWORD = get_var('SMTP_PASSWORD')


logger = logging.getLogger("airflow.task")

# ==========================================
# 2. í•¨ìˆ˜ ì •ì˜
# ==========================================

def get_country_stats():
    """
    [DB ì¡°íšŒ] ì „ì²´ ê¸°ê°„ì— ëŒ€í•´ êµ­ê°€ë³„ ê°€ì…ì ìˆ˜ ì§‘ê³„
    """
    engine = create_engine(DATABASE_URL)
    
    # ìš”ì²­í•˜ì‹  ì¿¼ë¦¬: ì „ì²´ ê¸°ê°„, êµ­ê°€ë³„ Group By, Count Distinct Email
    sql = """
    SELECT 
        country,
        COUNT(DISTINCT email) as user_count,
        MAX(synced_at) as last_updated
    FROM fsf2_beta_testers
    GROUP BY country
    ORDER BY user_count DESC;
    """
    
    try:
        df = pd.read_sql(sql, engine)
        logger.info(f"Fetched {len(df)} rows from DB.")
        return df
    except Exception as e:
        logger.error(f"DB Query Failed: {e}")
        raise

def update_google_sheet(df):
    """
    [êµ¬ê¸€ ì‹œíŠ¸] ê¸°ì¡´ ë‚´ìš© ì§€ìš°ê³  ë°ì´í„°í”„ë ˆì„ ë‚´ìš© ë¶™ì—¬ë„£ê¸°
    """
    if df is None or df.empty:
        logger.info("No data to update to Google Sheet.")
        return

    logger.info("Connecting to Google Sheets...")
    
    # GCP ì¸ì¦
    cred_dict = json.loads(CREDENTIALS_JSON)

    # 2. private_key ì¤„ë°”ê¿ˆ ë¬¸ì ì²˜ë¦¬ (í•„ìˆ˜ ì²´í¬)
    if 'private_key' in cred_dict:
            # ë§Œì•½ í‚¤ ê°’ì— \\n ë¬¸ìê°€ ê·¸ëŒ€ë¡œ ë“¤ì–´ìˆë‹¤ë©´ ì‹¤ì œ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€ê²½
        if '\\n' in cred_dict['private_key']:
            cred_dict['private_key'] = cred_dict['private_key'].replace('\\n', '\n')

    # 3. ëª…ì‹œì ìœ¼ë¡œ Service Account Credentials ìƒì„± (google.auth.default ì•„ë‹˜!)
    credentials = service_account.Credentials.from_service_account_info(
        cred_dict,
        scopes=["https://www.googleapis.com/auth/cloud-platform", 'https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    )
    
    try:
        client = gspread.authorize(credentials)
        
        # ì‹œíŠ¸ ì—´ê¸°
        sh = client.open_by_key(GOOGLE_SHEET_ID)
        worksheet = sh.worksheet(TARGET_SHEET_NAME)
        
        # ê¸°ì¡´ ë°ì´í„° í´ë¦¬ì–´ (í—¤ë” í¬í•¨ ì „ì²´ ì‚­ì œ)
        worksheet.clear()
        
        # ë°ì´í„° ì¤€ë¹„ (í—¤ë” + ë‚´ìš©)
        # gspreadëŠ” ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ë°›ìŠµë‹ˆë‹¤.
        header = df.columns.values.tolist()
        data = df.values.tolist()
        final_data = [header] + data
        
        # ë°ì´í„° ì—…ë°ì´íŠ¸ (A1 ì…€ë¶€í„° ì‹œì‘)
        worksheet.update(values=final_data, range_name='A1')
        logger.info(f"Successfully updated Google Sheet. ({len(final_data)} rows)")
        
    except Exception as e:
        logger.error(f"Google Sheet Update Failed: {e}")
        raise

def send_stats_email(df):
    """
    [ì´ë©”ì¼] ì§‘ê³„ ê²°ê³¼ë¥¼ HTML í…Œì´ë¸”ë¡œ ë³€í™˜í•˜ì—¬ ë°œì†¡
    """
    if df is None or df.empty:
        logger.info("No data to send via email.")
        return

    # 1. HTML ë³¸ë¬¸ ìƒì„±
    # Pandasì˜ to_html ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ í‘œë¥¼ ë§Œë“­ë‹ˆë‹¤.
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    html_table = df.to_html(index=False, border=1, justify='center')
    
    email_content = f"""
    <h3>[FSF2] CBT ì‚¬ì „ì˜ˆì•½ êµ­ê°€ë³„ í˜„í™© ë¦¬í¬íŠ¸</h3>
    <p><strong>ë°œì†¡ ì‹œê°„:</strong> {current_time}</p>
    <p><strong>ì´ ê°€ì…ì ìˆ˜:</strong> {df['user_count'].sum():,} ëª…</p>
    <br>
    {html_table}
    <br>
    <p>â€» ì´ ë©”ì¼ì€ Airflowì—ì„œ ìë™ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
    """

    # ë©”ì¼ ì œëª©
    subject = f"[FSF2] CBT ê°€ì…ì í˜„í™© ({datetime.now().strftime('%Y-%m-%d')})"
    
    # ì´ë©”ì¼ ë°œì†¡
    logger.info("ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì¤‘...")

    server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT, timeout=10)
    server.set_debuglevel(0)  # ë””ë²„ê·¸ ëª¨ë“œ ë„ê¸°
    
    # # ì¸ì¦ì´ í•„ìš”í•˜ë©´
    # if SENDER_PASSWORD:
    #     server.login(SENDER_EMAIL, SENDER_PASSWORD)
    current_time = datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S")

    msg = MIMEMultipart()
    msg['From'] = SENDER_EMAIL
    msg['To'] = ', '.join(EMAIL_RECIPIENT)
    msg['Subject'] = f"{subject}: {current_time}"
    msg.attach(MIMEText(email_content, 'html'))
    
    server.sendmail(SENDER_EMAIL, EMAIL_RECIPIENT, msg.as_string())
    server.quit()
    print("ë©”ì¼ ë°œì†¡ ì„±ê³µ")

# ==========================================
# 3. ë©”ì¸ ë¡œì§ ë° DAG
# ==========================================
def etl_process(**kwargs):
    # 1. DB ì¡°íšŒ
    df = get_country_stats()
    
    # 2. êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸
    update_google_sheet(df)
    
    # 3. ì´ë©”ì¼ ë°œì†¡
    send_stats_email(df)

default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    dag_id='fsf2_cbt_pre_register_report',
    default_args=default_args,
    description='êµ­ê°€ë³„ ê°€ì…ì í†µê³„ -> êµ¬ê¸€ì‹œíŠ¸ & ì´ë©”ì¼ ë°œì†¡',
    schedule=[fsf2_cbt_pre_register_etl],
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['fsf2', 'report'],
) as dag:

    report_task = PythonOperator(
        task_id='report_task',
        python_callable=etl_process
    )