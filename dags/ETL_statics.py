# Airflow function
from airflow import DAG, Dataset
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.models import Variable
from airflow.models.baseoperator import chain
from google.oauth2 import service_account
import json

import pandas as pd
from google.cloud import bigquery
from google.auth.transport.requests import Request
import logging

from datetime import datetime, timezone, timedelta
import time
import os
import pytz

#### Dimension table ì²˜ë¦¬ í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
PROJECT_ID = "datahub-478802"
LOCATION = "us-central1"

def get_gcp_credentials():
    """Airflow Variableì—ì„œ GCP ìê²© ì¦ëª…ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    credentials_json = Variable.get('GOOGLE_CREDENTIAL_JSON')
    cred_dict = json.loads(credentials_json)
    if 'private_key' in cred_dict:
        cred_dict['private_key'] = cred_dict['private_key'].replace('\\n', '\n')
    
    # [ìˆ˜ì •] ìŠ¤ì½”í”„(Scopes)ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì—¬ëŸ¬ ê°œ ì¶”ê°€í•©ë‹ˆë‹¤.
    SCOPES = [
        "https://www.googleapis.com/auth/cloud-platform",       # ê¸°ë³¸ ì „ì²´ ê¶Œí•œ
        "https://www.googleapis.com/auth/bigquery"             # BigQuery ê¶Œí•œ
    ]
    
    return service_account.Credentials.from_service_account_info(
        cred_dict,
        scopes=SCOPES
    )


def init_clients():
    """Task ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë˜ì–´ í•„ìš”í•œ í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    creds = get_gcp_credentials()
    
    # 1. GCP Clients
    bq_client = bigquery.Client(project=PROJECT_ID, credentials=creds)
    
    return {
        "bq_client": bq_client
    }


def calc_target_date(logical_date):
    """
    [í•µì‹¬ ë¡œì§]
    Airflow ì‹¤í–‰ ì‹œì (logical_date)ì„ KSTë¡œ ë³€í™˜í•œ í›„,
    'í•˜ë£¨ ì „(Yesterday)' ë‚ ì§œë¥¼ ê³„ì‚°í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    utc = pytz.utc
    kst = pytz.timezone('Asia/Seoul')
    
    # 1. UTC ì‹¤í–‰ ì‹œê°„ì„ KSTë¡œ ë³€í™˜
    run_date_kst = logical_date.replace(tzinfo=utc).astimezone(kst)
    
    # 2. KST ê¸°ì¤€ í•˜ë£¨ ì „ ë‚ ì§œ ê³„ì‚° (Yesterday)
    target_d = run_date_kst.date() - timedelta(days=1)
    
    # ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ return 
    target_date_str = target_d.strftime("%Y-%m-%d")
    
    return [target_date_str], run_date_kst


def target_date_range(start_date_str, end_date_str):
    """ë‚ ì§œ ë°ì´í„° ë°±í•„ìš©"""
    # ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜
    start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
    end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
    
    date_list = []
    current_date = start_date
    
    # ì¢…ë£Œ ë‚ ì§œê¹Œì§€ í•˜ë£¨ì”© ë”í•˜ë©° ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    while current_date <= end_date:
        date_list.append(current_date.strftime("%Y-%m-%d"))
        current_date += timedelta(days=1)
        
    return date_list



def etl_statics_daily_kpi(**context):

    # í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œ
    client = init_clients()["bq_client"]

    target_date, _ = calc_target_date(context['logical_date'])
    #################### ë°±í•„ìš© ë°ì´í„° ì²˜ë¦¬
    # target_date = target_date_range("2026-01-24", "2026-01-26")  ## ë°±í•„ìš©

    for td_str in target_date:
               
        print(f"ğŸ“ ëŒ€ìƒë‚ ì§œ: {td_str}")

        # ETL ì‘ì—… ìˆ˜í–‰
        query = f"""
        
        MERGE INTO `datahub-478802.datahub.statics_daily_kpi` as target
        USING (
        SELECT TA.datekey, TA.joyple_game_code, TA.DAU, TB.DRU, TC.PU
        , CAST(TC.IAP_revenue + TD.IAA_rev as INT64) as total_rev
        , CAST(TC.IAP_revenue as INT64) as IAP_rev
        , CAST(TC.IAP_revenue - TC.IAP_none_market_revenue as INT64) as IAP_market_rev
        , CAST(TC.IAP_none_market_revenue as INT64) as IAP_none_market_rev
        , CAST(TD.IAA_rev as INT64) as IAA_rev
        , ROUND(TC.PU/TA.DAU * 100, 2) as PUR
        , ROUND(TC.IAP_revenue / TC.PU, 0) as ARPPU
        , ROUND(TC.IAP_revenue / TA.DAU, 0) as ARPDAU
        , TE.installs_funnel
        , TF.installs_appsflyer
        , ROUND(TG.NNPU / TC.PU * 100, 2) as NNPUR
        , TG.NNPU
        , CAST(TG.NNPU_rev as INT64) as NNPU_rev
        FROM
        (
            select datekey, joyple_game_code, count(distinct auth_account_name) as DAU
            from `datahub-478802.datahub.f_common_access`
            where datekey >= '{td_str}' and datekey < DATE_ADD('{td_str}', INTERVAL 1 DAY)
            and access_type_id = 1
            group by datekey, joyple_game_code 
        ) as TA
        left join
        (
            select reg_datekey as datekey, joyple_game_code, count(distinct auth_account_name) as DRU
            from `datahub-478802.datahub.f_common_register`
            where reg_datekey >= '{td_str}' and reg_datekey < DATE_ADD('{td_str}', INTERVAL 1 DAY)
            group by reg_datekey, joyple_game_code 
        ) as TB
        ON TA.datekey = TB.datekey AND TA.joyple_game_code = TB.joyple_game_code
        left join
        (
            select datekey, joyple_game_code, count(distinct auth_account_name) as PU
            , sum(revenue) as IAP_revenue
            , sum(
            CASE WHEN pg_id in (select pg_id from `datahub-478802.datahub.dim_special_pg`) 
            AND platform_device_type in (select platform_device_type from `datahub-478802.datahub.dim_special_pg`)
            THEN revenue END
            ) as IAP_none_market_revenue
            from `datahub-478802.datahub.f_common_payment`
            where datekey >= '{td_str}' and datekey < DATE_ADD('{td_str}', INTERVAL 1 DAY)
            group by datekey, joyple_game_code 
        ) as TC
        ON TA.datekey = TC.datekey AND TA.joyple_game_code = TC.joyple_game_code
        left join 
        (
        select watch_datekey as datekey, joyple_game_code
        , sum(revenue_per_user_KRW) as IAA_rev
        from `datahub-478802.datahub.f_IAA_auth_account_performance`
        where watch_datekey >= '{td_str}' and watch_datekey < DATE_ADD('{td_str}', INTERVAL 1 DAY)
        group by watch_datekey, joyple_game_code
        ) as TD
        ON TA.datekey = TD.datekey AND TA.joyple_game_code = TD.joyple_game_code
        left join 
        (
        select datekey as datekey, joyple_game_code
        , count(distinct device_id) as installs_funnel
        from `datahub-478802.datahub.f_funnel_access_first`
        where datekey >= '{td_str}' and datekey < DATE_ADD('{td_str}', INTERVAL 1 DAY)
        group by datekey, joyple_game_code
        ) as TE
        ON TA.datekey = TE.datekey AND TA.joyple_game_code = TE.joyple_game_code
        left join 
        (
        select install_datekey as datekey, joyple_game_code
        , count(distinct tracker_account_id) as installs_appsflyer
        from `datahub-478802.datahub.f_tracker_install`
        where install_datekey >= '{td_str}' and install_datekey < DATE_ADD('{td_str}', INTERVAL 1 DAY)
        group by install_datekey, joyple_game_code
        ) as TF
        ON TA.datekey = TF.datekey AND TA.joyple_game_code = TF.joyple_game_code
        left join 
        (
        select datekey, joyple_game_code
        , count(distinct auth_account_name) as NNPU
        , sum(revenue) as NNPU_rev
        from `datahub-478802.datahub.f_common_payment`
        where datekey >= '{td_str}' and datekey < DATE_ADD('{td_str}', INTERVAL 1 DAY)
        and reg_datekey >= '{td_str}' and reg_datekey < DATE_ADD('{td_str}', INTERVAL 1 DAY)
        and reg_datediff = 0
        group by datekey, joyple_game_code
        ) as TG
        ON TA.datekey = TG.datekey AND TA.joyple_game_code = TG.joyple_game_code
        ) as source
        ON target.datekey = source.datekey AND target.joyple_game_code = source.joyple_game_code
        WHEN MATCHED THEN 
        UPDATE SET 
        target.DAU = source.DAU,
        target.DRU = source.DRU,
        target.PU = source.PU,
        target.total_rev = source.total_rev,
        target.IAP_rev = source.IAP_rev,
        target.IAP_market_rev = source.IAP_market_rev,
        target.IAP_none_market_rev = source.IAP_none_market_rev,
        target.IAA_rev = source.IAA_rev,
        target.PUR = source.PUR,
        target.ARPPU = source.ARPPU,
        target.ARPDAU = source.ARPDAU,
        target.installs_funnel = source.installs_funnel,
        target.installs_appsflyer = source.installs_appsflyer,
        target.NNPUR = source.NNPUR,
        target.NNPU = source.NNPU,
        target.NNPU_rev = source.NNPU_rev
        WHEN NOT MATCHED THEN 
        INSERT
        (
        datekey,
        joyple_game_code,
        DAU,
        DRU,
        PU,
        total_rev,
        IAP_rev,
        IAP_market_rev,
        IAP_none_market_rev,
        IAA_rev,
        PUR,
        ARPPU,
        ARPDAU,
        installs_funnel,
        installs_appsflyer,
        NNPUR,
        NNPU,
        NNPU_rev
        )
        VALUES 
        (
        source.datekey,
        source.joyple_game_code,
        source.DAU,
        source.DRU,
        source.PU,
        source.total_rev,
        source.IAP_rev,
        source.IAP_market_rev,
        source.IAP_none_market_rev,
        source.IAA_rev,
        source.PUR,
        source.ARPPU,
        source.ARPDAU,
        source.installs_funnel,
        source.installs_appsflyer,
        source.NNPUR,
        source.NNPU,
        source.NNPU_rev
        )
        """

        # 1. ì¿¼ë¦¬ ì‹¤í–‰
        query_job = client.query(query)

        try:
            # 2. ì‘ì—… ì™„ë£Œ ëŒ€ê¸° (ì—¬ê¸°ì„œ ì¿¼ë¦¬ê°€ ëë‚  ë•Œê¹Œì§€ ë¸”ë¡œí‚¹ë¨)
            # ì¿¼ë¦¬ì— ì—ëŸ¬ê°€ ìˆë‹¤ë©´ ì´ ë¼ì¸ì—ì„œ ì˜ˆì™¸(Exception)ê°€ ë°œìƒí•©ë‹ˆë‹¤.
            query_job.result()

            # 3. ì„±ê³µ ì‹œ ì¶œë ¥
            print(f"âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì„±ê³µ! (Job ID: {query_job.job_id})")
            print(f"â–  {td_str} statics_daily_kpi Batch ì™„ë£Œ")

        except Exception as e:
            # 4. ì‹¤íŒ¨ ì‹œ ì¶œë ¥
            print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
            raise e
    
    print("âœ… statics_daily_kpi ETL ì™„ë£Œ")
    return True
