# -*- coding: utf-8 -*-
"""
Google Sheets â†’ GCS ë§í¬ ì •ê·œí™” & Notion DB ì—…ë¡œë“œ DAG
ì¼ì¼ ë°°ì¹˜ë¡œ ì‹¤í–‰ë˜ë©°, ê° í”„ë¡œì íŠ¸ë³„ ì‹œíŠ¸ë¥¼ ë³‘ë ¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.
"""

from airflow import DAG, Dataset
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.models import Variable
from datetime import datetime, timedelta
import os
import sys
import json
try:
    import gspread
except ImportError:
    print("âš ï¸  gspread ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘...")
    import subprocess
    subprocess.check_call(['pip', 'install', 'gspread'])
    import gspread


gcs_creative_file_upload = Dataset('gcs_creative_file_upload')

# ê¸°ë³¸ DAG ì„¤ì •
default_args = {
    'owner': 'ds_bi',
    'depends_on_past': False,
    'email_on_failure': True,
    'email_on_retry': False,
    'email': ['65e43b85.joycity.com@kr.teams.ms'],  # ì‹¤íŒ¨ ì‹œ ì•Œë¦¼ ì´ë©”ì¼
    'retries': 1,
    'retry_delay': timedelta(minutes=2),
}

dag = DAG(
    dag_id='gcs_creative_file_upload',
    default_args=default_args,
    description='Google Sheets ë§í¬ ì •ê·œí™” ë° Notion DB ìë™ ì—…ë¡œë“œ',
    schedule='0 21 * * *',  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ ì‹¤í–‰ (KST ê¸°ì¤€ ì¡°ì • í•„ìš”)
    start_date=datetime(2025, 1, 1),
    catchup=False,
    max_active_runs=1,
    max_active_tasks=1,
    tags=['creative', 'notion', 'marketing'],
)

# =====================
# Airflow Variablesì—ì„œ ì„¤ì • ê°’ ë¡œë“œ
# =====================
def get_var(key: str, default: str = None) -> str:
    """í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Airflow Variable ì¡°íšŒ"""
    return os.environ.get(key) or Variable.get(key, default_var=default)

# ì„¤ì • ê°’ë“¤
NETWORK_BASE_PATH = get_var('__network_base_path', '/mnt/creative/')
SPREADSHEET_ID = get_var('__spreadsheet_id', '1n2-pedl4-QH8Jo4poqPk62ynyaezMaM0dKuWitRqyDo')
CREDENTIALS_JSON = get_var('GOOGLE_CREDENTIAL_JSON')
GCS_BUCKET = get_var('__gcs_bucket', 'ua_creative_files')
NOTION_API_KEY = get_var('NOTION_TOKEN_FOR_CREATIVE')
NOTION_DB_ID = get_var('NOTION_DB_ID_UA_CREATIVE_FILE')

TARGET_SHEETS = ['POTC', 'GBTW', 'WWMC', 'DRSG', 'DRB', 'JTWN', 'BSTD', 'RESU']

cred_dict = json.loads(CREDENTIALS_JSON)

if 'private_key' in cred_dict:
    private_key = cred_dict['private_key']
    # ë§Œì•½ \\n (ì´ì¤‘ ì´ìŠ¤ì¼€ì´í”„)ë¡œ ì €ì¥ë˜ì–´ ìˆë‹¤ë©´
    if '\\n' in private_key:
        cred_dict['private_key'] = private_key.replace('\\n', '\n')
    # ë˜ëŠ” ê³µë°±ì´ë‚˜ ë‹¤ë¥¸ ë¬¸ìë¡œ ê¹¨ì§„ ê²½ìš°
    elif 'BEGIN PRIVATE KEY-----' in private_key and '\n' not in private_key:
        print("âš ï¸ Private keyì— ì¤„ë°”ê¿ˆì´ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ì • ì¤‘...")
        # ìˆ˜ë™ìœ¼ë¡œ ì¤„ë°”ê¿ˆ ì¶”ê°€
        cred_dict['private_key'] = private_key.replace(
            '-----BEGIN PRIVATE KEY-----', 
            '-----BEGIN PRIVATE KEY-----\n'
        ).replace(
            '-----END PRIVATE KEY-----', 
            '\n-----END PRIVATE KEY-----\n'
        )

def check_dependencies(**context):
    """í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ í™•ì¸"""
    import subprocess
    
    required_packages = ['gspread', 'google-cloud-storage', 'notion-client']
    
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
        except ImportError:
            print(f"âš ï¸  {package} ì„¤ì¹˜ ì¤‘...")
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
    
    # ë„¤íŠ¸ì›Œí¬ ê²½ë¡œ í™•ì¸
    if not os.path.exists(NETWORK_BASE_PATH):
        print(f"âš ï¸  ë„¤íŠ¸ì›Œí¬ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {NETWORK_BASE_PATH}")
    
    print("âœ… í™˜ê²½ ê²€ì¦ ì™„ë£Œ")


def initialize_clients(**context):
    """Google Sheets, GCS, Notion í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    import gspread
    from google.oauth2.service_account import Credentials
    from google.cloud import storage
    from notion_client import Client as NotionClient
    
    # Google Sheets ì¸ì¦
    SCOPES = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ]

    
    sheet_creds = Credentials.from_service_account_info(cred_dict, scopes=SCOPES)
    gc = gspread.authorize(sheet_creds)
    
    # GCS í´ë¼ì´ì–¸íŠ¸
    storage_client = storage.Client.from_service_account_info(cred_dict)
    bucket = storage_client.bucket(GCS_BUCKET)
    
    # Notion í´ë¼ì´ì–¸íŠ¸
    notion = NotionClient(auth=NOTION_API_KEY)
    
    # XComì— ìƒíƒœ ì €ì¥
    context['ti'].xcom_push(key='clients_initialized', value=True)
    
    print("âœ… í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    return {
        'sheets_initialized': True,
        'gcs_initialized': True,
        'notion_initialized': True
    }


def fetch_notion_schema(**context):
    """Notion DB ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ë° ê¸°ì¡´ ì†Œì¬ëª… ëª©ë¡ ë¡œë“œ"""
    from notion_client import Client as NotionClient
    import unicodedata
    import re
    
    def nospace_lower(s: str) -> str:
        if s is None: return ""
        s = unicodedata.normalize('NFKC', str(s))
        s = re.sub(r'\s+', '', s)
        return s.lower()
    
    def get_plain_text_from_prop(prop_type: str, prop_value: dict) -> str:
        if not prop_value: return ""
        try:
            if prop_type in ("title", "rich_text"):
                arr = prop_value.get(prop_type, [])
                return "".join([t.get("plain_text", "") for t in arr]).strip()
            if prop_type == "select":
                opt = prop_value.get("select")
                return (opt or {}).get("name", "").strip() if opt else ""
            if prop_type == "multi_select":
                arr = prop_value.get("multi_select", [])
                return ", ".join([(o or {}).get("name", "").strip() for o in arr if o])
            if prop_type == "url":
                return (prop_value.get("url") or "").strip()
            if prop_type == "number":
                n = prop_value.get("number")
                return str(n).strip() if n is not None else ""
            if prop_type == "date":
                d = prop_value.get("date", {})
                return (d.get("start") or "").strip()
            return str(prop_value).strip()
        except Exception:
            return ""
    
    notion = NotionClient(auth=NOTION_API_KEY)
    
    # DB ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
    info = notion.databases.retrieve(database_id=NOTION_DB_ID)
    props = info.get("properties", {})
    prop_by_clean = {}
    title_prop_name = None
    project_prop = None
    sojae_prop_meta = None
    
    for name, meta in props.items():
        ptype = meta.get("type")
        clean = nospace_lower(name)
        if ptype == "title":
            title_prop_name = name
        if clean == nospace_lower('í”„ë¡œì íŠ¸'):
            project_prop = {"name": name, "type": ptype, "meta": meta}
        if clean == nospace_lower('ì†Œì¬ëª…'):
            sojae_prop_meta = {"name": name, "type": ptype, "meta": meta}
        prop_by_clean[clean] = {"name": name, "type": ptype, "meta": meta}
    
    # ê¸°ì¡´ ì†Œì¬ëª… ëª©ë¡ ë¡œë“œ
    existing_sojae_names = set()
    if sojae_prop_meta:
        target_real = sojae_prop_meta["name"]
        target_type = sojae_prop_meta["type"]
        cursor = None
        
        while True:
            resp = notion.databases.query(
                database_id=NOTION_DB_ID,
                start_cursor=cursor
            ) if cursor else notion.databases.query(database_id=NOTION_DB_ID)
            
            for page in resp.get("results", []):
                props_data = page.get("properties", {})
                if target_real in props_data:
                    raw = props_data[target_real]
                    val = get_plain_text_from_prop(target_type, raw)
                    if val:
                        existing_sojae_names.add(nospace_lower(val))
            
            if not resp.get("has_more"):
                break
            cursor = resp.get("next_cursor")
    
    schema_info = {
        'prop_by_clean': prop_by_clean,
        'title_prop_name': title_prop_name,
        'project_prop': project_prop,
        'sojae_prop_meta': sojae_prop_meta,
        'existing_sojae_names': list(existing_sojae_names)
    }
    
    context['ti'].xcom_push(key='notion_schema', value=schema_info)
    
    print(f"âœ… Notion ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì™„ë£Œ (ê¸°ì¡´ ì†Œì¬ëª…: {len(existing_sojae_names)}ê°œ)")
    return schema_info


def process_sheet(sheet_name, **context):
    """ê°œë³„ ì‹œíŠ¸ ì²˜ë¦¬ - ë§í¬ ì •ê·œí™” ë° Notion ì—…ë¡œë“œ"""
    import gspread
    from google.oauth2.service_account import Credentials
    from google.cloud import storage
    from notion_client import Client as NotionClient
    import time
    import re
    import os
    import unicodedata
    import mimetypes
    from datetime import timedelta
    from urllib.parse import quote
    
    # === ìœ í‹¸ í•¨ìˆ˜ ===
    def nospace_lower(s: str) -> str:
        if s is None: return ""
        s = unicodedata.normalize('NFKC', str(s))
        s = re.sub(r'\s+', '', s)
        return s.lower()
    
    def normalize(s: str) -> str:
        return unicodedata.normalize('NFKC', str(s)).strip().lower() if s is not None else ""
    
    def col_index_to_letter(idx: int) -> str:
        letters = ''
        while idx:
            idx, rem = divmod(idx - 1, 26)
            letters = chr(65 + rem) + letters
        return letters
    
    def looks_like_url(s: str) -> bool:
        if not s: return False
        s = str(s).strip()
        return bool(re.match(r'^(https?://|gs://|s3://|www\.)', s, re.IGNORECASE))
    
    def first_url(s: str) -> str:
        if not s: return ""
        raw = str(s).strip()
        for part in re.split(r'[,\n; ]+', raw):
            part = part.strip()
            if looks_like_url(part):
                return part
        m = re.search(r'(https?://[^\s",;]+)', raw, re.IGNORECASE)
        return m.group(1).strip() if m else ""
    
    def map_headers(ws, header_row: int = 3):
        headers = ws.row_values(header_row)
        mapping = {}
        for i, name in enumerate(headers, start=1):
            key = nospace_lower(name)
            if key and key not in mapping:
                mapping[key] = (i, name)
        return mapping
    
    def find_sheet_col_idx(mapping: dict, logical_name: str):
        key = nospace_lower(logical_name)
        if key in mapping:
            return mapping[key][0]
        # ë™ì˜ì–´
        if key == nospace_lower('íŒŒì¼ë§í¬') and nospace_lower('íŒŒì¼ ë§í¬') in mapping:
            return mapping[nospace_lower('íŒŒì¼ ë§í¬')][0]
        if key == nospace_lower('íŒŒì¼ ë§í¬') and nospace_lower('íŒŒì¼ë§í¬') in mapping:
            return mapping[nospace_lower('íŒŒì¼ë§í¬')][0]
        # í¼ì§€ ë§¤ì¹­
        for k, (idx, _orig) in mapping.items():
            if key and (key in k or k in key):
                return idx
        return None
    
    def last_nonempty_index(values):
        for i in range(len(values)-1, -1, -1):
            if str(values[i]).strip() != "":
                return i + 1
        return 0
    
    def is_shortcut_path(path: str) -> bool:
        try:
            name = os.path.basename(path).lower()
            if name.endswith('.lnk') or 'ë°”ë¡œê°€ê¸°' in name or 'shortcut' in name:
                return True
            if os.path.islink(path):
                return True
            if os.name == 'nt':
                import ctypes, ctypes.wintypes as wt
                GetFileAttributesW = ctypes.windll.kernel32.GetFileAttributesW
                GetFileAttributesW.argtypes = [wt.LPCWSTR]
                GetFileAttributesW.restype  = wt.DWORD
                FILE_ATTRIBUTE_REPARSE_POINT = 0x0400
                attrs = GetFileAttributesW(path)
                if attrs != 0xFFFFFFFF and (attrs & FILE_ATTRIBUTE_REPARSE_POINT):
                    return True
        except Exception:
            pass
        return False
    
    def extract_hyperlink_url(formula: str) -> str:
        if not formula: return ''
        m = re.match(r'^\s*=\s*HYPERLINK\s*\(\s*"([^"]+)"', formula, re.IGNORECASE)
        return m.group(1) if m else ''
    
    def public_url(bucket_name: str, object_path: str) -> str:
        return f"https://storage.googleapis.com/{bucket_name}/{quote(object_path, safe='/')}"
    
    def build_dest_path(sheet_name: str, filename: str) -> str:
        prefix = GCS_PREFIX_BY_SHEET.get(sheet_name, f"{sheet_name}/")
        if prefix and not prefix.endswith('/'):
            prefix += '/'
        return f"{prefix}{filename}"
    
    def upload_to_gcs_and_get_link(local_filepath: str, dest_path: str, bucket, uploaded_cache: dict) -> str:
        if dest_path in uploaded_cache:
            return uploaded_cache[dest_path]
        
        blob = bucket.blob(dest_path)
        if blob.exists():
            url = public_url(GCS_BUCKET, dest_path)
            uploaded_cache[dest_path] = url
            return url
        
        content_type = mimetypes.guess_type(local_filepath)[0] or 'application/octet-stream'
        try:
            blob.upload_from_filename(local_filepath, content_type=content_type)
        except Exception as e:
            print(f"â— ì—…ë¡œë“œ ì‹¤íŒ¨: {local_filepath} â†’ {e}")
            return 'ì—…ë¡œë“œ ì‹¤íŒ¨'
        
        url = public_url(GCS_BUCKET, dest_path)
        uploaded_cache[dest_path] = url
        return url
    
    def find_project_root(sheet_name: str) -> str | None:
        for a in ALIAS_PREFIX.get(sheet_name, []):
            p = os.path.join(NETWORK_BASE_PATH, a)
            if os.path.isdir(p):
                print(f"â€¢ [{sheet_name}] ë³„ì¹­ í´ë” ì‚¬ìš©: {p}")
                return p
        p = os.path.join(NETWORK_BASE_PATH, sheet_name)
        if os.path.isdir(p):
            print(f"â€¢ [{sheet_name}] ë™ì¼ëª… í´ë” ì‚¬ìš©: {p}")
            return p
        return None
    
    # Notion ìœ í‹¸ í•¨ìˆ˜
    def notion_rich(s: str):
        s = (s or '')
        if len(s) > 1900:
            s = s[:1900] + 'â€¦'
        return [{"type": "text", "text": {"content": s}}]
    
    def to_bool(s: str):
        if s is None: return None
        t = str(s).strip().lower()
        if t in {"y","yes","true","1","t","o","ok","ì‚¬ìš©","í™œìš©","ìˆìŒ","í¬í•¨","âœ”","âœ“"}:
            return True
        if t in {"n","no","false","0","f","x","ë¯¸ì‚¬ìš©","ì—†ìŒ","ë¹„í¬í•¨"}:
            return False
        return None
    
    def to_number(s: str):
        if s is None: return None
        t = str(s).strip().replace(",", "")
        if t == "": return None
        try:
            return float(t)
        except:
            return None
    
    def to_date_from_yymmdd(s: str):
        if not s: return None
        t = re.sub(r'\D+', '', str(s))
        if len(t) == 6:
            try:
                from datetime import datetime
                dt = datetime.strptime(t, "%y%m%d")
                return dt.date().isoformat()
            except:
                return None
        try:
            from datetime import datetime
            dt = datetime.fromisoformat(str(s))
            return dt.date().isoformat()
        except:
            return None
    
    def split_multi(s: str):
        if not s: return []
        parts = re.split(r'[,\n/;]+', str(s))
        return [p.strip() for p in parts if p.strip()]
    
    def coerce_payload(prop_type: str, value: str):
        v = "" if value is None else str(value).strip()
        try:
            if prop_type == "title":
                return {"title": notion_rich(v)}
            if prop_type == "rich_text":
                return {"rich_text": notion_rich(v)}
            if prop_type == "url":
                if looks_like_url(v): return {"url": v}
                return {"rich_text": notion_rich(v)}
            if prop_type == "checkbox":
                b = to_bool(v)
                return {"checkbox": b} if b is not None else {"rich_text": notion_rich(v)}
            if prop_type == "number":
                n = to_number(v)
                return {"number": n} if n is not None else {"rich_text": notion_rich(v)}
            if prop_type == "date":
                iso = to_date_from_yymmdd(v)
                return {"date": {"start": iso}} if iso else {"rich_text": notion_rich(v)}
            if prop_type == "select":
                if v == "": return {"select": None}
                return {"select": {"name": v}}
            if prop_type == "multi_select":
                items = split_multi(v)
                return {"multi_select": [{"name": it} for it in items]}
            return {"rich_text": notion_rich(v)}
        except Exception:
            return {"rich_text": notion_rich(v)}
    
    def find_db_prop(prop_by_clean: dict, logical_name: str):
        target = nospace_lower(logical_name)
        if target in prop_by_clean:
            return prop_by_clean[target]
        for clean_key, meta in prop_by_clean.items():
            if target in clean_key or clean_key in target:
                return meta
        return None
    
    # === ì„¤ì • ===
    SCOPES = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive"
    ]
    
    EXT_WHITELIST = ['.jpg', '.png', '.mp4']
    MAX_ROWS_PER_SHEET = 5000
    CHUNK_SIZE = 500
    DATA_START_ROW = 4
    MAX_FILES_SCAN = 20000
    MAX_SCAN_SECONDS = 120
    LOG_EVERY = 100
    GSPREAD_RETRY = 2
    
    GCS_PREFIX_BY_SHEET = {
        'POTC': 'POTC/', 'GBTW': 'GBTW/', 'WWMC': 'WWMC/', 'DRSG': 'DRSG/',
        'DRB': 'DRB/', 'JTWN': 'JTWN/', 'BSTD': 'BSTD/', 'RESU': 'RESU/',
    }
    
    ALIAS_PREFIX = {
        'DRSG': ['DS'],
        'WWMC': ['WWM'],
        'JTWN': ['JYTW'],
    }
    
    PROJECT_VIEW_URLS = {
        "POTC": "https://www.notion.so/joycity/273ea67a5681806880f2ff1faac3ec71?v=273ea67a568181269e9c000c18a91f2b",
        "GBTW": "https://www.notion.so/joycity/273ea67a5681806880f2ff1faac3ec71?v=273ea67a56818150a4c8000cc5dcd177",
        "WWMC": "https://www.notion.so/joycity/273ea67a5681806880f2ff1faac3ec71?v=273ea67a568181168968000c25c36c48",
        "DRSG": "https://www.notion.so/joycity/273ea67a5681806880f2ff1faac3ec71?v=273ea67a5681817bbfad000c84df1149",
        "DRB": "https://www.notion.so/joycity/273ea67a5681806880f2ff1faac3ec71?v=273ea67a568180f2a430000c03676a67",
        "JTWN": "https://www.notion.so/joycity/273ea67a5681806880f2ff1faac3ec71?v=273ea67a5681809991be000c24f6b232",
        "BSTD": "https://www.notion.so/joycity/273ea67a5681806880f2ff1faac3ec71?v=273ea67a5681809881d0000cab95e6b7",
        "RESU": "https://www.notion.so/joycity/273ea67a5681806880f2ff1faac3ec71?v=273ea67a568181079f38000c1192dc07"
    }
    
    # === í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ===
    
    sheet_creds = Credentials.from_service_account_info(cred_dict, scopes=SCOPES)
    gc = gspread.authorize(sheet_creds)
    spreadsheet = gc.open_by_key(SPREADSHEET_ID)

    storage_client = storage.Client.from_service_account_info(cred_dict)
    bucket = storage_client.bucket(GCS_BUCKET)
    
    notion = NotionClient(auth=NOTION_API_KEY)
    
    # Notion ìŠ¤í‚¤ë§ˆ ê°€ì ¸ì˜¤ê¸°
    schema_info = context['ti'].xcom_pull(key='notion_schema', task_ids='fetch_notion_schema')
    prop_by_clean = schema_info['prop_by_clean']
    title_prop_name = schema_info['title_prop_name']
    project_prop = schema_info['project_prop']
    existing_sojae_names = set(schema_info['existing_sojae_names'])
    
    print(f"\n{'='*60}")
    print(f"[{sheet_name}] ì²˜ë¦¬ ì‹œì‘")
    print(f"{'='*60}")
    
    try:
        ws = spreadsheet.worksheet(sheet_name)
    except Exception as e:
        print(f"â— ì‹œíŠ¸ '{sheet_name}' ì—†ìŒ - ê±´ë„ˆëœ€: {e}")
        return {'status': 'skipped', 'reason': 'sheet_not_found'}
    
    # í—¤ë” ë§¤í•‘
    headers_map = map_headers(ws, header_row=3)
    
    # í•„ìˆ˜ ì—´ í™•ì¸
    link_idx = find_sheet_col_idx(headers_map, 'íŒŒì¼ ë§í¬')
    if link_idx is None:
        print("â— 'íŒŒì¼ ë§í¬/íŒŒì¼ë§í¬' ì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return {'status': 'skipped', 'reason': 'no_link_column'}
    
    link_col_letter = col_index_to_letter(link_idx)
    yt_idx = find_sheet_col_idx(headers_map, 'Youtube URL')
    so_idx = find_sheet_col_idx(headers_map, 'ì†Œì¬ëª…')
    past_idx = find_sheet_col_idx(headers_map, 'ê³¼ê±°ì†Œì¬ëª…')
    cat_idx = find_sheet_col_idx(headers_map, 'ëŒ€ë¶„ë¥˜')
    
    # ë§í¬ ì—´ í¬ë§· ì„¤ì •
    try:
        spreadsheet.batch_update({
            "requests": [{
                "updateDimensionProperties": {
                    "range": {
                        "sheetId": ws.id,
                        "dimension": "COLUMNS",
                        "startIndex": link_idx - 1,
                        "endIndex": link_idx
                    },
                    "properties": {"pixelSize": 70},
                    "fields": "pixelSize"
                }
            }, {
                "repeatCell": {
                    "range": {
                        "sheetId": ws.id,
                        "startRowIndex": DATA_START_ROW - 1,
                        "endRowIndex": ws.row_count,
                        "startColumnIndex": link_idx - 1,
                        "endColumnIndex": link_idx
                    },
                    "cell": {"userEnteredFormat": {"wrapStrategy": "CLIP"}},
                    "fields": "userEnteredFormat.wrapStrategy"
                }
            }]
        })
        print(f"âœ“ '{link_col_letter}'ì—´ ë„ˆë¹„ 70px + CLIP ì ìš©")
    except Exception as e:
        print(f"âš ï¸ ì—´ í¬ë§· ì ìš© ì‹¤íŒ¨: {e}")
    
    # ë°ì´í„° ë¡œë“œ
    link_display_vals = ws.col_values(link_idx)[3:]
    youtube_vals = ws.col_values(yt_idx)[3:] if yt_idx else []
    so_vals_disp = ws.col_values(so_idx)[3:] if so_idx else []
    past_vals_disp = ws.col_values(past_idx)[3:] if past_idx else []
    
    # ë„¤íŠ¸ì›Œí¬ íŒŒì¼ ìŠ¤ìº”
    all_files = []
    uploaded_file_cache = {}
    project_root = find_project_root(sheet_name)
    
    if project_root:
        t0 = time.perf_counter()
        scan_files = 0
        try:
            candidate_dirs = []
            for name in os.listdir(project_root):
                path = os.path.join(project_root, name)
                if not os.path.isdir(path): continue
                if is_shortcut_path(path): continue
                if re.search(r'backup|ë°±ì—…|old|temp', name, re.I): continue
                if 'ì†Œì¬' in name:
                    candidate_dirs.append(path)
            
            for base_dir in candidate_dirs:
                print(f"  Â· [{sheet_name}] ìŠ¤ìº” ì‹œì‘: {base_dir}")
                for root, dirs, files in os.walk(base_dir):
                    dirs[:] = [d for d in dirs
                               if not is_shortcut_path(os.path.join(root, d))
                               and not re.search(r'backup|ë°±ì—…|old|temp', d, re.I)]
                    for fname in files:
                        if is_shortcut_path(os.path.join(root, fname)):
                            continue
                        scan_files += 1
                        if scan_files % 2000 == 0:
                            print(f"    .. ìŠ¤ìº” ì§„í–‰: {scan_files}ê°œ í™•ì¸, ìœ íš¨ {len(all_files)}ê°œ")
                        if time.perf_counter() - t0 > MAX_SCAN_SECONDS:
                            print(f"  âš ï¸ [{sheet_name}] ì¸ë±ì‹± ì‹œê°„ ì´ˆê³¼({time.perf_counter()-t0:.1f}s) ì¤‘ë‹¨")
                            break
                        if len(all_files) >= MAX_FILES_SCAN:
                            print(f"  âš ï¸ [{sheet_name}] ì¸ë±ì‹± ìƒí•œ {MAX_FILES_SCAN} ë„ë‹¬")
                            break
                        
                        ext = os.path.splitext(fname)[1].lower()
                        if ext in EXT_WHITELIST:
                            all_files.append({
                                'name': os.path.splitext(fname)[0],
                                'original': fname,
                                'path': os.path.join(root, fname)
                            })
                    else:
                        continue
                    break
        except Exception as e:
            print(f"â„¹ï¸ [{sheet_name}] ë£¨íŠ¸ ìŠ¤ìº” ì¤‘ ì˜ˆì™¸: {e}")
        print(f"â€¢ [{sheet_name}] ì¸ë±ì‹± ê²°ê³¼: ìœ íš¨ {len(all_files)}ê°œ, íŒŒì¼í™•ì¸ {scan_files}ê°œ, {time.perf_counter()-t0:.1f}s")
    else:
        print(f"â„¹ï¸ í”„ë¡œì íŠ¸ í´ë” ì—†ìŒ: {sheet_name} â€” íŒŒì¼ ë§¤ì¹­ ìƒëµ")
    
    # ë§í¬ ì—…ë°ì´íŠ¸ ë²”ìœ„ ê³„ì‚°
    last_link = last_nonempty_index(link_display_vals)
    last_yt = last_nonempty_index(youtube_vals)
    last_so = last_nonempty_index(so_vals_disp)
    last_past = last_nonempty_index(past_vals_disp)
    real_last = max(last_link, last_yt, last_so, last_past)
    
    if real_last == 0:
        print("â„¹ï¸ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {'status': 'completed', 'sheet_name': sheet_name, 'updated_links': 0, 'notion_rows': 0}
    
    end_row = min(3 + real_last, 3 + MAX_ROWS_PER_SHEET)
    start_row = DATA_START_ROW
    total_rows = max(0, end_row - start_row + 1)
    print(f"â€¢ [{sheet_name}] ë§í¬ ì—…ë°ì´íŠ¸ ëŒ€ìƒ: {total_rows}í–‰ (4~{end_row})")
    
    def get_safe(lst, idx): return lst[idx] if idx < len(lst) else ""
    
    rows_done = 0
    new_links_count = 0
    t_sheet = time.perf_counter()
    
    # ë§í¬ ì—…ë°ì´íŠ¸ ë°°ì¹˜ ì²˜ë¦¬
    while rows_done < total_rows:
        t_batch = time.perf_counter()
        batch_start = start_row + rows_done
        batch_end = min(batch_start + CHUNK_SIZE - 1, end_row)
        batch_len = batch_end - batch_start + 1
        link_range = f'{link_col_letter}{batch_start}:{link_col_letter}{batch_end}'
        print(f"  â–¶ [{sheet_name}] ë°°ì¹˜ ì‹œì‘ {batch_start}~{batch_end} (len={batch_len})")
        
        batch_values = []
        for i in range(batch_len):
            gi = rows_done + i
            disp = get_safe(link_display_vals, gi)
            yt_url = first_url(get_safe(youtube_vals, gi))
            
            so_name = get_safe(so_vals_disp, gi)
            past_name = get_safe(past_vals_disp, gi)
            
            tokens = [normalize(t) for t in (so_name, past_name) if t and normalize(t)]
            tokens = [t for t in tokens if len(t) > 2]
            
            chosen_url = None
            
            if yt_url:
                chosen_url = yt_url
            elif tokens and all_files:
                selected = None
                for f in all_files:
                    if any(tok in normalize(f['name']) for tok in tokens):
                        selected = f
                        break
                if selected:
                    filename = os.path.basename(selected['path'])
                    dest_path = build_dest_path(sheet_name, filename)
                    try:
                        gcs_link = upload_to_gcs_and_get_link(selected['path'], dest_path, bucket, uploaded_file_cache)
                    except Exception as e:
                        print(f"    â— ì—…ë¡œë“œ ì˜ˆì™¸({selected['path']}) â†’ {e}")
                        gcs_link = 'ì—…ë¡œë“œ ì‹¤íŒ¨'
                    if gcs_link and gcs_link != 'ì—…ë¡œë“œ ì‹¤íŒ¨':
                        chosen_url = gcs_link
                        new_links_count += 1
            
            if chosen_url:
                batch_values.append(chosen_url)
            else:
                if looks_like_url(disp):
                    batch_values.append(disp.strip())
                else:
                    batch_values.append(disp)
            
            if (i % LOG_EVERY == 0) and i > 0:
                print(f"    Â· ì§„í–‰ {i}/{batch_len} (ì „ì²´ {rows_done+i}/{total_rows})")
        
        # ë°°ì¹˜ ì»¤ë°‹
        commit_ok = False
        for attempt in range(1, GSPREAD_RETRY+2):
            try:
                cells = ws.range(link_range)
                for i, cell in enumerate(cells):
                    cell.value = batch_values[i]
                ws.update_cells(cells, value_input_option='USER_ENTERED')
                ws.format(link_range, {
                    "horizontalAlignment": "LEFT",
                    "wrapStrategy": "CLIP"
                })
                print(f"  âœ“ [{sheet_name}] ì»¤ë°‹ ì™„ë£Œ {batch_start}~{batch_end}")
                commit_ok = True
                break
            except Exception as e:
                print(f"  âš ï¸ ì»¤ë°‹ ì‹¤íŒ¨({attempt}) {batch_start}~{batch_end} â†’ {e}")
                time.sleep(1.2)
        
        if not commit_ok:
            print(f"  â— [{sheet_name}] ì»¤ë°‹ ìµœì¢… ì‹¤íŒ¨: {link_range}")
        
        rows_done += batch_len
    
    print(f"âœ… [{sheet_name}] ë§í¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {rows_done}í–‰ (ì‹ ê·œ {new_links_count}ê°œ)")
    
    # === Notion ì—…ë¡œë“œ ===
    if not so_idx:
        print("âš ï¸ 'ì†Œì¬ëª…' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•´ Notion ì—…ë¡œë“œ ìƒëµ")
        return {'status': 'completed', 'sheet_name': sheet_name, 'updated_links': new_links_count, 'notion_rows': 0}
    
    headers_row = ws.row_values(3)
    last_col_letter = col_index_to_letter(len(headers_row))
    rng_disp = f"A3:{last_col_letter}{end_row}"
    grid_disp = ws.get(rng_disp, value_render_option='UNFORMATTED_VALUE') or []
    grid_form = ws.get(rng_disp, value_render_option='FORMULA') or []
    
    if not grid_disp:
        return {'status': 'completed', 'sheet_name': sheet_name, 'updated_links': new_links_count, 'notion_rows': 0}
    
    header = grid_disp[0]
    data_rows_disp = grid_disp[1:]
    data_rows_form = grid_form[1:] if grid_form else []
    
    print(f"  â–¶ [{sheet_name}] Notion ì—…ë¡œë“œ ì‹œì‘ â€” ë°ì´í„° í–‰ ìˆ˜ {len(data_rows_disp)}")
    
    notion_rows = 0
    for r_i, row in enumerate(data_rows_disp):
        if (r_i % LOG_EVERY == 0) and r_i > 0:
            print(f"    Â· Notion ì§„í–‰ {r_i}/{len(data_rows_disp)}")
        
        # ì†Œì¬ëª… ë¹„ë©´ ìŠ¤í‚µ
        if (len(row) < so_idx) or (str(row[so_idx-1]).strip() == ""):
            continue
        
        # ëŒ€ë¶„ë¥˜ ë¹„ë©´ ìŠ¤í‚µ
        if cat_idx:
            if (len(row) < cat_idx) or (str(row[cat_idx-1]).strip() == ""):
                continue
        
        # í–‰ dict êµ¬ì„±
        row_dict = {}
        for cidx, h in enumerate(header, start=1):
            val = row[cidx-1] if len(row) >= cidx else ""
            if cidx == link_idx:
                ff = data_rows_form[r_i][link_idx-1] if (r_i < len(data_rows_form) and len(data_rows_form[r_i]) >= link_idx) else ""
                url_only = extract_hyperlink_url(ff) or (val if looks_like_url(val) else "")
                row_dict[h] = str(url_only)
            else:
                row_dict[h] = str(val if val is not None else "")
        
        # ì¤‘ë³µ ì²´í¬
        current_sojae_name = ""
        for k, v in row_dict.items():
            if nospace_lower(k) == nospace_lower("ì†Œì¬ëª…"):
                current_sojae_name = str(v).strip()
                break
        if current_sojae_name and nospace_lower(current_sojae_name) in existing_sojae_names:
            continue
        
        # Title ê°’: ê³¼ê±°ì†Œì¬ëª… ìš°ì„ 
        title_value = ""
        for k, v in row_dict.items():
            if nospace_lower(k) == nospace_lower('ê³¼ê±°ì†Œì¬ëª…') and str(v).strip():
                title_value = str(v).strip()
                break
        
        properties = {title_prop_name: {"title": notion_rich(title_value)}}
        
        # í”„ë¡œì íŠ¸ ì†ì„±
        if project_prop:
            pname = project_prop["name"]
            ptype = project_prop["type"]
            if ptype == "select":
                properties[pname] = {"select": {"name": sheet_name}}
            elif ptype == "multi_select":
                properties[pname] = {"multi_select": [{"name": sheet_name}]}
            elif ptype == "rich_text":
                properties[pname] = {"rich_text": notion_rich(sheet_name)}
            else:
                try: properties[pname] = coerce_payload(ptype, sheet_name)
                except: properties[pname] = {"rich_text": notion_rich(sheet_name)}
        
        # ë‚˜ë¨¸ì§€ ì—´
        for sh_col_name, val in row_dict.items():
            clean = nospace_lower(sh_col_name)
            if clean in {nospace_lower(title_prop_name), nospace_lower(project_prop["name"]) if project_prop else ""}:
                continue
            meta = prop_by_clean.get(clean) or find_db_prop(prop_by_clean, clean)
            if meta:
                real_name = meta["name"]
                ptype = meta["type"]
                properties[real_name] = coerce_payload(ptype, val)
        
        try:
            notion.pages.create(parent={"database_id": NOTION_DB_ID}, properties=properties)
            if current_sojae_name:
                existing_sojae_names.add(nospace_lower(current_sojae_name))
            notion_rows += 1
        except Exception as e:
            print(f"    â— Notion ì‹¤íŒ¨ r{r_i+DATA_START_ROW} â†’ {e}")
        
        time.sleep(0.35)
    
    if sheet_name in PROJECT_VIEW_URLS:
        print(f"ğŸ”— {sheet_name} ë·°: {PROJECT_VIEW_URLS[sheet_name]}")
    
    print(f"âœ… [{sheet_name}] ì™„ë£Œ - ë§í¬ {new_links_count}ê°œ, Notion {notion_rows}í–‰")
    
    return {
        'status': 'completed',
        'sheet_name': sheet_name,
        'updated_links': new_links_count,
        'notion_rows': notion_rows
    }

def generate_summary_report(**context):
    """ì „ì²´ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
    results = []
    
    for sheet_name in TARGET_SHEETS:
        task_id = f'process_{sheet_name.lower()}'
        result = context['ti'].xcom_pull(task_ids=task_id)
        if result:
            results.append(result)
    
    total_links = sum(r.get('updated_links', 0) for r in results if r.get('status') == 'completed')
    total_notion = sum(r.get('notion_rows', 0) for r in results if r.get('status') == 'completed')
    
    summary = f"""
{'='*60}
ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½
{'='*60}
ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì´ ì‹œíŠ¸ ìˆ˜: {len(TARGET_SHEETS)}
ì²˜ë¦¬ ì™„ë£Œ: {len([r for r in results if r.get('status') == 'completed'])}ê°œ
ë§í¬ ê°±ì‹ : {total_links}ê°œ
Notion ì—…ë¡œë“œ: {total_notion}í–‰

ì‹œíŠ¸ë³„ ìƒì„¸:
"""
    
    for result in results:
        if result:
            summary += f"\n  â€¢ {result.get('sheet_name', 'Unknown')}: "
            summary += f"ë§í¬ {result.get('updated_links', 0)}ê°œ, "
            summary += f"Notion {result.get('notion_rows', 0)}í–‰"
    
    print(summary)
    
    summary_data = {
        'total_sheets': len(TARGET_SHEETS),
        'completed': len([r for r in results if r.get('status') == 'completed']),
        'total_links_updated': total_links,
        'total_notion_rows': total_notion,
        'timestamp': datetime.now().isoformat(),
        'results': results,
        'summary_text': summary
    }
    
    # XComì— ìš”ì•½ ë°ì´í„° ì €ì¥ (ì´ë©”ì¼ ë°œì†¡ìš©)
    context['ti'].xcom_push(key='summary_report', value=summary_data)
    
    return summary_data


def send_summary_email(**context):
    """ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ì´ë©”ì¼ë¡œ ë°œì†¡"""
    import smtplib
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    from email.utils import formatdate
    
    # Airflow Variablesì—ì„œ SMTP ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    try:
        smtp_host = Variable.get('SMTP_HOST', default_var='smtp.gmail.com')
        smtp_port = int(Variable.get('SMTP_PORT', default_var='587'))
        smtp_user = Variable.get('EMAIL_FROM', default_var='ds_bi@joycity.com')
        smtp_password = Variable.get('SMTP_PASSWORD')
        email_from = Variable.get('EMAIL_FROM', default_var=smtp_user)
        email_to = Variable.get('EMAIL_TO', default_var='65e43b85.joycity.com@kr.teams.ms')

    except Exception as e:
        print(f"âš ï¸  SMTP ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ì´ë©”ì¼ ë°œì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {'status': 'skipped', 'reason': 'smtp_config_missing'}
    
    # ìš”ì•½ ë¦¬í¬íŠ¸ ê°€ì ¸ì˜¤ê¸°
    summary_data = context['ti'].xcom_pull(key='summary_report', task_ids='generate_summary_report')
    
    if not summary_data:
        print("â— ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {'status': 'failed', 'reason': 'no_summary_data'}
    
    # ì‹¤í–‰ ë‚ ì§œ
    execution_date = context.get('execution_date', datetime.now())
    date_str = execution_date.strftime('%Y-%m-%d')
    
    # ì´ë©”ì¼ ì œëª©
    total_links = summary_data.get('total_links_updated', 0)
    total_notion = summary_data.get('total_notion_rows', 0)
    completed = summary_data.get('completed', 0)
    total_sheets = summary_data.get('total_sheets', 0)
    
    subject = f"[Creative DB Sync] ì¼ì¼ ë°°ì¹˜ ì™„ë£Œ ({date_str}) - ë§í¬ {total_links}ê°œ, Notion {total_notion}í–‰"
    
    # ì´ë©”ì¼ ë³¸ë¬¸ (HTML)
    results = summary_data.get('results', [])
    
    # ì‹œíŠ¸ë³„ ìƒì„¸ í…Œì´ë¸” ìƒì„±
    sheet_details_html = ""
    for result in results:
        if result:
            status = result.get('status', 'unknown')
            status_emoji = 'âœ…' if status == 'completed' else 'âš ï¸'
            sheet_name = result.get('sheet_name', 'Unknown')
            links = result.get('updated_links', 0)
            notion = result.get('notion_rows', 0)
            
            sheet_details_html += f"""
            <tr>
                <td style="padding: 8px; border: 1px solid #ddd;">{status_emoji} {sheet_name}</td>
                <td style="padding: 8px; border: 1px solid #ddd; text-align: center;">{links}</td>
                <td style="padding: 8px; border: 1px solid #ddd; text-align: center;">{notion}</td>
                <td style="padding: 8px; border: 1px solid #ddd; text-align: center;">{status}</td>
            </tr>
            """
    
    html_body = f"""
    <html>
    <head>
        <style>
            body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }}
            .container {{ max-width: 800px; margin: 0 auto; padding: 20px; }}
            .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                      color: white; padding: 30px; border-radius: 10px 10px 0 0; }}
            .header h1 {{ margin: 0; font-size: 24px; }}
            .header p {{ margin: 5px 0 0 0; opacity: 0.9; }}
            .content {{ background: #ffffff; padding: 30px; border: 1px solid #e0e0e0; }}
            .summary-box {{ background: #f8f9fa; padding: 20px; border-radius: 8px; 
                           margin: 20px 0; border-left: 4px solid #667eea; }}
            .metric {{ display: inline-block; margin: 10px 20px 10px 0; }}
            .metric-value {{ font-size: 32px; font-weight: bold; color: #667eea; }}
            .metric-label {{ font-size: 14px; color: #666; }}
            table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
            th {{ background: #667eea; color: white; padding: 12px; text-align: left; }}
            td {{ padding: 8px; border: 1px solid #ddd; }}
            tr:nth-child(even) {{ background: #f8f9fa; }}
            .footer {{ background: #f8f9fa; padding: 20px; text-align: center; 
                      color: #666; font-size: 12px; border-radius: 0 0 10px 10px; }}
            .success {{ color: #28a745; font-weight: bold; }}
            .warning {{ color: #ffc107; font-weight: bold; }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸ¨ Creative DB Sync ì¼ì¼ ë°°ì¹˜ ë¦¬í¬íŠ¸</h1>
                <p>ì‹¤í–‰ ì¼ì‹œ: {summary_data.get('timestamp', 'N/A')}</p>
            </div>
            
            <div class="content">
                <div class="summary-box">
                    <h2 style="margin-top: 0;">ğŸ“Š ì²˜ë¦¬ ìš”ì•½</h2>
                    <div class="metric">
                        <div class="metric-value">{completed}/{total_sheets}</div>
                        <div class="metric-label">ì‹œíŠ¸ ì²˜ë¦¬ ì™„ë£Œ</div>
                    </div>
                    <div class="metric">
                        <div class="metric-value">{total_links}</div>
                        <div class="metric-label">ë§í¬ ê°±ì‹ </div>
                    </div>
                    <div class="metric">
                        <div class="metric-value">{total_notion}</div>
                        <div class="metric-label">Notion ì—…ë¡œë“œ</div>
                    </div>
                </div>
                
                <h2>ğŸ“‹ ì‹œíŠ¸ë³„ ì²˜ë¦¬ ê²°ê³¼</h2>
                <table>
                    <thead>
                        <tr>
                            <th>í”„ë¡œì íŠ¸</th>
                            <th style="text-align: center;">ë§í¬ ê°±ì‹ </th>
                            <th style="text-align: center;">Notion ì—…ë¡œë“œ</th>
                            <th style="text-align: center;">ìƒíƒœ</th>
                        </tr>
                    </thead>
                    <tbody>
                        {sheet_details_html}
                    </tbody>
                </table>
            </div>
            
            <div class="footer">
                <p>ì´ ë©”ì¼ì€ Airflow DAGì—ì„œ ìë™ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
            </div>
        </div>
    </body>
    </html>
    """
    
    # í”Œë ˆì¸ í…ìŠ¤íŠ¸ ë³¸ë¬¸ (HTML ë¯¸ì§€ì› í´ë¼ì´ì–¸íŠ¸ìš©)
    plain_body = summary_data.get('summary_text', 'ìš”ì•½ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
    
    # ì´ë©”ì¼ ë©”ì‹œì§€ ìƒì„±
    msg = MIMEMultipart('alternative')
    msg['Subject'] = subject
    msg['From'] = email_from
    msg['To'] = ', '.join(email_to)
    msg['Date'] = formatdate(localtime=True)
    
    # ë³¸ë¬¸ ì¶”ê°€
    part1 = MIMEText(plain_body, 'plain', 'utf-8')
    part2 = MIMEText(html_body, 'html', 'utf-8')
    msg.attach(part1)
    msg.attach(part2)
    
    # SMTP ë°œì†¡
    try:
        print(f"ğŸ“§ ì´ë©”ì¼ ë°œì†¡ ì¤‘... (ë°›ëŠ” ì‚¬ëŒ: {', '.join(email_to)})")
        
        server = smtplib.SMTP(smtp_host, smtp_port)
        server.ehlo()
        server.starttls()
        server.ehlo()
        server.login(smtp_user, smtp_password)
        server.sendmail(email_from, email_to, msg.as_string())
        server.quit()
        
        print(f"âœ… ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ!")
        return {
            'status': 'success',
            'recipients': email_to,
            'subject': subject,
            'timestamp': datetime.now().isoformat()
        }
        
    except smtplib.SMTPAuthenticationError:
        print("â— SMTP ì¸ì¦ ì‹¤íŒ¨: ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return {'status': 'failed', 'reason': 'authentication_failed'}
    except smtplib.SMTPException as e:
        print(f"â— SMTP ì˜¤ë¥˜: {e}")
        return {'status': 'failed', 'reason': str(e)}
    except Exception as e:
        print(f"â— ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")
        return {'status': 'failed', 'reason': str(e)}


# =====================
# DAG íƒœìŠ¤í¬ ì •ì˜
# =====================

# 1. í™˜ê²½ ê²€ì¦
task_check_deps = PythonOperator(
    task_id='check_dependencies',
    python_callable=check_dependencies,
    dag=dag,
)

# 2. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
task_init_clients = PythonOperator(
    task_id='initialize_clients',
    python_callable=initialize_clients,
    dag=dag,
)

# 3. Notion ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
task_fetch_schema = PythonOperator(
    task_id='fetch_notion_schema',
    python_callable=fetch_notion_schema,
    dag=dag,
)

# 4. ê° ì‹œíŠ¸ë³„ ë³‘ë ¬ ì²˜ë¦¬
sheet_tasks = []
for sheet in TARGET_SHEETS:
    task = PythonOperator(
        task_id=f'process_{sheet.lower()}',
        python_callable=process_sheet,
        op_kwargs={'sheet_name': sheet},
        # # Poolì„ ì‚¬ìš©í•œ ë™ì‹œ ì‹¤í–‰ ì œí•œ
        # pool='sheets_api_pool',  # ë¯¸ë¦¬ ìƒì„± í•„ìš”
        # pool_slots=2,
        
        # # ì¬ì‹œë„ ì„¤ì •
        # retries=5,
        # retry_delay=timedelta(seconds=30),
        # retry_exponential_backoff=True,
        # max_retry_delay=timedelta(minutes=15),
        dag=dag,
    )
    sheet_tasks.append(task)

# 5. ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸
task_summary = PythonOperator(
    task_id='generate_summary_report',
    python_callable=generate_summary_report,
    dag=dag,
)

# 6. ì´ë©”ì¼ ë°œì†¡
task_send_email = PythonOperator(
    task_id='send_summary_email',
    python_callable=send_summary_email,
    dag=dag,
)

bash_task = BashOperator(
    task_id = 'bash_task',
    outlets = [gcs_creative_file_upload],
    bash_command = 'echo "gcs_creative_file_upload ì™„ë£Œ!"',
    dag=dag,
)

# =====================
# DAG ì˜ì¡´ì„± ì„¤ì •
# =====================
task_check_deps >> task_init_clients >> task_fetch_schema >> sheet_tasks >> task_summary >> task_send_email >> bash_task