import time
import pandas as pd
from google.cloud import bigquery
from google import genai
from google.genai import types
from google.cloud import storage
import vertexai
from google.genai import Client
from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore

# ì¸ì¦ê´€ë ¨
import google.auth
from google.auth.transport.requests import Request
import logging

# ê·¸ë˜í”„ ê´€ë ¨ íŒ¨í‚¤ì§€
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter, StrMethodFormatter, PercentFormatter, MultipleLocator
import matplotlib as mpl
import matplotlib.font_manager as fm
from matplotlib import cm
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont # 2ê°€ì§€ íŒŒì¼ í•©ì¹˜ê¸°
import matplotlib.dates as mdates
import nest_asyncio
from jinja2 import Template
from playwright.async_api import async_playwright
import asyncio
import IPython.display as IPd
from bs4 import BeautifulSoup
from io import BytesIO
from typing import List, Tuple
from matplotlib import rcParams
from matplotlib.patches import Rectangle

# ì „ì²˜ë¦¬ ê´€ë ¨ íŒ¨í‚¤ì§€
import numpy as np
import re
import os 
import math
import time
import pandas as pd
from notion_client import Client
import requests
import json
from datetime import datetime, timezone, timedelta
from adjustText import adjust_text
from airflow.models import Variable
from airflow.operators.python import get_current_context
from zoneinfo import ZoneInfo  # Python 3.9 ì´ìƒ
from pathlib import Path
from game_framework_util import *


## ì¼ìë³„ ë§¤ì¶œ
def Daily_revenue_query(joyplegameid: int, bigquery_client, **context):
    query = f"""

    select day
    , cast(sum(if(monthtype = 'ì§€ë‚œë‹¬' , pricekrw, null ))as int64) as `ì§€ë‚œë‹¬`
    , cast(sum(if(monthtype = 'ì´ë²ˆë‹¬' , pricekrw, null ))as int64) as `ì´ë²ˆë‹¬`

    from
    (select *
    , format_date('%Y-%m',  logdatekst ) as Month
    , case when logdatekst >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH), INTERVAL 1 MONTH)
    and logdatekst< DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH) then 'ì§€ë‚œë‹¬'
    when logdatekst >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst <= LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH) then 'ì´ë²ˆë‹¬'
    else 'etc' end as monthtype
    , format_date('%d',  logdatekst ) as day
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdateKst>= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH), INTERVAL 1 MONTH)
    #and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )
    group by 1
    order by 1

    """
    query_result = query_run_method('1_daily_sales', bigquery_client, query)
    # âœ… get_current_context()ë¡œ context ê°€ì ¸ì˜¤ê¸°
    current_context = get_current_context()
    current_context['task_instance'].xcom_push(key='daily_revenue_df', value=query_result)

    return True
    
    
#### ì „ë…„ ëŒ€ë¹„ ì›” ë§¤ì¶œ ì¶”ì´
def Daily_revenue_YOY_query(joyplegameid: int, bigquery_client, **context):
    query = f"""

    select month
    , cast(sum(if(yeartype = 'ì‘ë…„' , pricekrw, null ))as int64) as `ì‘ë…„`
    , cast(sum(if(yeartype = 'ì˜¬í•´' , pricekrw, null ))as int64) as `ì˜¬í•´`

    from
    (select *
    , case
    when logdatekst >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR), INTERVAL 1 YEAR)
    and logdatekst< DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR) then 'ì‘ë…„'

    when logdatekst >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR)
    and logdatekst <= LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR) then 'ì˜¬í•´'
    else 'etc' end as yeartype
    , format_date('%m',  logdatekst ) as month
    , format_date('%Y',  logdatekst ) as year

    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdateKst>= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR), INTERVAL 1 YEAR)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR)
    )
    group by 1
    order by 1

    """
    query_result = query_run_method('1_daily_sales', bigquery_client, query)

    current_context = get_current_context()
    current_context['task_instance'].xcom_push(key='Daily_revenue_YOY_df', value=query_result)

    return True


## í˜„ì¬ ë§¤ì¶œê³¼ ëª©í‘œ ë§¤ì¶œ
def Daily_revenue_target_revenue_query(joyplegameid: int, gameidx: str, bigquery_client, **context):
    query = f"""
    ### 1> ì´ë²ˆë‹¬ ì¼ìë³„ ë§¤ì¶œ ì‹¤ì¸¡ì¹˜
    with thismonthRev as (
    select day ## ì¼ì
    , lastDay ## ì´ë²ˆë‹¬ ë§ˆì§€ë§‰ë‚  (ex - 30)
    , sum(pricekrw) as rev ## ë§¤ì¶œì•¡
    from
    (select *
    , cast(format_date('%d',  logdatekst ) as int64) as day ## ì¼ì
    , EXTRACT(DAY FROM LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)) as lastDay
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY)
    )
    group by day,lastDay
    order by day
    ),

    ### 2> ëª©í‘œë§¤ì¶œ í…Œì´ë¸”
    salesGoal as (
    select
        CAST(REPLACE(sales, ',', '') AS INT64) as salesGoalMonthly # ì‰¼í‘œ í¬í•¨í•œ string í˜•íƒœë¡œ ì ì¬ë˜ì–´ìˆì–´ì„œ int64 í˜•íƒœë¡œ ì „ì²˜ë¦¬
    , CAST(REPLACE(sales, ',', '') AS INT64)/cast(num_of_days as int64) as salesGoalDaily # ì¼í‰ê·  ëª©í‘œë§¤ì¶œ
    from `data-science-division-216308.gameInsightFramework.slgMonthlyGoal`
    where idx = '{gameidx}'
    and month = FORMAT_DATE('%Y-%m', DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
    ),

    ### 3> í•©ì¹˜ê¸°
    thismonthRev2 as (


    select
        a.day, a.lastDay, a.rev
    , b.salesGoalDaily
    , c.maxDay ## ì´ë²ˆë‹¬ ë©°ì¹ ê¹Œì§€ ê¸°ê°„ ì°¼ëŠ”ì§€
    #, case when maxDay >5 then rev ## 5ì¼ì¹˜ ì´ìƒì˜ ë§¤ì¶œì´ ìˆìœ¼ë©´ ê·¸ëƒ¥ ì¼í• ê³„ì‚°
    #       when maxDay<=5 and day=1 then salesGoalDaily ## 5ì¼ì¹˜ ì´í•˜ì˜ ë§¤ì¶œë§Œ ìˆë‹¤ë©´ , 1ì¼ì ë§¤ì¶œì„ ë³´ì •ì¹˜ ì ìš©
    #       else rev end as rev2
    , a.rev as rev2
    from
    ## ì¼ìë³„ ë§¤ì¶œ ì‹¤ì¸¡
    (select * from thismonthRev) as a

    ## ëª©í‘œë§¤ì¶œ (ì›”ë³„, ì¼ë³„)
    cross join
    (select *
    from salesGoal
    ) as b

    ## í˜„ì¬ ë©°ì¹ ê¹Œì§€ ë§¤ì¶œ ìˆëŠ”ì§€ -> 5ì¼ ì´ì „ì¸ì§€ ì´í›„ì¸ì§€ í™•ì¸ìš©ë„
    cross join
    (select cast(max(day) as int64) as maxDay from thismonthRev) as c

    )

    #select * from thismonthRev_and_revGoal order by day

    ### 4> ì „ì²˜ë¦¬
    select cast(current_sales as int64) as current_sales, b.salesGoalMonthly
    from
    (select (rev/maxDay)*lastDay as current_sales
    from
    (select sum(rev2) as rev, max(maxDay) as maxDay, max(lastDay) as lastDay
    from thismonthRev2)
    ) as a
    cross join
    (select * from salesGoal) as b

    """

    query_result = query_run_method('1_daily_sales', bigquery_client, query)
    
    current_context = get_current_context()
    current_context['task_instance'].xcom_push(key='Daily_revenue_target_revenue_df', value=query_result)

    return True


## ì „ë…„ ëŒ€ë¹„ ì›” ë§¤ì¶œ ì¶”ì´ ìˆ˜ì • - ë‹¹ì›”ì€ ì¼í• ê³„ì‚° ë§¤ì¶œ
def merge_daily_revenue(**context):

    current_context = get_current_context()

    s_total = current_context['task_instance'].xcom_pull(
        task_ids = 'Daily_revenue_query',
        key='daily_revenue_df'
    )
    val_total = current_context['task_instance'].xcom_pull(
        task_ids = 'Daily_revenue_YOY_query',
        key='Daily_revenue_YOY_df'
    )

    # âœ… ë°ì´í„° ê²€ì¦
    print(f"ğŸ“Š s_total type: {type(s_total)}, val: {s_total}")
    print(f"ğŸ“Š val_total type: {type(val_total)}, val: {val_total}")
    
    val = val_total.iat[0, 0]
    s = s_total.iloc[:, 2]
    try:
        idx = s.dropna().index[-1]                 # ë§ˆì§€ë§‰ non-null ë¼ë²¨ ì¸ë±ìŠ¤
        s_total.loc[idx, s_total.columns[2]] = val
    except IndexError:
        pass  # ëª¨ë‘ nullì¸ ê²½ìš°

    return s_total


## í”„ë¡¬í”„íŠ¸ 
### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸
def daily_revenue_gemini(service_sub: str, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION:list, **context):

    current_context = get_current_context()

    query_result1_dailySales = current_context['task_instance'].xcom_pull(
        task_ids = 'Daily_revenue_query',
        key='daily_revenue_df'
    )

    query_result1_monthlySales = current_context['task_instance'].xcom_pull(
        task_ids = 'Daily_revenue_YOY_query',
        key='Daily_revenue_YOY_df'
    )

    RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
    LABELS = {"datascience_division_service": 'gameinsight_framework',
            "run_id": RUN_ID,
            "datascience_division_service_sub" : service_sub}

    response1_salesComment = genai_client.models.generate_content(
    model=MODEL_NAME,
    contents = f"""
    ë‹¹ì›” ë§¤ì¶œì€ ì¼í• ê³„ì‚°ì‹œ {f"{int((query_result1_monthlySales.iat[0,0])):,}"}ì´ê³  ëª©í‘œëŠ” {f"{int((query_result1_monthlySales.iat[0,1])):,}"}ì´ì•¼.
    ë‹¹ì›” ë§¤ì¶œì€ ì¼í• ê³„ì‚°ì‹œ ~~ì´ê³  ëª©í‘œë§¤ì¶œì€ ~~ ìœ¼ë¡œ, ëª©í‘œëŒ€ë¹„ ì–¼ë§ˆ ë‹¬ì„±í–ˆë‹¤ì˜ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.
    ê·¸ë¦¬ê³  ì¶”ê°€ë¡œ ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•´ ì•„ì£¼ ê°„ë‹¨íˆ ì½”ë©˜íŠ¸ë¥¼ í•´ì¤˜.
    ~ìŠµë‹ˆë‹¤ ì²´ë¡œ ì•Œë ¤ì¤˜

    ê·¸ë¦¬ê³  ì „ë…„ë™ì›”ëŒ€ë¹„ì–´ë–¤ì§€ 3ì¤„ì´ë‚´ë¡œ ê°„ë‹¨íˆ ì•Œë ¤ì¤˜.

    ì•ìœ¼ë¡œ ì–´ë–»ê²Œ í•´ì•¼ê² ë‹¤ëŠ” ì‚¬ê²¬ì€ ì“°ì§€ë§ˆ.
    í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.
    <ì¼ìë³„ ì´ ë§¤ì¶œ>
    {query_result1_dailySales}

    < ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ>
    {query_result1_monthlySales}
    """,
    config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
            # tools=[RAG],
            temperature=0.5,
            labels=LABELS
        )

    )
    # ì½”ë©˜íŠ¸ ì¶œë ¥
    return response1_salesComment.text

# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

# ## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
# font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
# if Path(font_path).exists():
#     fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
#     mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
#     mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
# else:
#     print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

## ê·¸ë˜í”„ ê·¸ë¦¬ê¸° : arg ê°’ìœ¼ë¡œ ê²Œì„ ì½”ë“œ
def daily_revenue_graph_draw(gameidx: str, bucket, **context):

    current_context = get_current_context()

    df_daily = current_context['task_instance'].xcom_pull(
        task_ids='daily_revenue_query',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='daily_revenue_df'
    )
    
    x  = df_daily.iloc[:, 0]
    y1 = pd.to_numeric(df_daily.iloc[:, 1], errors='coerce')
    y2 = pd.to_numeric(df_daily.iloc[:, 2], errors='coerce')

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(x, y2, marker='o',
            markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
            label=df_daily.columns[2])
    ax.plot(x, y1, marker='o',
            markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
            linestyle='--', label=df_daily.columns[1])  # ê²¹ì³ì„œ í‘œì‹œ

    # ì˜µì…˜
    plt.title("ì¼ìë³„ ë§¤ì¶œ")
    #plt.xlabel(query_result1_dailySales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
    #plt.ylabel(query_result1_dailySales.columns[1])

    # yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

    # xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
    plt.xticks(df_daily[df_daily.columns[0]][::2], rotation=45)

    # ë²”ë¡€ í‘œì‹œ - ê·¸ë˜í”„ë‘ ì•ˆê²¹ì¹˜ê²Œ
    plt.legend(
        bbox_to_anchor=(1.05, 1),   # ê·¸ë˜í”„ ì˜¤ë¥¸ìª½ ë°”ê¹¥ (x=1.05, y=1)
        loc='upper left',           # ì•µì»¤ ê¸°ì¤€ ìœ„ì¹˜
        borderaxespad=0.             # ì¶•ê³¼ ê°„ê²©
    )

    # yì¶• 0ë¶€í„° ì‹œì‘ (ì•ˆí•˜ë©´ ëˆˆê¸ˆ ìµœì†Œê°’ ìì¢… ì¡°ì •)
    plt.ylim(0, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§

    # yì¶• ë³´ì¡°ì„ 
    plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„
    #plt.grid(axis='x', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

    #plt.xlabel("ë‚ ì§œ")
    #plt.ylabel("ë§¤ì¶œ")

    #plt.show()
    # ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
    plt.tight_layout()


    # í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
    # #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
    # ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
    ####################################### ì´ë¯¸ì§€ íŒŒì¼ì„ ì €ì¥í•  pathê°€ í•„ìš”í•¨ #####################
    filepath1_dailySales = "graph1_dailySales.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'


## ì›”ê°„ ë§¤ì¶œ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
def daily_revenue_YOY_graph_draw(gameidx: str, bucket, **context):

    current_context = get_current_context()

    query_result1_monthlySales = current_context['task_instance'].xcom_pull(
        task_ids='Daily_revenue_YOY_query',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='Daily_revenue_YOY_df'
    )

    x  = query_result1_monthlySales.iloc[:, 0]
    y1 = pd.to_numeric(query_result1_monthlySales.iloc[:, 1], errors='coerce')
    y2 = pd.to_numeric(query_result1_monthlySales.iloc[:, 2], errors='coerce')

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(x, y2, marker='o',
            markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
            label=query_result1_monthlySales.columns[2])
    ax.plot(x, y1, marker='o',
            markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
            linestyle='--', label=query_result1_monthlySales.columns[1])  # ê²¹ì³ì„œ í‘œì‹œ

    # ì˜µì…˜
    plt.title("ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ")
    #plt.xlabel(query_result1_monthlySales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
    #plt.ylabel(query_result1_monthlySales.columns[1])

    # yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

    # xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
    plt.xticks(query_result1_monthlySales[query_result1_monthlySales.columns[0]][::1], rotation=45)

    # ë²”ë¡€ í‘œì‹œ - ê·¸ë˜í”„ë‘ ì•ˆê²¹ì¹˜ê²Œ
    plt.legend(
        bbox_to_anchor=(1.05, 1),   # ê·¸ë˜í”„ ì˜¤ë¥¸ìª½ ë°”ê¹¥ (x=1.05, y=1)
        loc='upper left',           # ì•µì»¤ ê¸°ì¤€ ìœ„ì¹˜
        borderaxespad=0.             # ì¶•ê³¼ ê°„ê²©
    )

    # y ì¶• ì¡°ì • (20ì–µë¶€í„°)
    plt.ylim(2000000000, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§

    # yì¶• ë³´ì¡°ì„ 
    plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„
    #plt.grid(axis='x', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

    #plt.xlabel("month")
    #plt.ylabel("ë§¤ì¶œ")

    #plt.show()
    # ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
    plt.tight_layout()


    # í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
    # #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
    # ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
    filePath1_monthlySales = "graph1_monthlySales.png"
    plt.savefig(filePath1_monthlySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filePath1_monthlySales}')
    blob.upload_from_filename(filePath1_monthlySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filePath1_monthlySales)

    return f'{gameidx}/{filePath1_monthlySales}'



# 1) íŒŒì¼ ê²½ë¡œ
def merge_daily_graph(joyplegameid: int, gameidx: str, bucket):
    p1 = daily_revenue_graph_draw(joyplegameid, gameidx)
    p2 = daily_revenue_YOY_graph_draw(joyplegameid, gameidx)

    # 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
    blob1 = bucket.blob(p1)
    blob2 = bucket.blob(p2)

    im1 = blob1.download_as_bytes()
    im2 = blob2.download_as_bytes()

    im1 = Image.open(BytesIO(im1))
    im2 = Image.open(BytesIO(im2))

    # ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
    target_h = max(im1.height, im2.height)

    def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas

    im1_p = pad_to_height(im1, target_h)
    im2_p = pad_to_height(im2, target_h)

    gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
    bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

    out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
    out.paste(im1_p, (0, 0), im1_p)
    out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

    # 3) GCSì— ì €ì¥
    output_buffer = BytesIO()
    out.save(output_buffer, format='PNG')
    output_buffer.seek(0)

    # GCS ê²½ë¡œ
    gcs_path = f'{gameidx}/graph1_dailySales_monthlySales.png'
    blob = bucket.blob(gcs_path)
    blob.upload_from_string(output_buffer.getvalue(), content_type='image/png')

    return gcs_path


def daily_revenue_data_upload_to_notion(gameidx: str, service_sub, genai_client, MOEDEL_NAME, SYSTEM_INSTRUCTION, notion, bucket, headers_json, **context):

    current_context = get_current_context()

    PAGE_INFO=current_context['task_instance'].xcom_pull(
        task_ids = 'make_gameframework_notion_page',
        key='page_info'
    )
    query_result1_dailySales=current_context['task_instance'].xcom_pull(
        task_ids='daily_revenue_query',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='daily_revenue_df'
    )

    query_result1_monthlySales=current_context['task_instance'].xcom_pull(
        task_ids='Daily_revenue_YOY_query',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='Daily_revenue_YOY_df'
    )

    notion.blocks.children.append(
        PAGE_INFO["id"],
        children=[
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "\n\n1. ì¼ìë³„ ë§¤ì¶œ" }}]
                },
            }
        ],
    )

    gcs_path = f'{gameidx}/graph1_dailySales_monthlySales.png'
    blob = bucket.blob(gcs_path)
    image_bytes = blob.download_as_bytes()
    filename = 'graph1_dailySales_monthlySales.png'

    ########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
    # ì¼ìë³„ ë§¤ì¶œ
    # ê·¸ë˜í”„ëŠ” íŒŒì¼ ì €ì¥í›„ ì˜¬ë¦¬ëŠ” êµ¬ì¡°ë°–ì— ë˜ì§€ì•Šì•„ì„œ
    # 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
    create_url = "https://api.notion.com/v1/file_uploads"
    payload = {
        "filename": filename,
        "content_type": "image/png"
    }
    headers_json = headers_json
    resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
    resp.raise_for_status()
    file_upload = resp.json()
    file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
    upload_url = file_upload[upload_url]

    # 2) ì´ë¯¸ì§€ ì—…ë¡œë“œ
    headers_upload = {
        "Content-Type": "image/png"
    }
    requests.put(upload_url, headers=headers_upload, data=image_bytes)

    # file_upload["upload_url"] ë„ ì‘ë‹µì— í¬í•¨ë¨
    # 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data)
    send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
    files = {"file": (filename, BytesIO(image_bytes), "image/png")}
    headers_send = headers_json

    send_resp = requests.post(send_url, headers=headers_send, files=files)
    send_resp.raise_for_status()

    # 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
    append_url = f"https://api.notion.com/v1/blocks/{file_upload_id}/children"
    append_payload = {
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "file_upload",
                    "file_upload": {"id": file_upload_id},
                    # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
                }
            }
        ]
    }

    headers_json_patch = headers_json
    append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
    append_resp.raise_for_status()

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO["id"],
        df=query_result1_dailySales,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¼ìë³„ ë§¤ì¶œ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO["id"],
        df=query_result1_monthlySales,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    response1_salesComment = daily_revenue_gemini(service_sub, genai_client, MOEDEL_NAME, SYSTEM_INSTRUCTION)

    ## ì œë¯¸ë‚˜ì´
    blocks = md_to_notion_blocks(response1_salesComment)
    notion.blocks.children.append(
        block_id=PAGE_INFO["id"],
        children=blocks
    )

    return True



