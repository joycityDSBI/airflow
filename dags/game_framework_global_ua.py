import pandas as pd
from google.cloud import bigquery
from google import genai
from google.genai import types
from google.cloud import storage

# ê·¸ë˜í”„ ê´€ë ¨ íŒ¨í‚¤ì§€
from io import BytesIO
from typing import List, Tuple

# ì „ì²˜ë¦¬ ê´€ë ¨ íŒ¨í‚¤ì§€
import numpy as np
import os 
import time
from notion_client import Client
import requests
import json
from datetime import datetime, timezone, timedelta
from airflow.operators.python import get_current_context
from airflow.sdk import get_current_context
from game_framework_util import load_df_from_gcs, save_df_to_gcs, query_run_method, df_to_notion_table_under_toggle, md_to_notion_blocks

PROJECT_ID = "data-science-division-216308"
LOCATION = "us-central1"



def _setup_matplotlib_and_fonts():
    """matplotlib ë° í°íŠ¸ ì„¤ì • (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œë§Œ import)"""
    import matplotlib.pyplot as plt
    import seaborn as sns
    import matplotlib as mpl
    import matplotlib.font_manager as fm
    from matplotlib.ticker import FuncFormatter, StrMethodFormatter, PercentFormatter, MultipleLocator
    import matplotlib.dates as mdates
    from matplotlib import rcParams
    from matplotlib.patches import Rectangle
    
    # í°íŠ¸ ì„¤ì • (ì—¬ê¸°ì„œë§Œ ì‹¤í–‰)
    plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP', 'DejaVu Sans', 'Noto Sans']
    plt.rcParams['font.size'] = 10
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['lines.linewidth'] = 1.5
    
    print("âœ“ Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ")
    
    return {
        'plt': plt,
        'sns': sns,
        'mpl': mpl,
        'fm': fm,
        'FuncFormatter': FuncFormatter,
        'StrMethodFormatter': StrMethodFormatter,
        'PercentFormatter': PercentFormatter,
        'MultipleLocator': MultipleLocator,
        'mdates': mdates,
    }

def _setup_image_libs():
    """ì´ë¯¸ì§€ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬"""
    from PIL import Image, ImageDraw, ImageFont
    from io import BytesIO
    
    return {
        'Image': Image,
        'ImageDraw': ImageDraw,
        'ImageFont': ImageFont,
        'BytesIO': BytesIO,
    }

## ì´ë²ˆë‹¬ ê°€ì… ìœ ì €ì˜ êµ­ê°€ë³„ ë§¤ì¶œ
def cohort_by_country_revenue(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):
    query = f"""
    with countryRev as (
    select country2 as country, rev_rank2 as rev_rank, sum(rev) as rev
    from
    (select country, rev
    , case when rev_rank <= 9 then country  when rev_rank > 9 then 'etc' end as country2 # rev ê¸°ì¤€ 10ìœ„ë¶€í„°ëŠ” etc ë¡œ í‘œê¸°
    , case when rev_rank <= 9 then rev_rank when rev_rank > 9 then 10 end as rev_rank2
    from
    (select country, rev, row_number() OVER (ORDER BY rev desc ) AS rev_rank # rev ìˆœì„œëŒ€ë¡œ ë­í¬
    from
    (select countrycode as country, cast(sum(pricekrw) as int64) as rev
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    group by 1)
    )
    )
    group by 1,2
    order by rev_rank # etc êµ­ê°€ê°€ ë§¨ ë’¤ë¡œ ê°€ì•¼í•¨
    ),

    allRev as  (
    select cast(sum(pricekrw) as int64) as rev
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )

    select a.*, safe_divide(a.rev,b.rev) as rev_percent
    from
    (select * from countryRev ) as a
    cross join
    (select * from allRev) as b
    order by rev_rank

    """
    query_result=query_run_method(service_sub='3_global_ua',bigquery_client=bigquery_client, query=query)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    gcs_path = f"{gameidx}/{timestamp}.parquet"
        
    saved_path = save_df_to_gcs(query_result, bucket, gcs_path)
    
    return saved_path

## ì´ë²ˆë‹¬ êµ­ê°€ë³„ COST
def cohort_by_country_cost(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):
    query = f"""
    with countryCost as (
    select country2 as country, cost_rank2 as cost_rank, sum(cost) as cost
    from
    (select country, cost
    , case when cost_rank <= 9 then country when cost_rank > 9 then 'etc' end as country2 # cost ìˆœì„œëŒ€ë¡œ 10ìœ„ ë¶€í„°ëŠ” etc ë¡œ
    , case when cost_rank <= 9 then cost_rank else 10 end as cost_rank2
    from
    (select country, cost, row_number() OVER (ORDER BY cost desc ) AS cost_rank # cost ìˆœì„œë¡œ rank
    from
    (select countrycode as country, cast(sum(cost) as int64) cost
    from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
    where joyplegameid = {joyplegameid}
    and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    group by countrycode))
    )
    group by 1,2
    order by cost_rank # etc êµ­ê°€ê°€ ë§¨ ë’¤ë¡œ ê°€ì•¼í•¨
    ),

    allCost as (
    select cast(sum(cost) as int64) cost
    from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
    where joyplegameid = {joyplegameid}
    and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )

    select a.*, safe_divide(a.cost,b.cost) as cost_percent
    from
    (select * from countryCost) as a
    cross join
    (select * from allCost) as b
    order by cost_rank


    """
    query_result =query_run_method(service_sub='3_global_ua',bigquery_client=bigquery_client, query=query)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    gcs_path = f"{gameidx}/{timestamp}.parquet"
        
    saved_path = save_df_to_gcs(query_result, bucket, gcs_path)
    
    return saved_path


## êµ­ê°€ë³„ rev, cost í”„ë¡¬í”„íŠ¸
### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸
def cohort_by_gemini(gameidx:str, service_sub: str, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION:list, path_daily_revenue, path_monthly_revenue, bucket, PROJECT_ID, LOCATION, **context):
    
    from google.genai import Client
    genai_client = Client(vertexai=True,project=PROJECT_ID,location=LOCATION)

    cohort_country_revenue = load_df_from_gcs(bucket, path_daily_revenue)
    cohort_country_cost = load_df_from_gcs(bucket, path_monthly_revenue)

    RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
    LABELS = {"datascience_division_service": 'gameinsight_framework',
            "run_id": RUN_ID,
            "datascience_division_service_sub" : service_sub}

    #client = genai.Client(api_key="AIzaSyAVv2B6DM6w9jd1MxiP3PbzAEMkl97SCGY")
    response3_revAndCostByCountry = genai_client.models.generate_content(
    model=MODEL_NAME,
    contents = f"""
    ì´ë²ˆë‹¬ì— ì–´ë–¤ êµ­ê°€ì— ë§ˆì¼€íŒ…í–ˆê³ , ì–´ë–¤ êµ­ê°€ì—ì„œ ì‹ ê·œìœ ì €ì˜ ë§¤ì¶œì´ ë‚˜ì™”ëŠ”ì§€ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì¤„ê²Œ.
    ê°„ë‹¨í•˜ê²Œ í˜„í™© ìš”ì•½í•´ì¤˜.

    ë‹¹ì›” ë§ˆì¼€íŒ…ë¹„ìš©ì€ ì–¼ë§ˆì´ë©° ë‹¹ì›” ì‹ ê·œìœ ì € ë§¤ì¶œì€ ì–¼ë§ˆì…ë‹ˆë‹¤ë¥¼ ë¨¼ì € í•œì¤„ë¡œ ì„œë‘ì— ì–¸ê¸‰í•´ì¤˜.
    ì´ë²ˆë‹¬ COSTë§ì´ ì“´ êµ­ê°€ë“¤ ê°ê° COST ë¹„ì¤‘ì´ ëª‡% ì¸ì§€ í•œì¤„ì— ì¨ì£¼ê³ ,
    ì‹ ê·œìœ ì € ë§¤ì¶œ ë†’ì€ êµ­ê°€ë“¤ ê°ê° ëª‡% ë§¤ì¶œ ë¹„ì¤‘ì¸ì§€ í•œì¤„ì— ì¨ì¤˜ ì•Œë ¤ì¤˜.
    ê·¸ë¦¬ê³  ì£¼ìš” êµ­ê°€ë“¤ì— ëŒ€í•´ì„œ COST ë¹„ì¤‘ê³¼ ë§¤ì¶œë¹„ì¤‘ì„ ë¹„êµí•´ì„œ íŠ¹ì´í•œì ì´ ìˆëŠ”ê²ƒë§Œ ì•Œë ¤ì¤˜.

    ë§¤ì¶œê³¼ COST ì˜ ì•¡ìˆ˜ ì ˆëŒ“ê°’ì„ ë¹„êµí•˜ì§€ ë§ê³  ë¹„ì¤‘ì„ ë¹„êµí•´ì¤˜.
    etc ëŠ” ê¸°íƒ€ êµ­ê°€ë“¤ ì´ í•© í•œ ê°’ì´ë¼ì„œ etc ì— ëŒ€í•´ì„œëŠ” ì–¸ê¸‰í•˜ì§€ ë§ì•„ì¤˜.
    ë§ˆì¼€íŒ… íš¨ìœ¨ê°œì„ ì´ í•„ìš”í•˜ë‹¤ëŠ”ë§ì€ í•˜ì§€ë§ì•„ì¤˜.

    <ì›í•˜ëŠ” ì„œì‹>
    1. ìš”ì•½í•´ì£¼ê² ë‹¤ ë§ í•˜ì§€ë§ê³  ìš”ì•½í•œ ë‚´ìš©ì— ëŒ€í•´ì„œë§Œ ì ì–´ì£¼ë©´ ë¼.
    2. ìŠµë‹ˆë‹¤. ì²´ë¡œ ì¨ì¤˜
    3. í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.

    <ë°ì´í„° ì„¤ëª…>
    ë§¤ì¶œì´ë‘ ë§ˆì¼€íŒ… ë¹„ìš©ì´ë‘ ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ 9ê°œ êµ­ê°€ì™€ ê·¸ ì´í›„ 10ë²ˆì§¸ êµ­ê°€ë¶€í„°ëŠ” ì „ë¶€ etc êµ­ê°€ë¡œ ì²˜ë¦¬í–ˆì–´.
    etc ëŠ” êµ­ê°€ê°€ ì•„ë‹ˆë¼ ë‚˜ë¨¸ì§€ êµ­ê°€ ì´í•©ì´ì•¼.

    <ì´ë²ˆë‹¬ ê°€ì…ìœ ì €ì˜ êµ­ê°€ë³„ ë§¤ì¶œ>
    {cohort_country_revenue}

    <ì´ë²ˆë‹¬ êµ­ê°€ë³„ ë§ˆì¼€íŒ… ë¹„ìš©>
    {cohort_country_cost}

    """,
    config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
            # tools=[RAG],
            temperature=0.5,
            labels=LABELS
        )
    )

    # GCSì— ì—…ë¡œë“œ
    print("ğŸ“¤ GCSì— ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸ ì—…ë¡œë“œ ì¤‘...")
    gcs_response_path = f"{gameidx}/response3_revAndCostByCountry.text"
    blob = bucket.blob(gcs_response_path)
    blob.upload_from_string(
        response3_revAndCostByCountry.text,
        content_type='text/markdown; charset=utf-8'
    )

    # ì½”ë©˜íŠ¸ ì¶œë ¥
    return response3_revAndCostByCountry.text


# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

## OSë³„ ë§¤ì¶œ
def os_rev(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):
    query = f"""
    with osRev as (

    select os, rev from (
    select os, cast(sum(pricekrw) as int64) as rev
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    group by 1)
    where rev>0
    ),

    allRev as (
    select cast(sum(pricekrw) as int64) as rev
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )

    select a.*, safe_divide(a.rev,b.rev) as rev_percent
    from
    (select * from osRev) as a
    cross join
    (select * from allRev) as b
    """
    ## 129.93MB
    query_result = query_run_method('3_global_ua', bigquery_client, query)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    gcs_path = f"{gameidx}/{timestamp}.parquet"
        
    saved_path = save_df_to_gcs(query_result, bucket, gcs_path)

    return saved_path


## OSë³„ cost
def os_cost(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):
    query = f"""
    with osCost as (
    select os, cast(sum(cost) as int64) cost
    from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
    where joyplegameid = {joyplegameid}
    and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    group by os
    ),

    allCost as (
    select cast(sum(cost) as int64) cost
    from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
    where joyplegameid = {joyplegameid}
    and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )

    select a.*, safe_divide(a.cost,b.cost) as cost_percent
    from
    (select * from osCost) as a
    cross join
    (select * from allCost) as b
    """
    query_result = query_run_method('3_global_ua', bigquery_client, query)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    gcs_path = f"{gameidx}/{timestamp}.parquet"
        
    saved_path = save_df_to_gcs(query_result, bucket, gcs_path)

    return saved_path




### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸

#client = genai.Client(api_key="AIzaSyAVv2B6DM6w9jd1MxiP3PbzAEMkl97SCGY")
def os_by_gemini(gameidx:str, service_sub: str, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION:list, path_daily_revenue, path_monthly_revenue, bucket, PROJECT_ID, LOCATION, **context):
    
    from google.genai import Client
    genai_client = Client(vertexai=True,project=PROJECT_ID,location=LOCATION)

    os_rev_df = load_df_from_gcs(bucket, path_daily_revenue)
    os_cost_df = load_df_from_gcs(bucket, path_monthly_revenue)

    RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
    LABELS = {"datascience_division_service": 'gameinsight_framework',
            "run_id": RUN_ID,
            "datascience_division_service_sub" : service_sub}

    response3_revAndCostByOs = genai_client.models.generate_content(
    model=MODEL_NAME,
    contents = f"""

    ì´ë²ˆë‹¬ì— IOS ì— ëª‡ % ë§ˆì¼€íŒ… ë¹„ìš© ì‚¬ìš©í–ˆìœ¼ë©° IOS ì˜ ë§¤ì¶œë¹„ì¤‘ì€ ëª‡% ì…ë‹ˆë‹¤.
    ì˜ í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜.

    <ì›í•˜ëŠ” ì„œì‹>
    1. ìš”ì•½í•´ì£¼ê² ë‹¤ ë§ í•˜ì§€ë§ê³  ìš”ì•½í•œ ë‚´ìš©ì— ëŒ€í•´ì„œë§Œ ì ì–´ì£¼ë©´ ë¼.
    2. ìŠµë‹ˆë‹¤. ì²´ë¡œ ì¨ì¤˜
    3. í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.


    <ë°ì´í„° ì„¤ëª…>


    <ì´ë²ˆë‹¬ ê°€ì…ìœ ì €ì˜ OSë³„ ë§¤ì¶œ>
    {os_rev_df}

    <ì´ë²ˆë‹¬ OSë³„ ë§ˆì¼€íŒ… ë¹„ìš©>
    {os_cost_df}
    """,
    config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
            # tools=[RAG],
            temperature=0.5,
            labels=LABELS
        )

    )

    # GCSì— ì—…ë¡œë“œ
    print("ğŸ“¤ GCSì— ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸ ì—…ë¡œë“œ ì¤‘...")
    gcs_response_path = f"{gameidx}/response3_revAndCostByOs.text"
    blob = bucket.blob(gcs_response_path)
    blob.upload_from_string(
        response3_revAndCostByOs.text,
        content_type='text/markdown; charset=utf-8'
    )

    # ì½”ë©˜íŠ¸ ì¶œë ¥
    return response3_revAndCostByOs.text

# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

### ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
## êµ­ê°€ë³„ ë§¤ì¶œ

def by_country_revenue_graph_draw(gameidx: str, gcs_path:str, bucket, **context):
    ## í•œê¸€ í°íŠ¸ ì„¤ì •
    viz_libs = _setup_matplotlib_and_fonts()
    plt = viz_libs['plt']
    
    query_result3_revByCountry = load_df_from_gcs(bucket, gcs_path)
    query_result3_revByCountry = query_result3_revByCountry.sort_values(by="rev", ascending=False)

    sizes = query_result3_revByCountry["rev"].to_numpy()
    labels = query_result3_revByCountry["country"].to_numpy()
    total  = sizes.sum()

    fig, ax = plt.subplots(figsize=(5,5))
    wedges, _ = ax.pie(sizes, labels=None, startangle=90)

    # ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
    angles = [(p.theta1 + p.theta2)/2 for p in wedges]
    inside_r, outside_r = 0.6, 1.28

    # 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
    texts = []
    for ang, size, name in zip(angles, sizes, labels):
        percent = size / total * 100
        txt = f"{name} ({percent:.1f}%)"
        x_in = np.cos(np.deg2rad(ang)) * inside_r
        y_in = np.sin(np.deg2rad(ang)) * inside_r
        t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
        texts.append(t)

    # 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
    def any_overlaps(texts, renderer):
        bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
        overlaps = set()
        for i in range(len(bboxes)):
            for j in range(i+1, len(bboxes)):
                if bboxes[i].overlaps(bboxes[j]):
                    overlaps.add(i); overlaps.add(j)
        return overlaps

    # 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
    fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
    over_idx = any_overlaps(texts, fig.canvas.get_renderer())

    # ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
    idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
    for i in idx_sorted:
        ang = angles[i]
        # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
        x_out = np.cos(np.deg2rad(ang)) * outside_r
        y_out = np.sin(np.deg2rad(ang)) * outside_r
        # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
        x_edge = np.cos(np.deg2rad(ang)) * 1.0
        y_edge = np.sin(np.deg2rad(ang)) * 1.0

        # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
        txt_str = texts[i].get_text()
        texts[i].set_visible(False)

        # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
        ha = 'left' if x_out >= 0 else 'right'
        ax.annotate(
            txt_str,
            xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
            xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
            ha=ha, va='center', fontsize=9, color='black',
            arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
        )
    ax.set_title("êµ­ê°€ë³„ ë§¤ì¶œ ë¹„ì¤‘", pad=24)
    #plt.title("êµ­ê°€ë³„ ë§¤ì¶œ ë¹„ì¤‘")
    plt.tight_layout()

    filepath1_dailySales = "graph3_revByCountry.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'



def by_country_cost_graph_draw(gameidx: str, gcs_path:str, bucket, **context):
    
    # Step 1: matplotlib ì„¤ì • ë¡œë“œ
    viz_libs = _setup_matplotlib_and_fonts()
    plt = viz_libs['plt']

    query_result3_costByCountry = load_df_from_gcs(bucket, gcs_path)
    query_result3_costByCountry = query_result3_costByCountry.sort_values(by="cost", ascending=False)

    ### êµ­ê°€ë³„ Cost
    sizes = query_result3_costByCountry["cost"].to_numpy()
    labels = query_result3_costByCountry["country"].to_numpy()
    total  = sizes.sum()


    fig, ax = plt.subplots(figsize=(5,5))
    wedges, _ = ax.pie(sizes, labels=None, startangle=90)

    # ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
    angles = [(p.theta1 + p.theta2)/2 for p in wedges]
    inside_r, outside_r = 0.6, 1.28

    # 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
    texts = []
    for ang, size, name in zip(angles, sizes, labels):
        percent = size / total * 100
        txt = f"{name} ({percent:.1f}%)"
        x_in = np.cos(np.deg2rad(ang)) * inside_r
        y_in = np.sin(np.deg2rad(ang)) * inside_r
        t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
        texts.append(t)

    # 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
    def any_overlaps(texts, renderer):
        bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
        overlaps = set()
        for i in range(len(bboxes)):
            for j in range(i+1, len(bboxes)):
                if bboxes[i].overlaps(bboxes[j]):
                    overlaps.add(i); overlaps.add(j)
        return overlaps

    # 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
    fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
    over_idx = any_overlaps(texts, fig.canvas.get_renderer())

    # ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
    idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
    for i in idx_sorted:
        ang = angles[i]
        # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
        x_out = np.cos(np.deg2rad(ang)) * outside_r
        y_out = np.sin(np.deg2rad(ang)) * outside_r
        # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
        x_edge = np.cos(np.deg2rad(ang)) * 1.0
        y_edge = np.sin(np.deg2rad(ang)) * 1.0

        # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
        txt_str = texts[i].get_text()
        texts[i].set_visible(False)

        # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
        ha = 'left' if x_out >= 0 else 'right'
        ax.annotate(
            txt_str,
            xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
            xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
            ha=ha, va='center', fontsize=9, color='black',
            arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
        )
    ax.set_title("êµ­ê°€ë³„ COST ë¹„ì¤‘", pad=24)
    plt.tight_layout()


    filepath1_dailySales = "graph3_costByCountry.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'


def merge_contry_graph(gameidx: str, gcs_path_1:str, gcs_path_2:str, bucket, **context):
    # Step 1: Image ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
    image_libs = _setup_image_libs()
    Image = image_libs['Image']
    BytesIO = image_libs['BytesIO']

    p1=by_country_revenue_graph_draw(gameidx, gcs_path_1, bucket)
    p2=by_country_cost_graph_draw(gameidx, gcs_path_2, bucket)

    # 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
    print(f"ğŸ“¥ GCSì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    blob1 = bucket.blob(p1)
    blob2 = bucket.blob(p2)

    print(f"ğŸ“¥ blob1 ë‹¤ìš´ë¡œë“œ ì¤‘ ...")
    im1 = blob1.download_as_bytes()
    im2 = blob2.download_as_bytes()

    print(f"ğŸ–¼ï¸ Image ê°ì²´ ìƒì„± ì¤‘...")
    im1 = Image.open(BytesIO(im1))
    im2 = Image.open(BytesIO(im2))

    # ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
    print(f"ğŸ”„ ì´ë¯¸ì§€ ë†’ì´ ë§ì¶”ëŠ” ì¤‘...")
    target_h = max(im1.height, im2.height)

    def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas

    im1_p = pad_to_height(im1, target_h)
    im2_p = pad_to_height(im2, target_h)

    gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
    bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

    out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
    out.paste(im1_p, (0, 0), im1_p)
    out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

    # 3) GCSì— ì €ì¥
    print(f"ğŸ“¤ GCSì— ì—…ë¡œë“œ ì¤‘...")
    output_buffer = BytesIO()
    out.save(output_buffer, format='PNG')
    output_buffer.seek(0)

    # GCS ê²½ë¡œ
    gcs_path = f'{gameidx}/graph3_revAndCostByCountry.png'
    blob = bucket.blob(gcs_path)
    blob.upload_from_string(output_buffer.getvalue(), content_type='image/png')

    print(f"âœ… GCS ì—…ë¡œë“œ ì™„ë£Œ: gs://{bucket.name}/{gcs_path}")

    return gcs_path



### OS ë³„ ë§¤ì¶œ
def os_rev_graph_draw(gameidx: str, gcs_path:str, bucket, **context):

    # Step 1: matplotlib ì„¤ì • ë¡œë“œ
    viz_libs = _setup_matplotlib_and_fonts()
    plt = viz_libs['plt']

    query_result3_revByOs = load_df_from_gcs(bucket, gcs_path)

    sizes = query_result3_revByOs["rev"].to_numpy()
    labels = query_result3_revByOs["os"].to_numpy()
    total  = sizes.sum()


    fig, ax = plt.subplots(figsize=(5,5))
    wedges, _ = ax.pie(sizes, labels=None, startangle=90)

    # ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
    angles = [(p.theta1 + p.theta2)/2 for p in wedges]
    inside_r, outside_r = 0.6, 1.28

    # 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
    texts = []
    for ang, size, name in zip(angles, sizes, labels):
        percent = size / total * 100
        txt = f"{name} ({percent:.1f}%)"
        x_in = np.cos(np.deg2rad(ang)) * inside_r
        y_in = np.sin(np.deg2rad(ang)) * inside_r
        t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
        texts.append(t)

    # 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
    def any_overlaps(texts, renderer):
        bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
        overlaps = set()
        for i in range(len(bboxes)):
            for j in range(i+1, len(bboxes)):
                if bboxes[i].overlaps(bboxes[j]):
                    overlaps.add(i); overlaps.add(j)
        return overlaps

    # 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
    fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
    over_idx = any_overlaps(texts, fig.canvas.get_renderer())

    # ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
    idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
    for i in idx_sorted:
        ang = angles[i]
        # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
        x_out = np.cos(np.deg2rad(ang)) * outside_r
        y_out = np.sin(np.deg2rad(ang)) * outside_r
        # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
        x_edge = np.cos(np.deg2rad(ang)) * 1.0
        y_edge = np.sin(np.deg2rad(ang)) * 1.0

        # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
        txt_str = texts[i].get_text()
        texts[i].set_visible(False)

        # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
        ha = 'left' if x_out >= 0 else 'right'
        ax.annotate(
            txt_str,
            xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
            xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
            ha=ha, va='center', fontsize=9, color='black',
            arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
        )

    ax.set_title("OSë³„ ë§¤ì¶œ ë¹„ì¤‘", pad=24)
    plt.tight_layout()

    filepath1_dailySales = "graph3_revByOs.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'
    

### os ë³„ Cost
def os_cost_graph_draw(gameidx: str, gcs_path:str, bucket, **context):

    # Step 1: matplotlib ì„¤ì • ë¡œë“œ
    viz_libs = _setup_matplotlib_and_fonts()
    plt = viz_libs['plt']

    query_result3_costByOs = load_df_from_gcs(bucket, gcs_path)

    sizes = query_result3_costByOs["cost"].to_numpy()
    labels = query_result3_costByOs["os"].to_numpy()
    total  = sizes.sum()
    
    fig, ax = plt.subplots(figsize=(5,5))
    wedges, _ = ax.pie(sizes, labels=None, startangle=90)

    # ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
    angles = [(p.theta1 + p.theta2)/2 for p in wedges]
    inside_r, outside_r = 0.6, 1.28

    # 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
    texts = []
    for ang, size, name in zip(angles, sizes, labels):
        percent = size / total * 100
        txt = f"{name} ({percent:.1f}%)"
        x_in = np.cos(np.deg2rad(ang)) * inside_r
        y_in = np.sin(np.deg2rad(ang)) * inside_r
        t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
        texts.append(t)

    # 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
    def any_overlaps(texts, renderer):
        bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
        overlaps = set()
        for i in range(len(bboxes)):
            for j in range(i+1, len(bboxes)):
                if bboxes[i].overlaps(bboxes[j]):
                    overlaps.add(i); overlaps.add(j)
        return overlaps

    # 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
    fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
    over_idx = any_overlaps(texts, fig.canvas.get_renderer())

    # ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
    idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
    for i in idx_sorted:
        ang = angles[i]
        # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
        x_out = np.cos(np.deg2rad(ang)) * outside_r
        y_out = np.sin(np.deg2rad(ang)) * outside_r
        # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
        x_edge = np.cos(np.deg2rad(ang)) * 1.0
        y_edge = np.sin(np.deg2rad(ang)) * 1.0

        # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
        txt_str = texts[i].get_text()
        texts[i].set_visible(False)

        # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
        ha = 'left' if x_out >= 0 else 'right'
        ax.annotate(
            txt_str,
            xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
            xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
            ha=ha, va='center', fontsize=9, color='black',
            arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
        )

    ax.set_title("OSë³„ COST ë¹„ì¤‘", pad=24)
    plt.tight_layout()

    filepath1_dailySales = "graph3_costByOs.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'


def merge_os_graph(gameidx: str, gcs_path_1:str, gcs_path_2:str, bucket, **context):

    # Step 1: Image ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
    image_libs = _setup_image_libs()
    Image = image_libs['Image']
    BytesIO = image_libs['BytesIO']

    p1 = os_rev_graph_draw(gameidx, gcs_path_1, bucket)
    p2 = os_cost_graph_draw(gameidx, gcs_path_2, bucket)

    # 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
    print(f"ğŸ“¥ GCSì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    blob1 = bucket.blob(p1)
    blob2 = bucket.blob(p2)

    print(f"ğŸ“¥ blob1 ë‹¤ìš´ë¡œë“œ ì¤‘ ...")
    im1 = blob1.download_as_bytes()
    im2 = blob2.download_as_bytes()

    print(f"ğŸ–¼ï¸ Image ê°ì²´ ìƒì„± ì¤‘...")
    im1 = Image.open(BytesIO(im1))
    im2 = Image.open(BytesIO(im2))

      # ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
    print(f"ğŸ”„ ì´ë¯¸ì§€ ë†’ì´ ë§ì¶”ëŠ” ì¤‘...")
    target_h = max(im1.height, im2.height)

    def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas

    im1_p = pad_to_height(im1, target_h)
    im2_p = pad_to_height(im2, target_h)

    gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
    bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

    out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
    out.paste(im1_p, (0, 0), im1_p)
    out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

    # 3) GCSì— ì €ì¥
    print(f"ğŸ“¤ GCSì— ì—…ë¡œë“œ ì¤‘...")
    output_buffer = BytesIO()
    out.save(output_buffer, format='PNG')
    output_buffer.seek(0)

    # GCS ê²½ë¡œ
    gcs_path = f'{gameidx}/graph3_revAndCostByOs.png'
    blob = bucket.blob(gcs_path)
    blob.upload_from_string(output_buffer.getvalue(), content_type='image/png')

    print(f"âœ… GCS ì—…ë¡œë“œ ì™„ë£Œ: gs://{bucket.name}/{gcs_path}")

    return gcs_path


#### ë…¸ì…˜ì— ì—…ë¡œë“œ

def country_data_upload_to_notion(gameidx: str, st1, st2, service_sub, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION, notion, bucket, headers_json, **context):

    current_context = get_current_context()

    PAGE_INFO=current_context['task_instance'].xcom_pull(
        task_ids = 'make_gameframework_notion_page_wraper',
        key='page_info'
    )

    query_result3_revByCountry=load_df_from_gcs(bucket, st1)
    query_result3_costByCountry=load_df_from_gcs(bucket, st2)

    ########### (1) ì œëª©
    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "3. ê¸€ë¡œë²Œ ëª¨ê° ì§€í‘œ " }}]
                },
            }
        ],
    )

    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_3",
                "heading_3": {
                    "rich_text": [{"type": "text", "text": {"content": "(1) êµ­ê°€ë³„ ë§ˆì¼€íŒ…ë¹„ìš©ê³¼ ë§¤ì¶œë¹„ì¤‘" }}]
                },
            }
        ],
    )


    gcs_path = merge_contry_graph(gameidx=gameidx, gcs_path_1=st1, gcs_path_2=st2, bucket=bucket)
    blob = bucket.blob(gcs_path)
    image_bytes = blob.download_as_bytes()
    print(f"âœ… gcs_path : {gcs_path}")
    filename = gcs_path.split('/')[-1]

    print(f"âœ… GCS íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")

    ########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
    create_url = "https://api.notion.com/v1/file_uploads"
    payload = {
        "filename": filename,
        "content_type": "image/png"
    }
    headers_json = headers_json
    resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
    resp.raise_for_status()
    file_upload = resp.json()
    
    print(f"ğŸ“Š API ì‘ë‹µ: {file_upload}")
    file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
    upload_url = file_upload['upload_url']

# 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data) - ìˆ˜ì •ëœ ë¶€ë¶„
    send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
    files = {"file": (filename, BytesIO(image_bytes), "image/png")}

    # 2) ì´ë¯¸ì§€ ì—…ë¡œë“œ
    headers_send = {
        "Authorization": headers_json.get("Authorization"),
        "Notion-Version": headers_json.get("Notion-Version")
    }

    try:
        # [ìˆ˜ì •] headers=headers_upload ëŒ€ì‹  headers=headers_send ë¥¼ ì‚¬ìš©
        send_resp = requests.post(send_url, headers=headers_send, files=files) 
        send_resp.raise_for_status()
        print(f"âœ… NOTION ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"ì‘ì—… ì‹¤íŒ¨ : {e}")
        # ì‹¤íŒ¨ ì‹œ ì‘ë‹µ ë‚´ìš©ì„ í™•ì¸í•˜ë©´ ë””ë²„ê¹…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.
        if hasattr(e, 'response') and e.response is not None:
            print(f"ì˜¤ë¥˜ ì‘ë‹µ: {e.response.text}")
        raise e

    # 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
    append_url = f"https://api.notion.com/v1/blocks/{PAGE_INFO['id']}/children"
    append_payload = {
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "file_upload",
                    "file_upload": {"id": file_upload_id},
                    # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
                }
            }
        ]
    }

    headers_json_patch = headers_json
    append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
    append_resp.raise_for_status()

    ### ë¡œë°ì´í„° ì œê³µ
    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result3_revByCountry,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - êµ­ê°€ë³„ ë§¤ì¶œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )
    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result3_costByCountry,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - êµ­ê°€ë³„ COST  ",
        max_first_batch_rows=90,
        batch_size=100,
    )


    ### êµ­ê°€ë³„ cost rev ì½”ë©˜íŠ¸
    ########### (3) ì œë¯¸ë‚˜ì´ í•´ì„

    text = cohort_by_gemini(
        gameidx=gameidx,
        service_sub=service_sub,
        genai_client=genai_client,
        MODEL_NAME = MODEL_NAME,
        SYSTEM_INSTRUCTION=SYSTEM_INSTRUCTION,
        path_daily_revenue=st1,
        path_monthly_revenue=st2,
        bucket=bucket,
        PROJECT_ID=PROJECT_ID,
        LOCATION=LOCATION
    )
    blocks = md_to_notion_blocks(text)
    notion.blocks.children.append(
        block_id=PAGE_INFO['id'],
        children=blocks
    )

    ## ë¶€ì œëª©
    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_3",
                "heading_3": {
                    "rich_text": [{"type": "text", "text": {"content": "(2) OSë³„ ë§ˆì¼€íŒ…ë¹„ìš©ê³¼ ë§¤ì¶œë¹„ì¤‘" }}]
                },
            }
        ],
    )




## osë³„ cost, rev ê·¸ë˜í”„
########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
## IAP+ìœ ê°€ì ¬
def os_data_upload_to_notion(gameidx: str, st1, st2, service_sub, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION, notion, bucket, headers_json, **context):

    current_context = get_current_context()

    PAGE_INFO=current_context['task_instance'].xcom_pull(
        task_ids = 'make_gameframework_notion_page_wraper',
        key='page_info'
    )

    print(f"âœ… PAGE_INFO ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")

    page_id = PAGE_INFO.get('id')

    query_result3_costByOs=load_df_from_gcs(bucket, st1)
    query_result3_revByOs=load_df_from_gcs(bucket, st2)

    gcs_path = merge_os_graph(gameidx=gameidx, gcs_path_1=st1, gcs_path_2=st2, bucket=bucket, **context)
    blob = bucket.blob(gcs_path)
    image_bytes = blob.download_as_bytes()
    filename = gcs_path.split('/')[-1]

    print(f"âœ… GCS íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")

    # 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
    create_url = "https://api.notion.com/v1/file_uploads"
    payload = {
        "filename": filename,
        "content_type": "image/png"
    }
    headers_json = headers_json
    resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
    resp.raise_for_status()
    file_upload = resp.json()

    print(f"ğŸ“Š API ì‘ë‹µ: {file_upload}")
    file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
    upload_url = file_upload['upload_url']

    # 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data) - ìˆ˜ì •ëœ ë¶€ë¶„
    send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
    files = {"file": (filename, BytesIO(image_bytes), "image/png")}

    # 2) ì´ë¯¸ì§€ ì—…ë¡œë“œ
    headers_send = {
        "Authorization": headers_json.get("Authorization"),
        "Notion-Version": headers_json.get("Notion-Version")
    }

    try:
        # [ìˆ˜ì •] headers=headers_upload ëŒ€ì‹  headers=headers_send ë¥¼ ì‚¬ìš©
        send_resp = requests.post(send_url, headers=headers_send, files=files) 
        send_resp.raise_for_status()
        print(f"âœ… NOTION ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"ì‘ì—… ì‹¤íŒ¨ : {e}")
        # ì‹¤íŒ¨ ì‹œ ì‘ë‹µ ë‚´ìš©ì„ í™•ì¸í•˜ë©´ ë””ë²„ê¹…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.
        if hasattr(e, 'response') and e.response is not None:
            print(f"ì˜¤ë¥˜ ì‘ë‹µ: {e.response.text}")
        raise e
    
    # 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
    append_url = f"https://api.notion.com/v1/blocks/{PAGE_INFO['id']}/children"
    append_payload = {
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "file_upload",
                    "file_upload": {"id": file_upload_id},
                    # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
                }
            }
        ]
    }

    headers_json_patch = headers_json
    append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
    append_resp.raise_for_status()

    ### ë¡œë°ì´í„° ì œê³µ
    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result3_revByOs,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¥ê¸° ìì²´ê²°ì œ ë§¤ì¶œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result3_costByOs,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - OSë³„ COST ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    ## osë³„ cost, rev ì½”ë©˜íŠ¸
    ########### (3) ì œë¯¸ë‚˜ì´ í•´ì„
    gemini_text = os_by_gemini(
        gameidx=gameidx,
        service_sub=service_sub, 
        genai_client=genai_client, 
        MODEL_NAME=MODEL_NAME, 
        SYSTEM_INSTRUCTION=SYSTEM_INSTRUCTION,
        path_daily_revenue=st1,
        path_monthly_revenue=st2,
        bucket=bucket,
        PROJECT_ID=PROJECT_ID,
        LOCATION=LOCATION)
    blocks = md_to_notion_blocks(gemini_text)
    notion.blocks.children.append(
        block_id=PAGE_INFO['id'],
        children=blocks
    )


# ìµœê·¼ 30ì¼ ê¸°ì¤€ êµ­ê°€ê·¸ë£¹ë³„ X ê²°ì œì²˜ë³„ ë§¤ì¶œ ì¿¼ë¦¬
# ì§€ë¦¬ì  ì£¼ìš” êµ­ê°€ë³„ë¡œ ê·¸ë£¹í™”
# í•œêµ­
# ë¯¸êµ­
# ì¼ë³¸
# ë™ì•„ì‹œì•„ & ì˜¤ì„¸ì•„ë‹ˆì•„: ì¤‘êµ­, ëŒ€ë§Œ, í™ì½©, ì‹±ê°€í¬ë¥´, íƒœêµ­, ë² íŠ¸ë‚¨, ë§ë ˆì´ì‹œì•„, í•„ë¦¬í•€, ì¸ë„ë„¤ì‹œì•„, ì¸ë„, í˜¸ì£¼, ë‰´ì§ˆëœë“œ
# ì¤‘ë™: ì•„ëì—ë¯¸ë¦¬íŠ¸, ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„, í„°í‚¤, ì´ë€, ì´ìŠ¤ë¼ì—˜, ì¹´íƒ€ë¥´, ì¿ ì›¨ì´íŠ¸, ì˜¤ë§Œ, ë°”ë ˆì¸, ìš”ë¥´ë‹¨
# ì„œìœ ëŸ½: ì˜êµ­, í”„ë‘ìŠ¤, ë…ì¼, ì´íƒˆë¦¬ì•„, ìŠ¤í˜ì¸, ë„¤ëœë€ë“œ, ë²¨ê¸°ì—, ìŠ¤ìœ„ìŠ¤, ì˜¤ìŠ¤íŠ¸ë¦¬ì•„, ì•„ì¼ëœë“œ, í¬ë¥´íˆ¬ê°ˆ
# ë™ìœ ëŸ½: í´ë€ë“œ, ì²´ì½”, í—ê°€ë¦¬, ë£¨ë§ˆë‹ˆì•„, ìŠ¬ë¡œë°”í‚¤ì•„, ëŸ¬ì‹œì•„, ìš°í¬ë¼ì´ë‚˜, ë¶ˆê°€ë¦¬ì•„, ìŠ¬ë¡œë² ë‹ˆì•„, í¬ë¡œì•„í‹°ì•„
# ì•„ë©”ë¦¬ì¹´: ìºë‚˜ë‹¤, ë©•ì‹œì½”, ë¸Œë¼ì§ˆ, ì•„ë¥´í—¨í‹°ë‚˜, ì¹ ë ˆ, ì½œë¡¬ë¹„ì•„, í˜ë£¨
# ê¸°íƒ€: ê·¸ ì™¸ êµ­ê°€

def country_group_rev(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):
    query = f"""
    with chk as (
    SELECT
    perf.LogDateKST,
    perf,AuthAccountName,
    perf.CountryGroup,
        pg.PGRole,
        pg.PlatformDeviceTypeName,
        pg.PGName,
        pg.PGBuyCount,
        pg.PGPriceKRW
    FROM
    (
        select * except(CountryGroup)
            , CASE
    WHEN CountryCode = 'KR' THEN 'í•œêµ­'
    WHEN CountryCode = 'JP' THEN 'ì¼ë³¸'
    WHEN CountryCode = 'US' THEN 'ë¯¸êµ­'
    WHEN CountryCode IN ('CN', 'TW', 'HK', 'SG', 'TH', 'VN', 'MY', 'PH', 'ID', 'IN', 'AU', 'NZ') THEN 'ë™ì•„ì‹œì•„ & ì˜¤ì„¸ì•„ë‹ˆì•„'
    WHEN CountryCode IN ('AE', 'SA', 'TR', 'IR', 'IL', 'QA', 'KW', 'OM', 'BH', 'JO') THEN 'ì¤‘ë™'
    WHEN CountryCode IN ('GB', 'FR', 'DE', 'IT', 'ES', 'NL', 'BE', 'CH', 'AT', 'IE', 'PT') THEN 'ì„œìœ ëŸ½'
    WHEN CountryCode IN ('PL', 'CZ', 'HU', 'RO', 'SK', 'RU', 'UA', 'BG', 'SI', 'HR') THEN 'ë™ìœ ëŸ½'
    WHEN CountryCode IN ('CA', 'MX', 'BR', 'AR', 'CL', 'CO', 'PE') THEN 'ì•„ë©”ë¦¬ì¹´'
    ELSE 'ê¸°íƒ€'
    END AS CountryGroup
        from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
        where joyplegameid = {joyplegameid}
                and logdateKst >= DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 14 DAY)
                and logdatekst <= DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY)
    ) AS perf,
    UNNEST(perf.PaymentDetailArrayStruct) AS pg
    )

    select CountryGroup, LogDateKST, PGName, sum(PGPriceKRW) as Sales
    from chk
    group by CountryGroup, LogDateKST, PGName
    order by case when CountryGroup = 'í•œêµ­' then 1
                when CountryGroup = 'ë¯¸êµ­' then 2
                when CountryGroup = 'ì¼ë³¸' then 3
                when CountryGroup = 'ë™ì•„ì‹œì•„ & ì˜¤ì„¸ì•„ë‹ˆì•„' then 4
                when CountryGroup = 'ì„œìœ ëŸ½' then 5
                when CountryGroup = 'ë™ìœ ëŸ½' then 6
                when CountryGroup = 'ì•„ë©”ë¦¬ì¹´' then 7
                when CountryGroup = 'ì¤‘ë™' then 8
                when CountryGroup = 'ê¸°íƒ€' then 9
            end
            , LogDateKST, PGName
    """
    query_result = query_run_method('3_global_ua', bigquery_client, query)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    gcs_path = f"{gameidx}/{timestamp}.parquet"
        
    saved_path = save_df_to_gcs(query_result, bucket, gcs_path)

    return saved_path


def country_group_to_df(joyplegameid:int, gameidx:str, bigquery_client, bucket, **context):

    saved_path = country_group_rev(joyplegameid=joyplegameid, gameidx=gameidx, bigquery_client=bigquery_client, bucket=bucket, **context)
    query_result = load_df_from_gcs(bucket=bucket, path=saved_path)

    query_result = query_result.sort_values(by="Sales", ascending=False)

    grouped_dfs = {
        country: group_df.pivot_table(
            index="LogDateKST",
            columns="PGName",
            values="Sales",
            aggfunc="sum",
            fill_value=0
        )
        for country, group_df in query_result.groupby("CountryGroup")
    }

    grouped_dfs = {
    country: df[df.sum().sort_values(ascending=False).index]
    for country, df in grouped_dfs.items()
    }


    # ë¡œë°ì´í„° ì œê³µìš© ë°ì´í„°í”„ë ˆì„
    grouped_dfs_union = query_result.pivot_table(
        index=["CountryGroup", "LogDateKST"],  # ë‘ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ì¸ë±ìŠ¤ êµ¬ì„±
        columns="PGName",
        values="Sales",
        aggfunc="sum",
        fill_value=0
    ).reset_index()

    num_cols = grouped_dfs_union.select_dtypes(include="number").columns
    grouped_dfs_union[num_cols] = grouped_dfs_union[num_cols].astype(int)


    return grouped_dfs, grouped_dfs_union



def country_group_to_df_gemini(service_sub: str, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION:list, path_daily_revenue, bucket, **context):

    from google.genai import Client
    genai_client = Client(vertexai=True,project=PROJECT_ID,location=LOCATION)

    query_result = load_df_from_gcs(bucket=bucket, path=path_daily_revenue)

    RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
    LABELS = {"datascience_division_service": 'gameinsight_framework',
            "run_id": RUN_ID,
            f"datascience_division_service_sub" : service_sub}

    response_GeoPGSales = genai_client.models.generate_content(
        model=MODEL_NAME,
        contents=f"""
    ì§€ë‚œ 2ì£¼ê°„ êµ­ê°€ê·¸ë£¹ë³„ë¡œ ì¼ê°„ ê²°ì œì²˜ë³„ ë§¤ì¶œ ë°ì´í„°ì•¼.\n{query_result.to_csv(index=False)}
    ê° êµ­ê°€ê·¸ë£¹ì—ì„œ ê²°ì œì²˜ë³„ë¡œ ì¼ê°„ ë§¤ì¶œíë¦„ì´ ì–´ë–»ê²Œ ë˜ëŠ”ì§€, ì–´ë–¤ ê²°ì œì²˜ì˜ ë§¤ì¶œì´ ì–¸ì œ ê¸‰ì¦í–ˆëŠ”ì§€ë¥¼ ìš”ì•½í•´ì„œ 6ì¤„ ì´ë‚´ë¡œ ì•Œë ¤ì¤˜.
    ë§¤ì¶œ ê¸‰ì¦ì˜ ì›ì¸ì„ íŒŒì•…í•˜ì§€ëŠ” ë§ì•„ì¤˜.
    #, ##, ###, ####ì€ ì‚¬ìš©í•˜ì§€ ë§ì•„ì¤˜.
    """,
        config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
            # tools=[RAG],
            temperature=0.3
            ,labels=LABELS
            # max_output_tokens=2048
        )
    )

    return response_GeoPGSales.text



def country_group_df_draw(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):

    # Step 1: matplotlib ì„¤ì • ë¡œë“œ
    viz_libs = _setup_matplotlib_and_fonts()
    plt = viz_libs['plt']
    FuncFormatter = viz_libs['FuncFormatter']


    gcs_paths = []
    grouped_dfs, _ = country_group_to_df(joyplegameid=joyplegameid, gameidx=gameidx, bigquery_client=bigquery_client, bucket=bucket, **context)

    # âœ… ëª¨ë“  ê·¸ë£¹ë³„ë¡œ ê·¸ë˜í”„ ìƒì„±
    for country, df in grouped_dfs.items():
        # index(LogDateKST)ê°€ ë¬¸ìì—´ì´ë©´ datetimeìœ¼ë¡œ ë³€í™˜
        if not pd.api.types.is_datetime64_any_dtype(df.index):
            df.index = pd.to_datetime(df.index, errors="coerce")

        # ìˆ«ìí˜• ë³€í™˜ (Salesê°’)
        df = df.map(
            lambda x: pd.to_numeric(str(x).replace(",", "").replace("-", "0"), errors="coerce")
        )

        # âœ… ì¸ë±ìŠ¤ë¥¼ xì¶•ìœ¼ë¡œ ì‚¬ìš©
        x = df.index

        fig, ax = plt.subplots(figsize=(10, 5))

        # ê²°ì œìˆ˜ë‹¨ë³„ ì„ ê·¸ë˜í”„
        for col in df.columns:
            ax.plot(
                x, df[col],
                marker='o', markersize=3, linewidth=1,
                label=col
            )

        plt.title(f"{country} - ì¼ìë³„ ê²°ì œìˆ˜ë‹¨ ë§¤ì¶œ ì¶”ì´")
        plt.xlabel("ë‚ ì§œ")
        plt.ylabel("ë§¤ì¶œì•¡")

        # yì¶• ì²œ ë‹¨ìœ„ í¬ë§·
        ax.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

        # xì¶• ë¼ë²¨ íšŒì „
        plt.xticks(x, rotation=45)

        # ë²”ë¡€, ë³´ì¡°ì„ , ì €ì¥
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)
        plt.grid(axis='y', linestyle='--', alpha=0.7)
        plt.tight_layout()

        filepath1_dailySales = f"graph_{country}.png"
        plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
        plt.close()

        blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
        blob.upload_from_filename(filepath1_dailySales)

        blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
        blob.upload_from_filename(filepath1_dailySales)

        # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
        os.remove(filepath1_dailySales)

        # gcs ê²½ë¡œ ì¶”ê°€
        gcs_paths.append(f'{gameidx}/{filepath1_dailySales}')

    return gcs_paths
    

def merge_images_by_three_gcs(
    bucket,
    gcs_image_paths: List[str],
    output_dir: str,
    gameidx: str,
    gap: int = 0,
    bg_color: Tuple[int, int, int, int] = (255, 255, 255, 0),
    cleanup_temp: bool = True
    ) -> List[str]:

    # Step 1: Image ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
    image_libs = _setup_image_libs()
    Image = image_libs['Image']
    BytesIO = image_libs['BytesIO']

    def pad_to_height(img: Image.Image, h: int, bg: Tuple = bg_color) -> Image.Image:
        """ì´ë¯¸ì§€ì˜ ë†’ì´ë¥¼ ë§ì¶°ì¤Œ (ì„¸ë¡œ íŒ¨ë”© ì¶”ê°€)"""
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas
    
    # ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
    print("ì²˜ë¦¬í•  GCS ì´ë¯¸ì§€ ëª©ë¡:")
    for i, path in enumerate(gcs_image_paths, 1):
        print(f"  {i}. {path}")
    print()
    
    uploaded_paths = []
    temp_files = []
    
    # 3ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬
    for batch_num, i in enumerate(range(0, len(gcs_image_paths), 3), 1):
        imgs = []
        names = []
        
        # ìµœëŒ€ 3ê°œì˜ ì´ë¯¸ì§€ ë¡œë“œ
        for j in range(3):
            if i + j < len(gcs_image_paths):
                gcs_path = gcs_image_paths[i + j]
                
                try:
                    # GCSì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    blob = bucket.blob(gcs_path)
                    image_bytes = blob.download_as_bytes()
                    img = Image.open(BytesIO(image_bytes)).convert("RGBA")
                    imgs.append(img)
                    
                    # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±° ë° "graph_" ì œê±°
                    name = os.path.splitext(os.path.basename(gcs_path))[0]
                    if name.startswith("graph_"):
                        name = name.replace("graph_", "", 1)
                    names.append(name)
                    
                except Exception as e:
                    print(f"ê²½ê³ : GCSì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {gcs_path}")
                    print(f"  ì—ëŸ¬: {str(e)}")
                    continue
        
        if not imgs:
            print(f"ë°°ì¹˜ {batch_num}: ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        # ì„¸ë¡œ ë§ì¶”ê¸°
        target_h = max(img.height for img in imgs)
        imgs_padded = [pad_to_height(img, target_h) for img in imgs]
        
        # ê°€ë¡œë¡œ í•©ì¹˜ê¸°
        total_width = sum(img.width for img in imgs_padded) + gap * (len(imgs_padded) - 1)
        out = Image.new("RGBA", (total_width, target_h), bg_color)
        
        x_offset = 0
        for img in imgs_padded:
            out.paste(img, (x_offset, 0), img)
            x_offset += img.width + gap
        
        # íŒŒì¼ëª… êµ¬ì„±
        merged_filename = "graph_" + " ë° ".join(names) + ".png"
        temp_filepath = f"/tmp/{merged_filename}"
        
        # ë¡œì»¬ì— ì„ì‹œ ì €ì¥
        out.save(temp_filepath)
        temp_files.append(temp_filepath)
        
        # GCS ê²½ë¡œ êµ¬ì„±
        gcs_upload_path = f"{gameidx}/{output_dir}/{merged_filename}"
        
        # GCSì— ì—…ë¡œë“œ
        upload_blob = bucket.blob(gcs_upload_path)
        upload_blob.upload_from_filename(temp_filepath)
        
        print(f"âœ“ ë°°ì¹˜ {batch_num} ì €ì¥ë¨: gs://{bucket.name}/{gcs_upload_path}")
        uploaded_paths.append(gcs_upload_path)
    
    # ë¡œì»¬ ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if cleanup_temp:
        for temp_file in temp_files:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        print(f"\nâœ“ {len(temp_files)}ê°œì˜ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
    
    print(f"\nì´ {len(uploaded_paths)}ê°œì˜ í•©ì³ì§„ ì´ë¯¸ì§€ê°€ GCSì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

    return uploaded_paths


def merge_country_group_df_draw(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):
    """
    Airflow DAGì—ì„œ ì‚¬ìš©í•  wrapper í•¨ìˆ˜
    """
    from google.cloud import storage
    
    # GCS í´ë¼ì´ì–¸íŠ¸ ë° ë²„í‚· ì´ˆê¸°í™”
    client = storage.Client()
    bucket = client.bucket("game-framework1")  # ë²„í‚·ëª… ìˆ˜ì • í•„ìš”
    
    # ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (ë¦¬ìŠ¤íŠ¸)
    img_gcs_list = country_group_df_draw(joyplegameid, gameidx, bigquery_client, bucket)
    
    # í•©ì¹˜ê¸° ì²˜ë¦¬
    merged_paths = merge_images_by_three_gcs(
        bucket=bucket,
        gcs_image_paths=img_gcs_list,
        output_dir="merged",  # GCS ë‚´ ì¶œë ¥ ë””ë ‰í† ë¦¬
        gameidx=gameidx,
        gap=0,
        bg_color=(255, 255, 255, 0),
        cleanup_temp=True
    )
    
    return merged_paths


def country_group_data_upload_to_notion(joyplegameid: int, gameidx: str, st1, service_sub: str, 
                                        genai_client, MODEL_NAME, SYSTEM_INSTRUCTION, notion, bigquery_client,
                                        bucket, headers_json, NOTION_TOKEN, NOTION_VERSION, 
                                        bucket_name: str = "game-framework1", merged_image_dir: str= "merged", **context):

    current_context = get_current_context()

    PAGE_INFO=current_context['task_instance'].xcom_pull(
        task_ids = 'make_gameframework_notion_page_wraper',
        key='page_info'
    )

    print(f"ğŸ“Š page_info type: {type(PAGE_INFO)}")
    print(f"ğŸ“Š page_info: {PAGE_INFO}")
    print(f"âœ… PAGE_INFO ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")

    page_id = PAGE_INFO.get('id')

    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "êµ­ê°€ë³„ X ê²°ì œì²˜ë³„ ì§€í‘œ" }}]
                },
            }
        ],
    )

    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [
                        {'annotations': {'bold': True,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "ğŸŒ êµ­ê°€ê·¸ë£¹ ë¶„ë¥˜ ê¸°ì¤€\n1. í•œêµ­\n2. ë¯¸êµ­\n3. ì¼ë³¸\n"}},
                        {'annotations': {'bold': True,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "4. ì„œìœ ëŸ½: "}},
                        {'annotations': {'bold': False,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "ì˜êµ­, í”„ë‘ìŠ¤, ë…ì¼, ì´íƒˆë¦¬ì•„, ìŠ¤í˜ì¸, ë„¤ëœë€ë“œ, ë²¨ê¸°ì—, ìŠ¤ìœ„ìŠ¤, ì˜¤ìŠ¤íŠ¸ë¦¬ì•„, ì•„ì¼ëœë“œ, í¬ë¥´íˆ¬ê°ˆ\n"}},
                        {'annotations': {'bold': True,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "5. ë™ìœ ëŸ½: "}},
                        {'annotations': {'bold': False,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "í´ë€ë“œ, ì²´ì½”, í—ê°€ë¦¬, ë£¨ë§ˆë‹ˆì•„, ìŠ¬ë¡œë°”í‚¤ì•„, ëŸ¬ì‹œì•„, ìš°í¬ë¼ì´ë‚˜, ë¶ˆê°€ë¦¬ì•„, ìŠ¬ë¡œë² ë‹ˆì•„, í¬ë¡œì•„í‹°ì•„\n"}},
                        {'annotations': {'bold': True,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "6. ë™ì•„ì‹œì•„ & ì˜¤ì„¸ì•„ë‹ˆì•„: "}},
                        {'annotations': {'bold': False,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "ì¤‘êµ­, ëŒ€ë§Œ, í™ì½©, ì‹±ê°€í¬ë¥´, íƒœêµ­, ë² íŠ¸ë‚¨, ë§ë ˆì´ì‹œì•„, í•„ë¦¬í•€, ì¸ë„ë„¤ì‹œì•„, ì¸ë„, í˜¸ì£¼, ë‰´ì§ˆëœë“œ\n"}},
                        {'annotations': {'bold': True,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "7. ì•„ë©”ë¦¬ì¹´: "}},
                        {'annotations': {'bold': False,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "ìºë‚˜ë‹¤, ë©•ì‹œì½”, ë¸Œë¼ì§ˆ, ì•„ë¥´í—¨í‹°ë‚˜, ì¹ ë ˆ, ì½œë¡¬ë¹„ì•„, í˜ë£¨\n"}},
                                            {'annotations': {'bold': True,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "8. ì¤‘ë™: "}},
                        {'annotations': {'bold': False,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "ì•„ëì—ë¯¸ë¦¬íŠ¸, ì‚¬ìš°ë””ì•„ë¼ë¹„ì•„, í„°í‚¤, ì´ë€, ì´ìŠ¤ë¼ì—˜, ì¹´íƒ€ë¥´, ì¿ ì›¨ì´íŠ¸, ì˜¤ë§Œ, ë°”ë ˆì¸, ìš”ë¥´ë‹¨\n"}},
                        {'annotations': {'bold': True,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "9. ê¸°íƒ€: "}},
                        {'annotations': {'bold': False,
                                                'code': False,
                                                'color': 'default',
                                                'italic': False,
                                                'strikethrough': False,
                                                'underline': False},
                        "type": "text", "text": {"content": "ê·¸ ì™¸ êµ­ê°€ë“¤"}},
                        ]
                },
            }
        ],
    )

    # GCS í´ë¼ì´ì–¸íŠ¸ ë° ë²„í‚· ì´ˆê¸°í™”
    gcs_client = storage.Client()
    bucket = gcs_client.bucket(bucket_name)
    
    # GCSì—ì„œ í•©ì³ì§„ ì´ë¯¸ì§€ ëª©ë¡ ì¡°íšŒ
    gcs_image_paths = []
    blobs = gcs_client.list_blobs(
        bucket_name,
        prefix=f"{gameidx}/{merged_image_dir}/"
    )

    for blob in blobs:
        # "ë°"ì´ í¬í•¨ëœ PNG íŒŒì¼ë§Œ í•„í„°ë§
        if blob.name.lower().endswith(".png") and "ë°" in blob.name:
            gcs_image_paths.append(blob.name)
    
    # íŒŒì¼ëª… ì—­ìˆœ ì •ë ¬
    gcs_image_paths.sort(reverse=True)
    
    print(f"ì—…ë¡œë“œí•  ì´ë¯¸ì§€ ê°œìˆ˜: {len(gcs_image_paths)}ê°œ")
    print("ì´ë¯¸ì§€ ëª©ë¡:")
    for path in gcs_image_paths:
        print(f"  - {path}")
    

    # ê³µí†µ í—¤ë”
    headers_json = headers_json
    # GCSì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° Notion ì—…ë¡œë“œ
    for gcs_path in gcs_image_paths:
        filename = gcs_path.split('/')[-1]
        print(f"\nì—…ë¡œë“œ ì¤‘: {filename}")
        
        try:
            # GCSì—ì„œ ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë‹¤ìš´ë¡œë“œ
            blob = bucket.blob(gcs_path)
            image_bytes = blob.download_as_bytes()
            
            # íŒŒì¼ ì—…ë¡œë“œ ê°ì²´ ìƒì„±
            create_url = "https://api.notion.com/v1/file_uploads"
            payload = {
                "filename": filename,
                "content_type": "image/png"
            }
            resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
            resp.raise_for_status()
            file_upload = resp.json()
            file_upload_id = file_upload["id"]
            
            # íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡
            send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
            files = {"file": (filename, BytesIO(image_bytes), "image/png")}
            headers_send = {
                "Authorization": f"Bearer {NOTION_TOKEN}",
                "Notion-Version": NOTION_VERSION
            }
            send_resp = requests.post(send_url, headers=headers_send, files=files)
            send_resp.raise_for_status()
            
            # Notion í˜ì´ì§€ì— ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ ì²¨ë¶€
            append_url = f"https://api.notion.com/v1/blocks/{PAGE_INFO['id']}/children"
            append_payload = {
                "children": [
                    {
                        "object": "block",
                        "type": "image",
                        "image": {
                            "type": "file_upload",
                            "file_upload": {"id": file_upload_id},
                        }
                    }
                ]
            }
            
            append_resp = requests.patch(
                append_url, headers=headers_json, data=json.dumps(append_payload)
            )
            append_resp.raise_for_status()
            
            print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {filename}")
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ Notion API ì—ëŸ¬: {filename}")
            print(f"  ì—ëŸ¬: {str(e)}")
            continue
        except Exception as e:
            print(f"âŒ GCS ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ì—…ë¡œë“œ ì—ëŸ¬: {filename}")
            print(f"  ì—ëŸ¬: {str(e)}")
            continue
    
    print("\nğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ!")

    _, grouped_dfs_union =country_group_to_df(
        joyplegameid=joyplegameid, 
        gameidx=gameidx, 
        bigquery_client=bigquery_client,
        bucket=bucket,
        **context
    )

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=grouped_dfs_union,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - êµ­ê°€ë³„ X ê²°ì œì²˜ë³„ ì§€í‘œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )


    text = country_group_to_df_gemini(
        service_sub=service_sub,
        genai_client=genai_client,
        MODEL_NAME=MODEL_NAME,
        SYSTEM_INSTRUCTION=SYSTEM_INSTRUCTION,
        path_daily_revenue=st1,
        bucket=bucket
    )

    blocks = md_to_notion_blocks(text)
    notion.blocks.children.append(
        block_id=PAGE_INFO['id'],
        children=blocks
    )

    return True