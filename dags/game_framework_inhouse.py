import time
import pandas as pd
from google.cloud import bigquery
from google import genai
from google.genai import types
from google.cloud import storage
import vertexai
from google.genai import Client
from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore

# ì¸ì¦ê´€ë ¨
import google.auth
from google.auth.transport.requests import Request
import logging

# ê·¸ë˜í”„ ê´€ë ¨ íŒ¨í‚¤ì§€
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter, StrMethodFormatter, PercentFormatter, MultipleLocator
import matplotlib as mpl
import matplotlib.font_manager as fm
from matplotlib import cm
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont # 2ê°€ì§€ íŒŒì¼ í•©ì¹˜ê¸°
import matplotlib.dates as mdates
import nest_asyncio
from jinja2 import Template
from playwright.async_api import async_playwright
import asyncio
import IPython.display as IPd
from bs4 import BeautifulSoup
from io import BytesIO
from typing import List, Tuple
from matplotlib import rcParams
from matplotlib.patches import Rectangle

# ì „ì²˜ë¦¬ ê´€ë ¨ íŒ¨í‚¤ì§€
import numpy as np
import re
import os 
import math
import time
import pandas as pd
from notion_client import Client
import requests
import json
from datetime import datetime, timezone, timedelta
from adjustText import adjust_text
from airflow.models import Variable
from airflow.operators.python import get_current_context
from zoneinfo import ZoneInfo  # Python 3.9 ì´ìƒ
from pathlib import Path
from airflow.sdk import get_current_context
from game_framework_util import *

PROJECT_ID = "data-science-division-216308"
LOCATION = "us-central1"

import logging

# matplotlib.categoryì˜ ë¡œê·¸ ë ˆë²¨ì„ WARNINGìœ¼ë¡œ ì„¤ì • (INFO ë¡œê·¸ ë¬´ì‹œ)
logging.getLogger('matplotlib.category').setLevel(logging.WARNING)

## í•œê¸€ í°íŠ¸ ì„¤ì •
setup_korean_font()

# 2. ìì²´ê²°ì œ ë§¤ì¶œ
def inhouse_sales_query(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):
    query = f"""
    select logdatekst, cast(sum(pgpricekrw) as int64) as rev
    from
    (SELECT t1.*,
        t2.PGRole,
        t2.PlatformDeviceTypeName,
        t2.PGName,
        t2.PGBuyCount,
        t2.PGPriceKRW
    FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V` AS t1,
    UNNEST(t1.PaymentDetailArrayStruct) AS t2
    where joyplegameid = {joyplegameid}
    and pgrole = 'ìì²´ê²°ì œ'
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )
    group by 1 order by 1

    """
    query_result = query_run_method('2_inhouse_sales', bigquery_client, query)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    gcs_path = f"{gameidx}/{timestamp}.parquet"
        
    saved_path = save_df_to_gcs(query_result, bucket, gcs_path)

    return saved_path
    

### 2> 24ë…„ë¶€í„° ì›”ë³„ ìì²´ê²°ì œ ë§¤ì¶œ
def inhouse_sales_before24_query(joyplegameid: int, gameidx: str, bigquery_client, bucket, **context):
    query = f"""
    select a.month
    , cast(a.rev_all as int64) as rev_all
    , cast(b.rev as int64) as rev_self
    , safe_divide(b.rev,a.rev_all) as self_per
    from
    (select month, sum(pricekrw) as rev_all
    from
    (select *,format_date('%Y-%m', logdatekst ) as month
    FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>='2024-01-01'
    and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
    group by 1
    ) as a

    left join
    (select month, cast(sum(pgpricekrw) as int64) as rev
    from
    (SELECT t1.*,
        t2.PGRole,
        t2.PlatformDeviceTypeName,
        t2.PGName,
        t2.PGBuyCount,
        t2.PGPriceKRW,
        format_date('%Y-%m', logdatekst ) as month
    FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V` AS t1,
    UNNEST(t1.PaymentDetailArrayStruct) AS t2
    where joyplegameid = {joyplegameid}
    and pgrole = 'ìì²´ê²°ì œ'
    and logdatekst>='2024-01-01'
    and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
    group by 1) as b
    on a.month = b.month
    order by month
    """

    query_result = query_run_method('2_inhouse_sales', bigquery_client, query)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    gcs_path = f"{gameidx}/{timestamp}.parquet"
        
    saved_path = save_df_to_gcs(query_result, bucket, gcs_path)

    return saved_path


## ì œë¯¸ë‚˜ì´ í”„ë¡¬í”„íŠ¸ 
def inhouses_revenue_gemini(gameidx:str, service_sub: str, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION:list, path_daily_revenue, path_monthly_revenue, bucket, PROJECT_ID, LOCATION, **context):
    
    inhouse_sales = load_df_from_gcs(bucket, path_daily_revenue)
    inhouse_sales_before24 = load_df_from_gcs(bucket, path_monthly_revenue)

    RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
    LABELS = {"datascience_division_service": 'gameinsight_framework',
            "run_id": RUN_ID,
            "datascience_division_service_sub" : service_sub}

    prompt_2 = f"""

    1. ì•„ë˜ëŠ” ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œê³¼ ê³¼ê±°ë¶€í„° ì¥ê¸°ì ì¸ ìì²´ê²°ì œ ë§¤ì¶œì´ì•¼.ê°„ë‹¨í•˜ê²Œ í•´ì„í•´ì¤˜.
    2. ìì²´ê²°ì œì— ëŒ€í•œ ì •ì˜ë¥¼ ì“¸ í•„ìš”ëŠ” ì—†ì–´.
    3. ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ê³ , ì¥ê¸°ì ì¸ ìì²´ê²°ì œ íŠ¸ë Œë“œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì¤˜.
    4. ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œì™€ ì¥ê¸°ì ì¸ ìì²´ê²°ì œ íŠ¸ë Œë“œ ë‹¨ë½ì„ ë‚˜ëˆ ì¤˜. ì˜ˆ) <ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œ> , <ì¥ê¸°ì  ìì²´ê²°ì œ íŠ¸ë Œë“œ>
    5. ë‚´ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì“°ì§€ë§ˆ.
    6. ë³€ìˆ˜ëª…ì— ëŒ€í•´ì„  ì–¸ê¸‰í•˜ì§€ë§ˆ.
    7. ìì²´ê²°ì œë€, êµ¬ê¸€ì´ë‚˜ ì• í”Œì˜ ë§ˆì¼“ ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°í•˜ê¸° ìœ„í•´ ìˆ˜ìˆ˜ë£Œê°€ ë‚®ì€ ê²°ì œ í”Œë«í¼ì—ì„œ ê²°ì œí•˜ëŠ” ê²ƒì„ ë§í•´.
    8. ë‹¤ìŒì€ ìì²´ê²°ì œì— ëŒ€í•œ ë¶„ì„ì…ë‹ˆë‹¤ ì´ëŸ° ì‚¬ì „ì— ë§ í•˜ì§€ë§ê³  ê·¸ëƒ¥ ë¶„ì„ê²°ê³¼ë¥¼ ì•Œë ¤ì¤˜
    9. ì‚¬ê²¬ì„ ì“°ì§€ë§ê³  ê·¸ëƒ¥ í˜„ì¬ ìƒí™©ì— ëŒ€í•´ íŒ©íŠ¸ë§Œ ì•Œë ¤ì¤˜.


    < ì„œì‹ ìš”êµ¬ì‚¬í•­ >
    í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.

    <ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ>
    {inhouse_sales}

    < ì¥ê¸°ì  ìì²´ê²°ì œ ë§¤ì¶œ>
    {inhouse_sales_before24}

    """

    response2_selfPaymentSales = genai_client.models.generate_content(
        model=MODEL_NAME,
        contents=prompt_2,
        config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
            #tools=[rag_retrieval_tool_test],
            temperature=0.5,
            labels=LABELS
            # max_output_tokens=2048
        )
    )

    # GCSì— ì—…ë¡œë“œ
    print("ğŸ“¤ GCSì— ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸ ì—…ë¡œë“œ ì¤‘...")
    gcs_response_path = f"{gameidx}/response2_selfPaymentSales.text"
    blob = bucket.blob(gcs_response_path)
    blob.upload_from_string(
        response2_selfPaymentSales.text,
        content_type='text/markdown; charset=utf-8'
    )

    return response2_selfPaymentSales.text

## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
# font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
# if Path(font_path).exists():
#     fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
#     mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
#     mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
# else:
#     print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

def inhouse_revenue_graph_draw(gameidx: str, gcs_path:str, bucket, **context):

    query_result2_dailySelfPaymentSales = load_df_from_gcs(bucket, gcs_path)
    
    # Seaborn ì„  ê·¸ë˜í”„
    sns.lineplot(
        x= query_result2_dailySelfPaymentSales.columns[0],
        y=query_result2_dailySelfPaymentSales.columns[1],
        data=query_result2_dailySelfPaymentSales,
        marker="o"
        )

    # ì˜µì…˜
    plt.title("ì´ë²ˆë‹¬ ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ")
    #plt.xlabel(query_result2_dailySelfPaymentSales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
    #plt.ylabel(query_result2_dailySelfPaymentSales.columns[1])

    # yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

    # xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
    plt.xticks(query_result2_dailySelfPaymentSales[query_result2_dailySelfPaymentSales.columns[0]][::1], rotation=45)

    # yì¶• 0ë¶€í„° ì‹œì‘
    plt.ylim(0, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§
    # yì¶• ë³´ì¡°ì„ 
    plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

    # x,yì¶• ì œê±°
    plt.xlabel(None)
    plt.ylabel(None)

    #plt.show()
    # ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
    plt.tight_layout()


    # í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
    # #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
    # ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨

    ####################################### ì´ë¯¸ì§€ íŒŒì¼ì„ ì €ì¥í•  pathê°€ í•„ìš”í•¨ #####################
    filepath1_inhouseSales = "graph1_dailySelfPaymentSales.png"
    plt.savefig(filepath1_inhouseSales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_inhouseSales}')
    blob.upload_from_filename(filepath1_inhouseSales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_inhouseSales)

    return f'{gameidx}/{filepath1_inhouseSales}'



## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
# font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
# if Path(font_path).exists():
#     fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
#     mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
#     mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
# else:
#     print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

def inhouse_revenue_monthly_graph_draw(gameidx: str, gcs_path:str, bucket, **context):
    
    query_result2_monthlySelfPaymentSales = load_df_from_gcs(bucket, gcs_path)

    # Figure & Axes ìƒì„±
    fig, ax1 = plt.subplots(figsize=(10,5))

    # ì˜µì…˜
    plt.title("ì›”ë³„ ìì²´ê²°ì œ ë§¤ì¶œ & ìì²´ê²°ì œ ë§¤ì¶œ ë¹„ì¤‘ (24ë…„1ì›”~) ")

    # ì²« ë²ˆì§¸ yì¶• (ì™¼ìª½, ë§‰ëŒ€ê·¸ë˜í”„)
    ax1.bar(query_result2_monthlySelfPaymentSales["month"],
            query_result2_monthlySelfPaymentSales["rev_self"],
            color="#5B9BD5",
            #label="Sales"
            )
    #ax1.set_ylabel("Sales", color="black")
    ax1.tick_params(axis="y", labelcolor="black")

    # ë‘ ë²ˆì§¸ yì¶• (ì˜¤ë¥¸ìª½, ì„ ê·¸ë˜í”„)
    ax2 = ax1.twinx()
    ax2.plot(query_result2_monthlySelfPaymentSales["month"],
            query_result2_monthlySelfPaymentSales["self_per"],
            color="#ED7D31",
            marker="o",
            #label="Users"
            )
    #ax2.set_ylabel("Users", color="black")
    ax2.tick_params(axis="y", labelcolor="black")

    # ğŸ‘‰ ì„  ìœ„ì— ë°ì´í„° ë ˆì´ë¸” í‘œì‹œ
    for x, y in zip(query_result2_monthlySelfPaymentSales["month"],
                    query_result2_monthlySelfPaymentSales["self_per"]):
        ax2.annotate(f"{y:.0%}",  # 0.23 â†’ "23%"
                    xy=(x, y),
                    xytext=(0, 5),  # ì‚´ì§ ìœ„ë¡œ
                    textcoords="offset points",
                    ha="center", color="black"
                    )


    # yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
    ax1.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))

    # í¼ì„¼íŠ¸ í¬ë§· ìë™ ì ìš© (self_perê°€ 0~1ì´ë©´ 1.0, 0~100ì´ë©´ 100)
    maxv = float(query_result2_monthlySelfPaymentSales["self_per"].max())
    ax2.yaxis.set_major_formatter(PercentFormatter(1.0 if maxv <= 1.5 else 100))

    # xì¶• ëˆˆê¸ˆ(ê°’) ì„¸ë¡œ íšŒì „ â€” ì¶• ê°ì²´ì— ì§ì ‘ ì ìš©
    for tick in ax1.get_xticklabels():
        tick.set_rotation(90)
        tick.set_ha("center")  # ë˜ëŠ” "right"ë¡œ ë°”ê¿”ë„ ë¨

    # ì œëª© & ê²©ì
    ax1.grid(axis="y", linestyle="--", alpha=0.7)

    plt.tight_layout()

    # í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
    # #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
    # ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
    filepath1_inhouseMonthlySales = "graph1_monthlySelfPaymentSales.png"
    plt.savefig(filepath1_inhouseMonthlySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_inhouseMonthlySales}')
    blob.upload_from_filename(filepath1_inhouseMonthlySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_inhouseMonthlySales)

    return f'{gameidx}/{filepath1_inhouseMonthlySales}'


## ê·¸ë˜í”„ í•©ì¹˜ê¸°
### ìì²´ê²°ì œ ì¼ìë³„ + ìì²´ê²°ì œ ì›”ë³„

### Rê·¸ë£¹ë³„ ë§¤ì¶œê·¸ë˜í”„ì™€ PU ê·¸ë˜í”„ í•©ì¹˜ê¸°

def merge_inhouse_graph(gameidx: str, gcs_path_1:str, gcs_path_2:str, bucket, **context):

    p1 = inhouse_revenue_graph_draw(gameidx, gcs_path_1, bucket)
    print(f"âœ… p1 ê²½ë¡œ: {p1}")

    p2 = inhouse_revenue_monthly_graph_draw(gameidx, gcs_path_2, bucket)
    print(f"âœ… p2 ê²½ë¡œ: {p2}")

    # 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
    print(f"ğŸ“¥ GCSì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    blob1 = bucket.blob(p1)
    blob2 = bucket.blob(p2)

    print(f"ğŸ“¥ blob1 ë‹¤ìš´ë¡œë“œ ì¤‘ ...")
    im1 = blob1.download_as_bytes()
    im2 = blob2.download_as_bytes()

    print(f"ğŸ–¼ï¸ Image ê°ì²´ ìƒì„± ì¤‘...")
    im1 = Image.open(BytesIO(im1))
    im2 = Image.open(BytesIO(im2))

    # ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
    print(f"ğŸ”„ ì´ë¯¸ì§€ ë†’ì´ ë§ì¶”ëŠ” ì¤‘...")
    target_h = max(im1.height, im2.height)

    def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas

    im1_p = pad_to_height(im1, target_h)
    im2_p = pad_to_height(im2, target_h)

    gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
    bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

    out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
    out.paste(im1_p, (0, 0), im1_p)
    out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

    # 3) GCSì— ì €ì¥
    print(f"ğŸ“¤ GCSì— ì—…ë¡œë“œ ì¤‘...")
    output_buffer = BytesIO()
    out.save(output_buffer, format='PNG')
    output_buffer.seek(0)

    # GCS ê²½ë¡œ
    gcs_path = f'{gameidx}/graph2_selfPaymentSales.png'
    blob = bucket.blob(gcs_path)
    blob.upload_from_string(output_buffer.getvalue(), content_type='image/png')

    print(f"âœ… GCS ì—…ë¡œë“œ ì™„ë£Œ: gs://{bucket.name}/{gcs_path}")

    return gcs_path



def inhouse_revenue_data_upload_to_notion(gameidx: str, st1, st2, service_sub, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION, notion, bucket, headers_json, NOTION_TOKEN, NOTION_VERSION,  **context):

    if 'task_instance' in context:
        ti = context['task_instance']
    else:
        current_context = get_current_context()
        ti = current_context['task_instance']
    
    PAGE_INFO = ti.xcom_pull(
        task_ids='make_gameframework_notion_page_wraper',
        key='page_info'
    )

    print(f"ğŸ“Š page_info type: {type(PAGE_INFO)}")
    print(f"ğŸ“Š page_info: {PAGE_INFO}")
    print(f"âœ… PAGE_INFO ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")

    page_id = PAGE_INFO.get('id')

    query_result1_inhouseSales=load_df_from_gcs(bucket, st1)
    query_result1_inhouseMonthlySales=load_df_from_gcs(bucket, st2)
    
    ########### (1) ì œëª©
    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "2. ìì²´ê²°ì œ ë§¤ì¶œ" }}]
                },
            }
        ],
    )

    gcs_path = merge_inhouse_graph(gameidx=gameidx, gcs_path_1=st1, gcs_path_2=st2, bucket=bucket, **context)
    blob = bucket.blob(gcs_path)
    image_bytes = blob.download_as_bytes()
    filename = gcs_path.split('/')[-1]

    print(f"âœ… GCS íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")

    ########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
    create_url = "https://api.notion.com/v1/file_uploads"
    payload = {
        "filename": filename,
        "content_type": "image/png"
    }
    headers_json = headers_json
    resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
    resp.raise_for_status()
    file_upload = resp.json()
    
    print(f"ğŸ“Š API ì‘ë‹µ: {file_upload}")
    file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
    upload_url = file_upload['upload_url']

    # 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data) - ìˆ˜ì •ëœ ë¶€ë¶„
    send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
    files = {"file": (filename, BytesIO(image_bytes), "image/png")}

    # 2) ì´ë¯¸ì§€ ì—…ë¡œë“œ
    headers_send = {
        "Authorization": headers_json.get("Authorization"),
        "Notion-Version": headers_json.get("Notion-Version")
    }

    try:
        # [ìˆ˜ì •] headers=headers_upload ëŒ€ì‹  headers=headers_send ë¥¼ ì‚¬ìš©
        send_resp = requests.post(send_url, headers=headers_send, files=files) 
        send_resp.raise_for_status()
        print(f"âœ… NOTION ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"ì‘ì—… ì‹¤íŒ¨ : {e}")
        # ì‹¤íŒ¨ ì‹œ ì‘ë‹µ ë‚´ìš©ì„ í™•ì¸í•˜ë©´ ë””ë²„ê¹…ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.
        if hasattr(e, 'response') and e.response is not None:
            print(f"ì˜¤ë¥˜ ì‘ë‹µ: {e.response.text}")
        raise e
    

    # 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
    append_url = f"https://api.notion.com/v1/blocks/{page_id}/children"
    append_payload = {
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "file_upload",
                    "file_upload": {"id": file_upload_id},
                    # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
                }
            }
        ]
    }

    headers_json_patch = headers_json
    append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
    append_resp.raise_for_status()

    ## (3) ë¡œë°ì´í„°
    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result1_inhouseSales,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result1_inhouseMonthlySales,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¥ê¸° ìì²´ê²°ì œ ë§¤ì¶œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    ## (4) ì œë¯¸ë‚˜ì´ í•´ì„
    print(f"1ï¸âƒ£ GEMINI ë¬¸ì˜ ì²˜ë¦¬ ì‹œì‘")
    gemini_text = inhouses_revenue_gemini(gameidx, service_sub, genai_client, MODEL_NAME, SYSTEM_INSTRUCTION, st1, st2, bucket, PROJECT_ID=PROJECT_ID, LOCATION=LOCATION)
    blocks = md_to_notion_blocks(gemini_text)

    notion.blocks.children.append(
        block_id=PAGE_INFO['id'],
        children=blocks
    )

    print(f"2ï¸âƒ£ GEMINI ë‹µë³€ ë“±ë¡ ì™„ë£Œ")

    return True

