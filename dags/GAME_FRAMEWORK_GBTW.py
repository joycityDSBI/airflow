import time
import pandas as pd
from google.cloud import bigquery
from google import genai
from google.genai import types
from goole.cloud import storage
from vertexai import rag
import vertexai
from google.genai import Client
from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore

# ì¸ì¦ê´€ë ¨
import google.auth
from google.auth.transport.requests import Request

# ê·¸ë˜í”„ ê´€ë ¨ íŒ¨í‚¤ì§€
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter, StrMethodFormatter, PercentFormatter, MultipleLocator
import matplotlib as mpl
import matplotlib.font_manager as fm
from matplotlib import cm
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont # 2ê°€ì§€ íŒŒì¼ í•©ì¹˜ê¸°
import matplotlib.dates as mdates
import nest_asyncio
from jinja2 import Template
from playwright.async_api import async_playwright
import asyncio
import IPython.display as IPd
from bs4 import BeautifulSoup
from io import BytesIO

# ì „ì²˜ë¦¬ ê´€ë ¨ íŒ¨í‚¤ì§€
import numpy as np
import re
import os 
import math
import time
import pandas as pd
from notion_client import Client
import requests
import json
from datetime import datetime, timezone, timedelta
from adjustText import adjust_text
from airflow.models import Variable
from zoneinfo import ZoneInfo  # Python 3.9 ì´ìƒ

# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
def get_var(key: str, default: str = None) -> str:
    """í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Airflow Variable ì¡°íšŒ"""
    return os.environ.get(key) or Variable.get(key, default_var=default)

# ë³€ìˆ˜ ìƒì„±
t0 = time.time()
PROJECT_ID = "data-science-division-216308"
LOCATION = "us-central1"
MODEL_NAME = "gemini-2.5-flash"

NOTION_TOKEN=get_var("MS_TEAM_NOTION_TOKEN") # MSíŒ€ API í‚¤
NOTION_VERSION=get_var("NOTION_API_VERSION")
DATABASE_ID=get_var("GAMEFRAMEWORK_GBTW_NOTION_DB_ID")
CREDENTIALS_JSON = get_var('GOOGLE_CREDENTIAL_JSON')

cred_dict = json.loads(CREDENTIALS_JSON)
credentials, project_id = google.auth.default(
    scopes=["https://www.googleapis.com/auth/cloud-platform"]
)
credentials.refresh(Request())

# í´ë¼ì´ì–¸íŠ¸ ëª¨ìŒ
genai_client = Client(vertexai=True,project=PROJECT_ID,location=LOCATION)
bigquery_client = bigquery.Client(project=PROJECT_ID, credentials=credentials)# location=LOCATION ## us-central1 ë¡œ í•  ê²½ìš° í—ˆë¸Œ ì¡°íšŒë¶ˆê°€ëŠ¥
notion = Client(auth=NOTION_TOKEN)
gcs_client = storage.Client.from_service_account_info(cred_dict)
bucket = gcs_client.bucket('game-framework1')

#### ì œë¯¸ë‚˜ì´ ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ 
SYSTEM_INSTRUCTION = [
                "You're a Game Data Analyst.",
                "Your task is to analyze the metrics of a given mobile game and identify the causes of any changes.",
                "Your answers must be in Korean.",
                "The unit of amount in the Sales or Revenue, Cost Data is Korean Won.",
                "You must answer in Notion's Markdown format, but do not use title syntax.",
            ]

## í˜ì´ì§€ ìƒì„± í•¨ìˆ˜ //////////// task í•¨ìˆ˜
def make_gameframework_notion_page(gameidx: str, **context):

    url = "https://api.notion.com/v1/pages"
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }

    # íƒ€ì„ì¡´ ì§€ì •
    kst = ZoneInfo("Asia/Seoul")
    # ì˜¤ëŠ˜
    today_kst = datetime.now(kst).date()
    # ì–´ì œ
    yesterday_kst = today_kst - timedelta(days=1)

    # ì´ë²ˆ ë‹¬ 1ì¼ (ì–´ì œ ë‚ ì§œ ê¸°ì¤€)
    first_day = yesterday_kst.replace(day=1)

    # íƒ€ì´í‹€ ë¬¸ìì—´ ë§Œë“¤ê¸°
    title = f"{yesterday_kst.strftime('%y')}ë…„ {yesterday_kst.month}ì›” ë§¤ì¶œí˜„í™©( ~ {yesterday_kst})"
    print(f"{title} : {gameidx}")

    # í˜ì´ì§€ ìƒì„± ìš”ì²­ ë°”ë””
    data = {
        "parent": {"database_id": DATABASE_ID},
        "properties": {
            "ì´ë¦„": {
                "title": [
                    {"text": {"content": title }}
                ]
            },
            "ë“±ë¡ ë‚ ì§œ": {
                "date": {"start": today_kst.isoformat() }
            },
            "í”„ë¡œì íŠ¸": {
                "multi_select": [
                    {"name": {gameidx}}   # ë‹¤ì¤‘ ì„ íƒ ì˜µì…˜
                ]
            },
            "ë¦¬í¬íŠ¸ ì¢…ë¥˜": {
                "multi_select": [
                    {"name": "ê²Œì„ë¶„ì„"}   # ë‹¤ì¤‘ ì„ íƒ ì˜µì…˜
                ]
            },
            "ì‘ì„±ì": {
                "people": [
                    {"id": "ce95f16a-6b6b-447d-a996-a9c5f0cc0113"},  # Notion user_id
                    {"id": "662575bc-731c-481c-afc7-13b2fdf5482a"}  # Notion user_id
                ]
            }
        }
    }

    res = requests.post(url, headers=headers, json=data)

    if res.status_code == 200:
        page_info = res.json() # âœ… í˜ì´ì§€ ID page_info["id"]
        print(f"âœ… í˜ì´ì§€ ìƒì„± ì„±ê³µ âœ… í˜ì´ì§€ ID : {page_info["id"]}")
    else:
        print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {res.status_code} >> {res.text}")

    notion.blocks.children.append(
        block_id=page_info["id"] ,
        children=[
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [
                        {
                            "type": "text",
                            "text": {"content": " â—¾ ëª©ì°¨"},
                            "annotations": {"bold": True}
                        }
                    ]
                }
            }
        ]
    )

    # ëª©ì°¨ ë¸”ë¡ ì¶”ê°€
    notion.blocks.children.append(
        block_id=page_info["id"] ,
        children=[
            {
                "object": "block",
                "type": "table_of_contents",
                "table_of_contents": {
                    "color": "default"  # "gray", "brown", "orange", "yellow", "green", "blue", "purple", "pink", "red" ê°€ëŠ¥
                }
            }
        ],
    )
    
    if res.status_code == 200:
        page_info = res.json()
        print(f"âœ… í˜ì´ì§€ ìƒì„± ì„±ê³µ âœ… í˜ì´ì§€ ID : {page_info['id']}")
    else:
        print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {res.status_code} >> {res.text}")

    context['task_instance'].xcom_push(key='page_info', value=page_info)

    return page_info 



################# notion í˜ì´ì§€ ìƒì„± í•¨ìˆ˜ ì‹¤í–‰ ############################

# ğŸ‘‰ Markdown ë‚´ **êµµê²Œ** ì²˜ë¦¬ ë³€í™˜
def parse_rich_text(md_text):
    """
    '**êµµê²Œ**' â†’ Notion rich_text [{"text": {...}, "annotations": {"bold": True}}]
    """
    parts = re.split(r"(\*\*.*?\*\*)", md_text)  # **...** ê¸°ì¤€ split
    rich_text = []
    for part in parts:
        if part.startswith("**") and part.endswith("**"):
            rich_text.append({
                "type": "text",
                "text": {"content": part[2:-2]},
                "annotations": {"bold": True}
            })
        else:
            if part:
                rich_text.append({
                    "type": "text",
                    "text": {"content": part}
                })
    return rich_text



# ğŸ‘‰ Markdownì„ Notion Blocksë¡œ ë³€í™˜
def md_to_notion_blocks(md_text, blank_blocks=3):
    blocks = []
    lines = md_text.splitlines()
    stack = [blocks]  # í˜„ì¬ ê³„ì¸µ ì¶”ì 

    def detect_indent_unit(lines):
        indents = []
        for line in lines:
            if line.lstrip().startswith(("* ", "- ", "+ ")):  # ë¦¬ìŠ¤íŠ¸ ë¬¸ë²• ê°ì§€
                indent = len(line) - len(line.lstrip())
                if indent > 0:
                    indents.append(indent)
        return min(indents) if indents else 4  # fallback = 4ì¹¸
    indent_unit = detect_indent_unit(lines)

    i = 0
    while i < len(lines):
        line = lines[i].rstrip()
        if not line:
            i += 1
            continue

        # Heading ì²˜ë¦¬
        if line.startswith("# "):
            stack = [blocks]
            stack[-1].append({
                "object": "block",
                "type": "heading_1",
                "heading_1": {"rich_text": parse_rich_text(line[2:])}
            })
        elif line.startswith("## "):
            stack = [blocks]
            stack[-1].append({
                "object": "block",
                "type": "heading_2",
                "heading_2": {"rich_text": parse_rich_text(line[3:])}
            })
        elif line.startswith("### "):
            stack = [blocks]
            stack[-1].append({
                "object": "block",
                "type": "heading_3",
                "heading_3": {"rich_text": parse_rich_text(line[4:])}
            })

        # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        elif line.lstrip().startswith("* "):
            indent = len(line) - len(line.lstrip())  # ë“¤ì—¬ì“°ê¸° ë ˆë²¨
            content = line.strip()[2:].strip()

            block = {
                "object": "block",
                "type": "bulleted_list_item",
                "bulleted_list_item": {
                    "rich_text": parse_rich_text(content),
                    "children": []
                }
            }

            # indent ê¸°ë°˜ ê³„ì¸µ ì²˜ë¦¬
            level = indent // indent_unit + 1
            while len(stack) > level:
                stack.pop()
            stack[-1].append(block)
            stack.append(block["bulleted_list_item"]["children"])
        else:
            stack = [blocks]
            # ì¼ë°˜ ë¬¸ë‹¨
            stack[-1].append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {"rich_text": parse_rich_text(line.strip())}
            })

        i += 1

    # âœ… ë§ˆì§€ë§‰ì— ë¹ˆ ë¸”ë¡ ì¶”ê°€ (ê°œìˆ˜ëŠ” íŒŒë¼ë¯¸í„° blank_blocksë¡œ ì œì–´)
    for _ in range(blank_blocks):
        blocks.append({
            "object": "block",
            "type": "paragraph",
            "paragraph": {"rich_text": []}
        })

    return blocks


def df_to_notion_table_under_toggle(
    notion: Client,
    page_id: str,
    df: pd.DataFrame,
    toggle_title: str = "ğŸ“Š Data Table",
    max_first_batch_rows: int = 90,
    batch_size: int = 100,
    has_column_header: bool = True,
    has_row_header: bool = False,
    ):
    """
    Notion í˜ì´ì§€ì— í† ê¸€ì„ ë§Œë“¤ê³ , ê·¸ ì•„ë˜ì— Pandas DataFrameì„ í‘œ(Table)ë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    - ìµœì´ˆ ìƒì„± ì‹œ í…Œì´ë¸”ì˜ header + ì´ˆê¸° í–‰ë“¤ì„ table.children ì•ˆì— í¬í•¨
    - ì´í›„ ë‚¨ì€ í–‰ë“¤ì€ table_rowë¡œ ë°°ì¹˜ append

    Parameters
    ----------
    notion : notion_client.Client
        Notion SDK í´ë¼ì´ì–¸íŠ¸ (Client(auth=...) ë¡œ ìƒì„±)
    page_id : str
        í…Œì´ë¸”ì„ ì¶”ê°€í•  í˜ì´ì§€(í˜¹ì€ ë¸”ë¡) ID
    df : pandas.DataFrame
        ì—…ë¡œë“œí•  ë°ì´í„°í”„ë ˆì„
    toggle_title : str
        í† ê¸€ íƒ€ì´í‹€
    max_first_batch_rows : int
        í…Œì´ë¸” ìµœì´ˆ ìƒì„± ì‹œ í¬í•¨í•  ì´ˆê¸° í–‰ ê°œìˆ˜(Too many children ë°©ì§€ìš©)
    batch_size : int
        ì´í›„ ë°°ì¹˜ append ì‹œ ë¬¶ìŒ í¬ê¸°
    has_column_header : bool
        Notion í…Œì´ë¸” ì˜µì…˜ - ì»¬ëŸ¼ í—¤ë” ì‚¬ìš© ì—¬ë¶€
    has_row_header : bool
        Notion í…Œì´ë¸” ì˜µì…˜ - í–‰ í—¤ë” ì‚¬ìš© ì—¬ë¶€

    Returns
    -------
    dict : {"toggle_id": str, "table_id": str, "rows_created": int}
    """
    # 1) í† ê¸€ ìƒì„±
    toggle_resp = notion.blocks.children.append(
        page_id,
        children=[
            {
                "object": "block",
                "type": "toggle",
                "toggle": {
                    "rich_text": [
                        {
                            "type": "text",
                            "text": {"content": toggle_title[:2000]},
                            "annotations": {
                                "bold": True,
                                "italic": False,
                                "underline": False,
                                "strikethrough": False,
                                "code": False,
                                "color": "blue"   # â† ìƒ‰ìƒ ì§€ì •
                            },
                        }
                    ]
                },
            }
        ],
    )
    toggle_id = toggle_resp["results"][0]["id"]

    # 2) í—¤ë”/ì´ˆê¸°í–‰ ì¤€ë¹„
    table_width = len(df.columns)

    # í—¤ë”(ì»¬ëŸ¼ëª…)
    header_cells = []
    for col in df.columns.astype(str).tolist():
        header_cells.append([{"type": "text", "text": {"content": str(col)[:2000]}}])

    # ì´ˆê¸° ë°ì´í„° í–‰
    first_rows_blocks = []
    row_count = 0
    for _, row in df.iterrows():
        if row_count >= max_first_batch_rows:
            break
        row_cells = []
        for col in df.columns:
            val = row[col]
            #s = "" if (val is None or (isinstance(val, float) and math.isnan(val))) else str(val)
            s = "" if pd.isna(val) else str(val)
            row_cells.append([{"type": "text", "text": {"content": s[:2000]}}])

        # ì—´ ìˆ˜ ì•ˆì „ì¥ì¹˜(íŒ¨ë”©/ì ˆë‹¨)
        if len(row_cells) < table_width:
            row_cells += [[{"type": "text", "text": {"content": ""}}]] * (table_width - len(row_cells))
        elif len(row_cells) > table_width:
            row_cells = row_cells[:table_width]

        first_rows_blocks.append(
            {"object": "block", "type": "table_row", "table_row": {"cells": row_cells}}
        )
        row_count += 1

    # 3) í…Œì´ë¸” ë¸”ë¡ ìƒì„±: table.children ì•ˆì— header + ì´ˆê¸°í–‰ í¬í•¨(ì¤‘ìš”)
    table_block = {
        "object": "block",
        "type": "table",
        "table": {
            "table_width": table_width,
            "has_column_header": has_column_header,
            "has_row_header": has_row_header,
            "children": (
                [
                    {
                        "object": "block",
                        "type": "table_row",
                        "table_row": {"cells": header_cells},
                    }
                ]
                + first_rows_blocks
            ),
        },
    }

    table_create_resp = notion.blocks.children.append(toggle_id, children=[table_block])
    table_id = table_create_resp["results"][0]["id"]

    # 4) ë‚¨ì€ í–‰ë“¤ ë°°ì¹˜ ì¶”ê°€
    total = len(df)
    start = row_count
    while start < total:
        end = min(start + batch_size, total)
        batch_children = []

        for _, row in df.iloc[start:end].iterrows():
            row_cells = []
            for col in df.columns:
                val = row[col]
                s = "" if (val is None or (isinstance(val, float) and math.isnan(val))) else str(val)
                row_cells.append([{"type": "text", "text": {"content": s[:2000]}}])

            if len(row_cells) < table_width:
                row_cells += [[{"type": "text", "text": {"content": ""}}]] * (table_width - len(row_cells))
            elif len(row_cells) > table_width:
                row_cells = row_cells[:table_width]

            batch_children.append(
                {"object": "block", "type": "table_row", "table_row": {"cells": row_cells}}
            )

        notion.blocks.children.append(table_id, children=batch_children)
        start = end

    return {"toggle_id": toggle_id, "table_id": table_id, "rows_created": total}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ìš© ì˜ˆì‹œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# from notion_client import Client
# notion = Client(auth=NOTION_TOKEN)
# resp = df_to_notion_table_under_toggle(
#     notion=notion,
#     page_id=PAGE_ID,
#     df=query_result1_dailySales,
#     toggle_title="ğŸ“Š Daily Sales (DataFrame Table)",
#     max_first_batch_rows=90,
#     batch_size=100,
# )
# print(resp)

### ì¼ìë³„ ë§¤ì¶œ
# ì¿¼ë¦¬ & ì œë¯¸ë‚˜ì´ í”„ë¡¬í”„íŠ¸

def query_run_method(service_sub: str, query):
    RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
    LABELS = {"datascience_division_service": 'gameinsight_framework',
            "run_id": RUN_ID,
            f"datascience_division_service_sub" : {service_sub}} ## ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë¶™ì¼ ìˆ˜ ìˆìŒ.
    print("ğŸ“§ RUN_ID=", RUN_ID, "ğŸ“§ LABEL_ID=", LABELS)

    query_result = bigquery_client.query(query, job_config=bigquery.QueryJobConfig(labels=LABELS)).to_dataframe()
    return query_result

## ì¼ìë³„ ë§¤ì¶œ
def Daily_revenue_query(joyplegameid: int, **context):
    query = f"""

    select day
    , cast(sum(if(monthtype = 'ì§€ë‚œë‹¬' , pricekrw, null ))as int64) as `ì§€ë‚œë‹¬`
    , cast(sum(if(monthtype = 'ì´ë²ˆë‹¬' , pricekrw, null ))as int64) as `ì´ë²ˆë‹¬`

    from
    (select *
    , format_date('%Y-%m',  logdatekst ) as Month
    , case when logdatekst >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH), INTERVAL 1 MONTH)
    and logdatekst< DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH) then 'ì§€ë‚œë‹¬'
    when logdatekst >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst <= LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH) then 'ì´ë²ˆë‹¬'
    else 'etc' end as monthtype
    , format_date('%d',  logdatekst ) as day
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdateKst>= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH), INTERVAL 1 MONTH)
    #and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )
    group by 1
    order by 1

    """
    query_result = query_run_method('1_daily_sales', query)
    context['task_instance'].xcom_push(key='daily_revenue_df', value=query_result)

    return True
    
    
#### ì „ë…„ ëŒ€ë¹„ ì›” ë§¤ì¶œ ì¶”ì´
def Daily_revenue_YOY_query(joyplegameid: int, **context):
    query = f"""

    select month
    , cast(sum(if(yeartype = 'ì‘ë…„' , pricekrw, null ))as int64) as `ì‘ë…„`
    , cast(sum(if(yeartype = 'ì˜¬í•´' , pricekrw, null ))as int64) as `ì˜¬í•´`

    from
    (select *
    , case
    when logdatekst >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR), INTERVAL 1 YEAR)
    and logdatekst< DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR) then 'ì‘ë…„'

    when logdatekst >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR)
    and logdatekst <= LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR) then 'ì˜¬í•´'
    else 'etc' end as yeartype
    , format_date('%m',  logdatekst ) as month
    , format_date('%Y',  logdatekst ) as year

    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdateKst>= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR), INTERVAL 1 YEAR)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR)
    )
    group by 1
    order by 1

    """
    query_result = query_run_method('1_daily_sales', query)
    context['task_instance'].xcom_push(key='Daily_revenue_YOY_df', value=query_result)

    return True


## í˜„ì¬ ë§¤ì¶œê³¼ ëª©í‘œ ë§¤ì¶œ
def Daily_revenue_target_revenue_query(joyplegameid: int, gameidx: str, **context):
    query = f"""
    ### 1> ì´ë²ˆë‹¬ ì¼ìë³„ ë§¤ì¶œ ì‹¤ì¸¡ì¹˜
    with thismonthRev as (
    select day ## ì¼ì
    , lastDay ## ì´ë²ˆë‹¬ ë§ˆì§€ë§‰ë‚  (ex - 30)
    , sum(pricekrw) as rev ## ë§¤ì¶œì•¡
    from
    (select *
    , cast(format_date('%d',  logdatekst ) as int64) as day ## ì¼ì
    , EXTRACT(DAY FROM LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)) as lastDay
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY)
    )
    group by day,lastDay
    order by day
    ),

    ### 2> ëª©í‘œë§¤ì¶œ í…Œì´ë¸”
    salesGoal as (
    select
        CAST(REPLACE(sales, ',', '') AS INT64) as salesGoalMonthly # ì‰¼í‘œ í¬í•¨í•œ string í˜•íƒœë¡œ ì ì¬ë˜ì–´ìˆì–´ì„œ int64 í˜•íƒœë¡œ ì „ì²˜ë¦¬
    , CAST(REPLACE(sales, ',', '') AS INT64)/cast(num_of_days as int64) as salesGoalDaily # ì¼í‰ê·  ëª©í‘œë§¤ì¶œ
    from `data-science-division-216308.gameInsightFramework.slgMonthlyGoal`
    where idx = {gameidx}
    and month = FORMAT_DATE('%Y-%m', DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
    ),

    ### 3> í•©ì¹˜ê¸°
    thismonthRev2 as (


    select
        a.day, a.lastDay, a.rev
    , b.salesGoalDaily
    , c.maxDay ## ì´ë²ˆë‹¬ ë©°ì¹ ê¹Œì§€ ê¸°ê°„ ì°¼ëŠ”ì§€
    #, case when maxDay >5 then rev ## 5ì¼ì¹˜ ì´ìƒì˜ ë§¤ì¶œì´ ìˆìœ¼ë©´ ê·¸ëƒ¥ ì¼í• ê³„ì‚°
    #       when maxDay<=5 and day=1 then salesGoalDaily ## 5ì¼ì¹˜ ì´í•˜ì˜ ë§¤ì¶œë§Œ ìˆë‹¤ë©´ , 1ì¼ì ë§¤ì¶œì„ ë³´ì •ì¹˜ ì ìš©
    #       else rev end as rev2
    , a.rev as rev2
    from
    ## ì¼ìë³„ ë§¤ì¶œ ì‹¤ì¸¡
    (select * from thismonthRev) as a

    ## ëª©í‘œë§¤ì¶œ (ì›”ë³„, ì¼ë³„)
    cross join
    (select *
    from salesGoal
    ) as b

    ## í˜„ì¬ ë©°ì¹ ê¹Œì§€ ë§¤ì¶œ ìˆëŠ”ì§€ -> 5ì¼ ì´ì „ì¸ì§€ ì´í›„ì¸ì§€ í™•ì¸ìš©ë„
    cross join
    (select cast(max(day) as int64) as maxDay from thismonthRev) as c

    )

    #select * from thismonthRev_and_revGoal order by day

    ### 4> ì „ì²˜ë¦¬
    select cast(current_sales as int64) as current_sales, b.salesGoalMonthly
    from
    (select (rev/maxDay)*lastDay as current_sales
    from
    (select sum(rev2) as rev, max(maxDay) as maxDay, max(lastDay) as lastDay
    from thismonthRev2)
    ) as a
    cross join
    (select * from salesGoal) as b

    """

    query_result = query_run_method('1_daily_sales', query)
    context['task_instance'].xcom_push(key='Daily_revenue_target_revenue_df', value=query_result)

    return True


## ì „ë…„ ëŒ€ë¹„ ì›” ë§¤ì¶œ ì¶”ì´ ìˆ˜ì • - ë‹¹ì›”ì€ ì¼í• ê³„ì‚° ë§¤ì¶œ
def merge_daily_revenue(joyplegameid: int, gameidx: str, **context):

    s_total = context['task_instance'].xcom_pull(
        task_ids = 'Daily_revenue_query',
        key='daily_revenue_df'
    )
    val_total = context['task_instance'].xcom_pull(
        task_ids = 'Daily_revenue_YOY_query',
        key='Daily_revenue_YOY_df'
    )

    val = val_total.iat[0, 0]
    s = s_total.iloc[:, 2]
    try:
        idx = s.dropna().index[-1]                 # ë§ˆì§€ë§‰ non-null ë¼ë²¨ ì¸ë±ìŠ¤
        s_total.loc[idx, s_total.columns[2]] = val
    except IndexError:
        pass  # ëª¨ë‘ nullì¸ ê²½ìš°

    return s_total


## í”„ë¡¬í”„íŠ¸ 
### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸
def daily_revenue_gemini(joyplegameid: int, service_sub: str, **context):
    query_result1_dailySales = context['task_instance'].xcom_pull(
        task_ids = 'Daily_revenue_query',
        key='daily_revenue_df'
    )
    query_result1_monthlySales = context['task_instance'].xcom_pull(
        task_ids = 'Daily_revenue_YOY_query',
        key='Daily_revenue_YOY_df'
    )

    RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
    LABELS = {"datascience_division_service": 'gameinsight_framework',
            "run_id": RUN_ID,
            f"datascience_division_service_sub" : {service_sub}}

    response1_salesComment = genai_client.models.generate_content(
    model='gemini-2.5-flash',
    contents = f"""
    ë‹¹ì›” ë§¤ì¶œì€ ì¼í• ê³„ì‚°ì‹œ {f"{int((query_result1_monthlySales.iat[0,0])):,}"}ì´ê³  ëª©í‘œëŠ” {f"{int((query_result1_monthlySales.iat[0,1])):,}"}ì´ì•¼.
    ë‹¹ì›” ë§¤ì¶œì€ ì¼í• ê³„ì‚°ì‹œ ~~ì´ê³  ëª©í‘œë§¤ì¶œì€ ~~ ìœ¼ë¡œ, ëª©í‘œëŒ€ë¹„ ì–¼ë§ˆ ë‹¬ì„±í–ˆë‹¤ì˜ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.
    ê·¸ë¦¬ê³  ì¶”ê°€ë¡œ ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•´ ì•„ì£¼ ê°„ë‹¨íˆ ì½”ë©˜íŠ¸ë¥¼ í•´ì¤˜.
    ~ìŠµë‹ˆë‹¤ ì²´ë¡œ ì•Œë ¤ì¤˜

    ê·¸ë¦¬ê³  ì „ë…„ë™ì›”ëŒ€ë¹„ì–´ë–¤ì§€ 3ì¤„ì´ë‚´ë¡œ ê°„ë‹¨íˆ ì•Œë ¤ì¤˜.

    ì•ìœ¼ë¡œ ì–´ë–»ê²Œ í•´ì•¼ê² ë‹¤ëŠ” ì‚¬ê²¬ì€ ì“°ì§€ë§ˆ.
    í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.
    <ì¼ìë³„ ì´ ë§¤ì¶œ>
    {query_result1_dailySales}

    < ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ>
    {query_result1_monthlySales}
    """,
    config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
            # tools=[RAG],
            temperature=0.5,
            labels=LABELS
        )

    )
    # ì½”ë©˜íŠ¸ ì¶œë ¥
    return response1_salesComment.text

# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

# ## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
# font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
# if Path(font_path).exists():
#     fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
#     mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
#     mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
# else:
#     print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

## ê·¸ë˜í”„ ê·¸ë¦¬ê¸° : arg ê°’ìœ¼ë¡œ ê²Œì„ ì½”ë“œ
def daily_revenue_graph_draw(joyplegameid: int, gameidx: str, **context):

    df_daily = context['task_instance'].xcom_pull(
        task_ids='daily_revenue_query',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='daily_revenue_df'
    )
    
    x  = df_daily.iloc[:, 0]
    y1 = pd.to_numeric(df_daily.iloc[:, 1], errors='coerce')
    y2 = pd.to_numeric(df_daily.iloc[:, 2], errors='coerce')

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(x, y2, marker='o',
            markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
            label=df_daily.columns[2])
    ax.plot(x, y1, marker='o',
            markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
            linestyle='--', label=df_daily.columns[1])  # ê²¹ì³ì„œ í‘œì‹œ

    # ì˜µì…˜
    plt.title("ì¼ìë³„ ë§¤ì¶œ")
    #plt.xlabel(query_result1_dailySales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
    #plt.ylabel(query_result1_dailySales.columns[1])

    # yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

    # xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
    plt.xticks(df_daily[df_daily.columns[0]][::2], rotation=45)

    # ë²”ë¡€ í‘œì‹œ - ê·¸ë˜í”„ë‘ ì•ˆê²¹ì¹˜ê²Œ
    plt.legend(
        bbox_to_anchor=(1.05, 1),   # ê·¸ë˜í”„ ì˜¤ë¥¸ìª½ ë°”ê¹¥ (x=1.05, y=1)
        loc='upper left',           # ì•µì»¤ ê¸°ì¤€ ìœ„ì¹˜
        borderaxespad=0.             # ì¶•ê³¼ ê°„ê²©
    )

    # yì¶• 0ë¶€í„° ì‹œì‘ (ì•ˆí•˜ë©´ ëˆˆê¸ˆ ìµœì†Œê°’ ìì¢… ì¡°ì •)
    plt.ylim(0, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§

    # yì¶• ë³´ì¡°ì„ 
    plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„
    #plt.grid(axis='x', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

    #plt.xlabel("ë‚ ì§œ")
    #plt.ylabel("ë§¤ì¶œ")

    #plt.show()
    # ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
    plt.tight_layout()


    # í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
    # #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
    # ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
    ####################################### ì´ë¯¸ì§€ íŒŒì¼ì„ ì €ì¥í•  pathê°€ í•„ìš”í•¨ #####################
    filepath1_dailySales = "graph1_dailySales.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'


## ì›”ê°„ ë§¤ì¶œ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
def daily_revenue_YOY_graph_draw(joyplegameid: int, gameidx: str, **context):

    query_result1_monthlySales = context['task_instance'].xcom_pull(
        task_ids='Daily_revenue_YOY_query',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='Daily_revenue_YOY_df'
    )

    x  = query_result1_monthlySales.iloc[:, 0]
    y1 = pd.to_numeric(query_result1_monthlySales.iloc[:, 1], errors='coerce')
    y2 = pd.to_numeric(query_result1_monthlySales.iloc[:, 2], errors='coerce')

    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(x, y2, marker='o',
            markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
            label=query_result1_monthlySales.columns[2])
    ax.plot(x, y1, marker='o',
            markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
            linestyle='--', label=query_result1_monthlySales.columns[1])  # ê²¹ì³ì„œ í‘œì‹œ

    # ì˜µì…˜
    plt.title("ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ")
    #plt.xlabel(query_result1_monthlySales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
    #plt.ylabel(query_result1_monthlySales.columns[1])

    # yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

    # xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
    plt.xticks(query_result1_monthlySales[query_result1_monthlySales.columns[0]][::1], rotation=45)

    # ë²”ë¡€ í‘œì‹œ - ê·¸ë˜í”„ë‘ ì•ˆê²¹ì¹˜ê²Œ
    plt.legend(
        bbox_to_anchor=(1.05, 1),   # ê·¸ë˜í”„ ì˜¤ë¥¸ìª½ ë°”ê¹¥ (x=1.05, y=1)
        loc='upper left',           # ì•µì»¤ ê¸°ì¤€ ìœ„ì¹˜
        borderaxespad=0.             # ì¶•ê³¼ ê°„ê²©
    )

    # y ì¶• ì¡°ì • (20ì–µë¶€í„°)
    plt.ylim(2000000000, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§

    # yì¶• ë³´ì¡°ì„ 
    plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„
    #plt.grid(axis='x', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

    #plt.xlabel("month")
    #plt.ylabel("ë§¤ì¶œ")

    #plt.show()
    # ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
    plt.tight_layout()


    # í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
    # #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
    # ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
    filePath1_monthlySales = "graph1_monthlySales.png"
    plt.savefig(filePath1_monthlySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filePath1_monthlySales}')
    blob.upload_from_filename(filePath1_monthlySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filePath1_monthlySales)

    return f'{gameidx}/{filePath1_monthlySales}'



# 1) íŒŒì¼ ê²½ë¡œ
def merge_daily_graph(joyplegameid: int, gameidx: str):
    p1 = daily_revenue_graph_draw(joyplegameid, gameidx)
    p2 = daily_revenue_YOY_graph_draw(joyplegameid, gameidx)

    # 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
    blob1 = bucket.blob(p1)
    blob2 = bucket.blob(p2)

    im1 = blob1.download_as_bytes()
    im2 = blob2.download_as_bytes()

    im1 = Image.open(BytesIO(im1))
    im2 = Image.open(BytesIO(im2))

    # ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
    target_h = max(im1.height, im2.height)

    def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas

    im1_p = pad_to_height(im1, target_h)
    im2_p = pad_to_height(im2, target_h)

    gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
    bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

    out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
    out.paste(im1_p, (0, 0), im1_p)
    out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

    # 3) GCSì— ì €ì¥
    output_buffer = BytesIO()
    out.save(output_buffer, format='PNG')
    output_buffer.seek(0)

    # GCS ê²½ë¡œ
    gcs_path = f'{gameidx}/graph1_dailySales_monthlySales.png'
    blob = bucket.blob(gcs_path)
    blob.upload_from_string(output_buffer.getvalue(), content_type='image/png')

    return gcs_path


def daily_revenue_data_upload_to_notion(joyplegameid: int, gameidx: str, **context):

    PAGE_INFO=context['task_instance'].xcom_pull(
        task_ids = 'make_gameframework_notion_page',
        key='page_info'
    )
    query_result1_dailySales=context['task_instance'].xcom_pull(
        task_ids='daily_revenue_query',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='daily_revenue_df'
    )

    query_result1_monthlySales=context['task_instance'].xcom_pull(
        task_ids='Daily_revenue_YOY_query',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='Daily_revenue_YOY_df'
    )

    notion.blocks.children.append(
        PAGE_INFO["id"],
        children=[
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "\n\n1. ì¼ìë³„ ë§¤ì¶œ" }}]
                },
            }
        ],
    )

    gcs_path = f'{gameidx}/graph1_dailySales_monthlySales.png'
    blob = bucket.blob(gcs_path)
    image_bytes = blob.download_as_bytes()
    filename = 'graph1_dailySales_monthlySales.png'

    ########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
    # ì¼ìë³„ ë§¤ì¶œ
    # ê·¸ë˜í”„ëŠ” íŒŒì¼ ì €ì¥í›„ ì˜¬ë¦¬ëŠ” êµ¬ì¡°ë°–ì— ë˜ì§€ì•Šì•„ì„œ
    # 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
    create_url = "https://api.notion.com/v1/file_uploads"
    payload = {
        "filename": filename,
        "content_type": "image/png"
    }
    headers_json = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }
    resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
    resp.raise_for_status()
    file_upload = resp.json()
    file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
    upload_url = file_upload[upload_url]

    # 2) ì´ë¯¸ì§€ ì—…ë¡œë“œ
    headers_upload = {
        "Content-Type": "image/png"
    }
    requests.put(upload_url, headers=headers_upload, data=image_bytes)

    # file_upload["upload_url"] ë„ ì‘ë‹µì— í¬í•¨ë¨
    # 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data)
    send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
    files = {"file": (filename, BytesIO(image_bytes), "image/png")}
    headers_send = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION
    }
    send_resp = requests.post(send_url, headers=headers_send, files=files)
    send_resp.raise_for_status()

    # 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
    append_url = f"https://api.notion.com/v1/blocks/{file_upload_id}/children"
    append_payload = {
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "file_upload",
                    "file_upload": {"id": file_upload_id},
                    # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
                }
            }
        ]
    }

    headers_json_patch = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }
    append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
    append_resp.raise_for_status()

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO["id"],
        df=query_result1_dailySales,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¼ìë³„ ë§¤ì¶œ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO["id"],
        df=query_result1_monthlySales,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    response1_salesComment = daily_revenue_gemini(joyplegameid=joyplegameid)

    ## ì œë¯¸ë‚˜ì´
    blocks = md_to_notion_blocks(response1_salesComment)
    notion.blocks.children.append(
        block_id=PAGE_INFO["id"],
        children=blocks
    )

    return True




# 2. ìì²´ê²°ì œ ë§¤ì¶œ
def inhouse_sales_query(joyplegameid: int, **context):
    query = f"""
    select logdatekst, cast(sum(pgpricekrw) as int64) as rev
    from
    (SELECT t1.*,
        t2.PGRole,
        t2.PlatformDeviceTypeName,
        t2.PGName,
        t2.PGBuyCount,
        t2.PGPriceKRW
    FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V` AS t1,
    UNNEST(t1.PaymentDetailArrayStruct) AS t2
    where joyplegameid = {joyplegameid}
    and pgrole = 'ìì²´ê²°ì œ'
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )
    group by 1 order by 1

    """
    query_result = query_run_method('2_inhouse_sales', query)

    context['task_instance'].xcom_push(key='inhouse_sales_df', value=query_result)

    return True

### 2> 24ë…„ë¶€í„° ì›”ë³„ ìì²´ê²°ì œ ë§¤ì¶œ
def inhouse_sales_before24_query(joyplegameid: int, **context):
    query = f"""
    select a.month
    , cast(a.rev_all as int64) as rev_all
    , cast(b.rev as int64) as rev_self
    , safe_divide(b.rev,a.rev_all) as self_per
    from
    (select month, sum(pricekrw) as rev_all
    from
    (select *,format_date('%Y-%m', logdatekst ) as month
    FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>='2024-01-01'
    and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
    group by 1
    ) as a

    left join
    (select month, cast(sum(pgpricekrw) as int64) as rev
    from
    (SELECT t1.*,
        t2.PGRole,
        t2.PlatformDeviceTypeName,
        t2.PGName,
        t2.PGBuyCount,
        t2.PGPriceKRW,
        format_date('%Y-%m', logdatekst ) as month
    FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V` AS t1,
    UNNEST(t1.PaymentDetailArrayStruct) AS t2
    where joyplegameid = {joyplegameid}
    and pgrole = 'ìì²´ê²°ì œ'
    and logdatekst>='2024-01-01'
    and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
    group by 1) as b
    on a.month = b.month
    order by month
    """

    query_result = query_run_method('2_inhouse_sales', query)
    context['task_instance'].xcom_push(key='inhouse_sales_before24_df', value=query_result)

    return True

## ì œë¯¸ë‚˜ì´ í”„ë¡¬í”„íŠ¸ 
def inhouses_revenue_gemini(joyplegameid: int, **context):
    
    inhouse_sales = context['task_instance'].xcom_pull(
        task_ids='inhouse_sales_query',
        key='inhouse_sales_df'
    )
    inhouse_sales_before24 = context['task_instance'].xcom_pull(
        task_ids='inhouse_sales_before24_query',
        key='inhouse_sales_before24_df'
    )

    prompt_2 = f"""

    1. ì•„ë˜ëŠ” ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œê³¼ ê³¼ê±°ë¶€í„° ì¥ê¸°ì ì¸ ìì²´ê²°ì œ ë§¤ì¶œì´ì•¼.ê°„ë‹¨í•˜ê²Œ í•´ì„í•´ì¤˜.
    2. ìì²´ê²°ì œì— ëŒ€í•œ ì •ì˜ë¥¼ ì“¸ í•„ìš”ëŠ” ì—†ì–´.
    3. ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ê³ , ì¥ê¸°ì ì¸ ìì²´ê²°ì œ íŠ¸ë Œë“œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì¤˜.
    4. ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œì™€ ì¥ê¸°ì ì¸ ìì²´ê²°ì œ íŠ¸ë Œë“œ ë‹¨ë½ì„ ë‚˜ëˆ ì¤˜. ì˜ˆ) <ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œ> , <ì¥ê¸°ì  ìì²´ê²°ì œ íŠ¸ë Œë“œ>
    5. ë‚´ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì“°ì§€ë§ˆ.
    6. ë³€ìˆ˜ëª…ì— ëŒ€í•´ì„  ì–¸ê¸‰í•˜ì§€ë§ˆ.
    7. ìì²´ê²°ì œë€, êµ¬ê¸€ì´ë‚˜ ì• í”Œì˜ ë§ˆì¼“ ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°í•˜ê¸° ìœ„í•´ ìˆ˜ìˆ˜ë£Œê°€ ë‚®ì€ ê²°ì œ í”Œë«í¼ì—ì„œ ê²°ì œí•˜ëŠ” ê²ƒì„ ë§í•´.
    8. ë‹¤ìŒì€ ìì²´ê²°ì œì— ëŒ€í•œ ë¶„ì„ì…ë‹ˆë‹¤ ì´ëŸ° ì‚¬ì „ì— ë§ í•˜ì§€ë§ê³  ê·¸ëƒ¥ ë¶„ì„ê²°ê³¼ë¥¼ ì•Œë ¤ì¤˜
    9. ì‚¬ê²¬ì„ ì“°ì§€ë§ê³  ê·¸ëƒ¥ í˜„ì¬ ìƒí™©ì— ëŒ€í•´ íŒ©íŠ¸ë§Œ ì•Œë ¤ì¤˜.


    < ì„œì‹ ìš”êµ¬ì‚¬í•­ >
    í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.

    <ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ>
    {inhouse_sales}

    < ì¥ê¸°ì  ìì²´ê²°ì œ ë§¤ì¶œ>
    {inhouse_sales_before24}

    """

    response2_selfPaymentSales = genai_client.models.generate_content(
        model=MODEL_NAME,
        contents=prompt_2,
        config=types.GenerateContentConfig(

            # ì˜ì–´ë¡œ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì˜ ì´í•´í•  ìˆ˜ ìˆìŒ.
            system_instruction=SYSTEM_INSTRUCTION,
            #tools=[rag_retrieval_tool_test],
            temperature=0.5,
            labels=labels
            # max_output_tokens=2048
        )
    )

    return response2_selfPaymentSales.text

## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
# font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
# if Path(font_path).exists():
#     fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
#     mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
#     mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
# else:
#     print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

def inhouse_revenue_graph_draw(joyplegameid: int, gameidx: str, **context):

    query_result2_dailySelfPaymentSales = context['task_instance'].xcom_pull(
        task_ids='inhouse_sales_query',
        key='inhouse_sales_df'
    )
    
    # Seaborn ì„  ê·¸ë˜í”„
    sns.lineplot(
        x= query_result2_dailySelfPaymentSales.columns[0],
        y=query_result2_dailySelfPaymentSales.columns[1],
        data=query_result2_dailySelfPaymentSales,
        marker="o"
        )

    # ì˜µì…˜
    plt.title("ì´ë²ˆë‹¬ ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ")
    #plt.xlabel(query_result2_dailySelfPaymentSales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
    #plt.ylabel(query_result2_dailySelfPaymentSales.columns[1])

    # yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

    # xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
    plt.xticks(query_result2_dailySelfPaymentSales[query_result2_dailySelfPaymentSales.columns[0]][::1], rotation=45)

    # yì¶• 0ë¶€í„° ì‹œì‘
    plt.ylim(0, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§
    # yì¶• ë³´ì¡°ì„ 
    plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

    # x,yì¶• ì œê±°
    plt.xlabel(None)
    plt.ylabel(None)

    #plt.show()
    # ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
    plt.tight_layout()


    # í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
    # #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
    # ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨

    ####################################### ì´ë¯¸ì§€ íŒŒì¼ì„ ì €ì¥í•  pathê°€ í•„ìš”í•¨ #####################
    filepath1_inhouseSales = "graph1_dailySelfPaymentSales.png"
    plt.savefig(filepath1_inhouseSales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_inhouseSales}')
    blob.upload_from_filename(filepath1_inhouseSales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_inhouseSales)

    return f'{gameidx}/{filepath1_inhouseSales}'



## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
# font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
# if Path(font_path).exists():
#     fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
#     mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
#     mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
# else:
#     print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

def inhouse_revenue_monthly_graph_draw(joyplegameid: int, gameidx: str, **context):
    
    query_result2_monthlySelfPaymentSales = context['task_instance'].xcom_pull(
        task_ids='inhouse_sales_before24_query',
        key='inhouse_sales_before24_df'
    )

    # Figure & Axes ìƒì„±
    fig, ax1 = plt.subplots(figsize=(10,5))

    # ì˜µì…˜
    plt.title("ì›”ë³„ ìì²´ê²°ì œ ë§¤ì¶œ & ìì²´ê²°ì œ ë§¤ì¶œ ë¹„ì¤‘ (24ë…„1ì›”~) ")

    # ì²« ë²ˆì§¸ yì¶• (ì™¼ìª½, ë§‰ëŒ€ê·¸ë˜í”„)
    ax1.bar(query_result2_monthlySelfPaymentSales["month"],
            query_result2_monthlySelfPaymentSales["rev_self"],
            color="#5B9BD5",
            #label="Sales"
            )
    #ax1.set_ylabel("Sales", color="black")
    ax1.tick_params(axis="y", labelcolor="black")

    # ë‘ ë²ˆì§¸ yì¶• (ì˜¤ë¥¸ìª½, ì„ ê·¸ë˜í”„)
    ax2 = ax1.twinx()
    ax2.plot(query_result2_monthlySelfPaymentSales["month"],
            query_result2_monthlySelfPaymentSales["self_per"],
            color="#ED7D31",
            marker="o",
            #label="Users"
            )
    #ax2.set_ylabel("Users", color="black")
    ax2.tick_params(axis="y", labelcolor="black")

    # ğŸ‘‰ ì„  ìœ„ì— ë°ì´í„° ë ˆì´ë¸” í‘œì‹œ
    for x, y in zip(query_result2_monthlySelfPaymentSales["month"],
                    query_result2_monthlySelfPaymentSales["self_per"]):
        ax2.annotate(f"{y:.0%}",  # 0.23 â†’ "23%"
                    xy=(x, y),
                    xytext=(0, 5),  # ì‚´ì§ ìœ„ë¡œ
                    textcoords="offset points",
                    ha="center", color="black"
                    )


    # yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
    ax1.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))

    # í¼ì„¼íŠ¸ í¬ë§· ìë™ ì ìš© (self_perê°€ 0~1ì´ë©´ 1.0, 0~100ì´ë©´ 100)
    maxv = float(query_result2_monthlySelfPaymentSales["self_per"].max())
    ax2.yaxis.set_major_formatter(PercentFormatter(1.0 if maxv <= 1.5 else 100))

    # xì¶• ëˆˆê¸ˆ(ê°’) ì„¸ë¡œ íšŒì „ â€” ì¶• ê°ì²´ì— ì§ì ‘ ì ìš©
    for tick in ax1.get_xticklabels():
        tick.set_rotation(90)
        tick.set_ha("center")  # ë˜ëŠ” "right"ë¡œ ë°”ê¿”ë„ ë¨

    # ì œëª© & ê²©ì
    ax1.grid(axis="y", linestyle="--", alpha=0.7)

    plt.tight_layout()

    # í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
    # #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
    # ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
    filepath1_inhouseMonthlySales = "graph1_monthlySelfPaymentSales.png"
    plt.savefig(filepath1_inhouseMonthlySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_inhouseMonthlySales}')
    blob.upload_from_filename(filepath1_inhouseMonthlySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_inhouseMonthlySales)

    return f'{gameidx}/{filepath1_inhouseMonthlySales}'


## ê·¸ë˜í”„ í•©ì¹˜ê¸°
### ìì²´ê²°ì œ ì¼ìë³„ + ìì²´ê²°ì œ ì›”ë³„

### Rê·¸ë£¹ë³„ ë§¤ì¶œê·¸ë˜í”„ì™€ PU ê·¸ë˜í”„ í•©ì¹˜ê¸°

def merge_inhouse_graph(joyplegameid: int, gameidx: str):
    # 1) íŒŒì¼ ê²½ë¡œ
    p1 = inhouse_revenue_graph_draw(joyplegameid, gameidx)
    p2 = inhouse_revenue_monthly_graph_draw(joyplegameid, gameidx)

    # 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
    blob1 = bucket.blob(p1)
    blob2 = bucket.blob(p2)

    im1 = blob1.download_as_bytes()
    im2 = blob2.download_as_bytes()

    im1 = Image.open(BytesIO(im1))
    im2 = Image.open(BytesIO(im2))

    # ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
    target_h = max(im1.height, im2.height)

    def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas

    im1_p = pad_to_height(im1, target_h)
    im2_p = pad_to_height(im2, target_h)

    gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
    bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

    out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
    out.paste(im1_p, (0, 0), im1_p)
    out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

    # 3) GCSì— ì €ì¥
    output_buffer = BytesIO()
    out.save(output_buffer, format='PNG')
    output_buffer.seek(0)

    # GCS ê²½ë¡œ
    gcs_path = f'{gameidx}/graph2_selfPaymentSales.png'
    blob = bucket.blob(gcs_path)
    blob.upload_from_string(output_buffer.getvalue(), content_type='image/png')

    return gcs_path



def inhouse_revenue_data_upload_to_notion(joyplegameid: int, gameidx: str, **context):

    PAGE_INFO=context['task_instance'].xcom_pull(
        task_ids = 'make_gameframework_notion_page',
        key='page_info'
    )
    query_result1_inhouseSales = context['task_instance'].xcom_pull(
        task_ids = 'inhouse_sales_query',
        key='inhouse_sales_df'
    )
    query_result1_inhouseMonthlySales = context['task_instance'].xcom_pull(
        task_ids='inhouse_sales_before24_query',
        key='inhouse_sales_before24_df'
    )
    
    ########### (1) ì œëª©
    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "2. ìì²´ê²°ì œ ë§¤ì¶œ" }}]
                },
            }
        ],
    )

    gcs_path = f'{gameidx}/graph2_selfPaymentSales.png'
    blob = bucket.blob(gcs_path)
    image_bytes = blob.download_as_bytes()
    filename = 'graph2_selfPaymentSales.png'

    ########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
    create_url = "https://api.notion.com/v1/file_uploads"
    payload = {
        "filename": filename,
        "content_type": "image/png"
    }
    headers_json = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }
    resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
    resp.raise_for_status()
    file_upload = resp.json()
    file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
    upload_url = file_upload[upload_url]

    # 2) ì´ë¯¸ì§€ ì—…ë¡œë“œ
    headers_upload = {
        "Content-Type": "image/png"
    }
    requests.put(upload_url, headers=headers_upload, data=image_bytes)

    send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
    files = {"file": (filename, BytesIO(image_bytes), "image/png")}
    headers_send = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION
    }
    send_resp = requests.post(send_url, headers=headers_send, files=files)
    send_resp.raise_for_status()

    # 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
    append_url = f"https://api.notion.com/v1/blocks/{file_upload_id}/children"
    append_payload = {
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "file_upload",
                    "file_upload": {"id": file_upload_id},
                    # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
                }
            }
        ]
    }

    headers_json_patch = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }
    append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
    append_resp.raise_for_status()

    ## (3) ë¡œë°ì´í„°
    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result1_inhouseSales,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result1_inhouseMonthlySales,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¥ê¸° ìì²´ê²°ì œ ë§¤ì¶œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    ## (4) ì œë¯¸ë‚˜ì´ í•´ì„
    gemini_text = inhouses_revenue_gemini(joyplegameid)
    blocks = md_to_notion_blocks(gemini_text)

    notion.blocks.children.append(
        block_id=PAGE_INFO['id'],
        children=blocks
    )

    return True




## ì´ë²ˆë‹¬ ê°€ì… ìœ ì €ì˜ êµ­ê°€ë³„ ë§¤ì¶œ
def cohort_by_country_revenue(joyplegameid: int, **context):
    query = f"""
    with countryRev as (
    select country2 as country, rev_rank2 as rev_rank, sum(rev) as rev
    from
    (select country, rev
    , case when rev_rank <= 9 then country  when rev_rank > 9 then 'etc' end as country2 # rev ê¸°ì¤€ 10ìœ„ë¶€í„°ëŠ” etc ë¡œ í‘œê¸°
    , case when rev_rank <= 9 then rev_rank when rev_rank > 9 then 10 end as rev_rank2
    from
    (select country, rev, row_number() OVER (ORDER BY rev desc ) AS rev_rank # rev ìˆœì„œëŒ€ë¡œ ë­í¬
    from
    (select countrycode as country, cast(sum(pricekrw) as int64) as rev
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    group by 1)
    )
    )
    group by 1,2
    order by rev_rank # etc êµ­ê°€ê°€ ë§¨ ë’¤ë¡œ ê°€ì•¼í•¨
    ),

    allRev as  (
    select cast(sum(pricekrw) as int64) as rev
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )

    select a.*, safe_divide(a.rev,b.rev) as rev_percent
    from
    (select * from countryRev ) as a
    cross join
    (select * from allRev) as b
    order by rev_rank

    """
    query_result=query_run_method('3_global_ua', query)

    context['task_instance'].xcom_push(key='cohort_by_country_revenue_df', value=query_result)
    
    return True

## ì´ë²ˆë‹¬ êµ­ê°€ë³„ COST
def cohort_by_country_cost(joyplegameid: int, **context):
    query = f"""
    with countryCost as (
    select country2 as country, cost_rank2 as cost_rank, sum(cost) as cost
    from
    (select country, cost
    , case when cost_rank <= 9 then country when cost_rank > 9 then 'etc' end as country2 # cost ìˆœì„œëŒ€ë¡œ 10ìœ„ ë¶€í„°ëŠ” etc ë¡œ
    , case when cost_rank <= 9 then cost_rank else 10 end as cost_rank2
    from
    (select country, cost, row_number() OVER (ORDER BY cost desc ) AS cost_rank # cost ìˆœì„œë¡œ rank
    from
    (select countrycode as country, cast(sum(cost) as int64) cost
    from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
    where joyplegameid = {joyplegameid}
    and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    group by countrycode))
    )
    group by 1,2
    order by cost_rank # etc êµ­ê°€ê°€ ë§¨ ë’¤ë¡œ ê°€ì•¼í•¨
    ),

    allCost as (
    select cast(sum(cost) as int64) cost
    from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
    where joyplegameid = {joyplegameid}
    and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )

    select a.*, safe_divide(a.cost,b.cost) as cost_percent
    from
    (select * from countryCost) as a
    cross join
    (select * from allCost) as b
    order by cost_rank


    """
    query_result =query_run_method('3_global_ua', query)
    context['task_instance'].xcom_push(key='cohort_by_country_cost_df', value=query_result)
    
    return True


## êµ­ê°€ë³„ rev, cost í”„ë¡¬í”„íŠ¸
### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸
def cohort_by_gemini(joyplegameid: int, **context):
    
    cohort_country_revenue = context['task_instance'].xcom_pull(
        task_ids='cohort_by_country_revenue',
        key='cohort_by_country_revenue_df'
    )
    cohort_country_cost = context['task_instance'].xcom_pull(
        task_ids='cohort_by_country_cost',
        key='cohort_by_country_cost_df'
    )

    #client = genai.Client(api_key="AIzaSyAVv2B6DM6w9jd1MxiP3PbzAEMkl97SCGY")
    response3_revAndCostByCountry = genai_client.models.generate_content(
    model='gemini-2.5-flash',

    contents = f"""
    ì´ë²ˆë‹¬ì— ì–´ë–¤ êµ­ê°€ì— ë§ˆì¼€íŒ…í–ˆê³ , ì–´ë–¤ êµ­ê°€ì—ì„œ ì‹ ê·œìœ ì €ì˜ ë§¤ì¶œì´ ë‚˜ì™”ëŠ”ì§€ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì¤„ê²Œ.
    ê°„ë‹¨í•˜ê²Œ í˜„í™© ìš”ì•½í•´ì¤˜.

    ë‹¹ì›” ë§ˆì¼€íŒ…ë¹„ìš©ì€ ì–¼ë§ˆì´ë©° ë‹¹ì›” ì‹ ê·œìœ ì € ë§¤ì¶œì€ ì–¼ë§ˆì…ë‹ˆë‹¤ë¥¼ ë¨¼ì € í•œì¤„ë¡œ ì„œë‘ì— ì–¸ê¸‰í•´ì¤˜.
    ì´ë²ˆë‹¬ COSTë§ì´ ì“´ êµ­ê°€ë“¤ ê°ê° COST ë¹„ì¤‘ì´ ëª‡% ì¸ì§€ í•œì¤„ì— ì¨ì£¼ê³ ,
    ì‹ ê·œìœ ì € ë§¤ì¶œ ë†’ì€ êµ­ê°€ë“¤ ê°ê° ëª‡% ë§¤ì¶œ ë¹„ì¤‘ì¸ì§€ í•œì¤„ì— ì¨ì¤˜ ì•Œë ¤ì¤˜.
    ê·¸ë¦¬ê³  ì£¼ìš” êµ­ê°€ë“¤ì— ëŒ€í•´ì„œ COST ë¹„ì¤‘ê³¼ ë§¤ì¶œë¹„ì¤‘ì„ ë¹„êµí•´ì„œ íŠ¹ì´í•œì ì´ ìˆëŠ”ê²ƒë§Œ ì•Œë ¤ì¤˜.

    ë§¤ì¶œê³¼ COST ì˜ ì•¡ìˆ˜ ì ˆëŒ“ê°’ì„ ë¹„êµí•˜ì§€ ë§ê³  ë¹„ì¤‘ì„ ë¹„êµí•´ì¤˜.
    etc ëŠ” ê¸°íƒ€ êµ­ê°€ë“¤ ì´ í•© í•œ ê°’ì´ë¼ì„œ etc ì— ëŒ€í•´ì„œëŠ” ì–¸ê¸‰í•˜ì§€ ë§ì•„ì¤˜.
    ë§ˆì¼€íŒ… íš¨ìœ¨ê°œì„ ì´ í•„ìš”í•˜ë‹¤ëŠ”ë§ì€ í•˜ì§€ë§ì•„ì¤˜.

    <ì›í•˜ëŠ” ì„œì‹>
    1. ìš”ì•½í•´ì£¼ê² ë‹¤ ë§ í•˜ì§€ë§ê³  ìš”ì•½í•œ ë‚´ìš©ì— ëŒ€í•´ì„œë§Œ ì ì–´ì£¼ë©´ ë¼.
    2. ìŠµë‹ˆë‹¤. ì²´ë¡œ ì¨ì¤˜
    3. í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.

    <ë°ì´í„° ì„¤ëª…>
    ë§¤ì¶œì´ë‘ ë§ˆì¼€íŒ… ë¹„ìš©ì´ë‘ ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ 9ê°œ êµ­ê°€ì™€ ê·¸ ì´í›„ 10ë²ˆì§¸ êµ­ê°€ë¶€í„°ëŠ” ì „ë¶€ etc êµ­ê°€ë¡œ ì²˜ë¦¬í–ˆì–´.
    etc ëŠ” êµ­ê°€ê°€ ì•„ë‹ˆë¼ ë‚˜ë¨¸ì§€ êµ­ê°€ ì´í•©ì´ì•¼.

    <ì´ë²ˆë‹¬ ê°€ì…ìœ ì €ì˜ êµ­ê°€ë³„ ë§¤ì¶œ>
    {cohort_country_revenue}

    <ì´ë²ˆë‹¬ êµ­ê°€ë³„ ë§ˆì¼€íŒ… ë¹„ìš©>
    {cohort_country_cost}

    """,
    config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
            # tools=[RAG],
            temperature=0.5,
            labels=labels
        )

    )
    # ì½”ë©˜íŠ¸ ì¶œë ¥
    return response3_revAndCostByCountry.text


# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

## OSë³„ cost
def os_cost(joyplegameid: int, **context):
    query = f"""
    with osCost as (
    select os, cast(sum(cost) as int64) cost
    from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
    where joyplegameid = {joyplegameid}
    and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    group by os
    ),

    allCost as (
    select cast(sum(cost) as int64) cost
    from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
    where joyplegameid = {joyplegameid}
    and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )

    select a.*, safe_divide(a.cost,b.cost) as cost_percent
    from
    (select * from osCost) as a
    cross join
    (select * from allCost) as b
    """

    query_result =query_run_method('3_global_ua', query)
    context['task_instance'].xcom_push(key='os_cost_df', value=query_result)

    return True

## OSë³„ ë§¤ì¶œ
def os_rev(joyplegameid: int, **context):
    query = f"""
    with osRev as (

    select os, rev from (
    select os, cast(sum(pricekrw) as int64) as rev
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    group by 1)
    where rev>0
    ),

    allRev as (
    select cast(sum(pricekrw) as int64) as rev
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = {joyplegameid}
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )

    select a.*, safe_divide(a.rev,b.rev) as rev_percent
    from
    (select * from osRev) as a
    cross join
    (select * from allRev) as b
    """
    ## 129.93MB
    query_result =query_run_method('3_global_ua', query)
    context['task_instance'].xcom_push(key='os_rev_df', value=query_result)

    return True


### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸

#client = genai.Client(api_key="AIzaSyAVv2B6DM6w9jd1MxiP3PbzAEMkl97SCGY")
def os_by_gemini(joyplegameid: int, **context):
    
    os_rev_df= context['task_instance'].xcom_pull(
        task_ids='os_cost',
        key='os_cost_df'
    )
    os_cost_df= context['task_instance'].xcom_pull(
        task_ids='os_rev',
        key='os_rev_df'
    )

    response3_revAndCostByOs = genai_client.models.generate_content(
    model='gemini-2.5-flash',

    contents = f"""

    ì´ë²ˆë‹¬ì— IOS ì— ëª‡ % ë§ˆì¼€íŒ… ë¹„ìš© ì‚¬ìš©í–ˆìœ¼ë©° IOS ì˜ ë§¤ì¶œë¹„ì¤‘ì€ ëª‡% ì…ë‹ˆë‹¤.
    ì˜ í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜.


    <ì›í•˜ëŠ” ì„œì‹>
    1. ìš”ì•½í•´ì£¼ê² ë‹¤ ë§ í•˜ì§€ë§ê³  ìš”ì•½í•œ ë‚´ìš©ì— ëŒ€í•´ì„œë§Œ ì ì–´ì£¼ë©´ ë¼.
    2. ìŠµë‹ˆë‹¤. ì²´ë¡œ ì¨ì¤˜
    3. í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.


    <ë°ì´í„° ì„¤ëª…>


    <ì´ë²ˆë‹¬ ê°€ì…ìœ ì €ì˜ OSë³„ ë§¤ì¶œ>
    {os_rev_df}

    <ì´ë²ˆë‹¬ OSë³„ ë§ˆì¼€íŒ… ë¹„ìš©>
    {os_cost_df}
    """,
    config=types.GenerateContentConfig(
            system_instruction=SYSTEM_INSTRUCTION,
            # tools=[RAG],
            temperature=0.5,
            labels=labels
        )

    )
    # ì½”ë©˜íŠ¸ ì¶œë ¥
    return response3_revAndCostByOs.text

# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

### ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
## êµ­ê°€ë³„ ë§¤ì¶œ

def by_country_revenue_graph_draw(joyplegameid: int, gameidx: str, **context):
    
    query_result3_revByCountry = context['task_instance'].xcom_pull(
        task_ids = 'cohort_by_country_revenue',
        key='cohort_by_country_revenue_df'
    )

    sizes = query_result3_revByCountry["rev"].to_numpy()
    labels = query_result3_revByCountry["country"].to_numpy()
    total  = sizes.sum()

    fig, ax = plt.subplots(figsize=(5,5))
    wedges, _ = ax.pie(sizes, labels=None, startangle=90)

    # ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
    angles = [(p.theta1 + p.theta2)/2 for p in wedges]
    inside_r, outside_r = 0.6, 1.28

    # 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
    texts = []
    for ang, size, name in zip(angles, sizes, labels):
        percent = size / total * 100
        txt = f"{name} ({percent:.1f}%)"
        x_in = np.cos(np.deg2rad(ang)) * inside_r
        y_in = np.sin(np.deg2rad(ang)) * inside_r
        t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
        texts.append(t)

    # 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
    def any_overlaps(texts, renderer):
        bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
        overlaps = set()
        for i in range(len(bboxes)):
            for j in range(i+1, len(bboxes)):
                if bboxes[i].overlaps(bboxes[j]):
                    overlaps.add(i); overlaps.add(j)
        return overlaps

    # 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
    fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
    over_idx = any_overlaps(texts, fig.canvas.get_renderer())

    # ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
    idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
    for i in idx_sorted:
        ang = angles[i]
        # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
        x_out = np.cos(np.deg2rad(ang)) * outside_r
        y_out = np.sin(np.deg2rad(ang)) * outside_r
        # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
        x_edge = np.cos(np.deg2rad(ang)) * 1.0
        y_edge = np.sin(np.deg2rad(ang)) * 1.0

        # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
        txt_str = texts[i].get_text()
        texts[i].set_visible(False)

        # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
        ha = 'left' if x_out >= 0 else 'right'
        ax.annotate(
            txt_str,
            xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
            xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
            ha=ha, va='center', fontsize=9, color='black',
            arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
        )
    ax.set_title("êµ­ê°€ë³„ ë§¤ì¶œ ë¹„ì¤‘", pad=24)
    #plt.title("êµ­ê°€ë³„ ë§¤ì¶œ ë¹„ì¤‘")
    plt.tight_layout()

    filepath1_dailySales = "graph3_revByCountry.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'



def by_country_cost_graph_draw(joyplegameid: int, gameidx: str, **context):
    
    query_result3_costByCountry = context['task_instance'].xcom_pull(
        task_ids = 'cohort_by_country_cost',
        key='cohort_by_country_cost_df'
    )

    ### êµ­ê°€ë³„ Cost
    sizes = query_result3_costByCountry["cost"].to_numpy()
    labels = query_result3_costByCountry["country"].to_numpy()
    total  = sizes.sum()


    fig, ax = plt.subplots(figsize=(5,5))
    wedges, _ = ax.pie(sizes, labels=None, startangle=90)

    # ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
    angles = [(p.theta1 + p.theta2)/2 for p in wedges]
    inside_r, outside_r = 0.6, 1.28

    # 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
    texts = []
    for ang, size, name in zip(angles, sizes, labels):
        percent = size / total * 100
        txt = f"{name} ({percent:.1f}%)"
        x_in = np.cos(np.deg2rad(ang)) * inside_r
        y_in = np.sin(np.deg2rad(ang)) * inside_r
        t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
        texts.append(t)

    # 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
    def any_overlaps(texts, renderer):
        bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
        overlaps = set()
        for i in range(len(bboxes)):
            for j in range(i+1, len(bboxes)):
                if bboxes[i].overlaps(bboxes[j]):
                    overlaps.add(i); overlaps.add(j)
        return overlaps

    # 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
    fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
    over_idx = any_overlaps(texts, fig.canvas.get_renderer())

    # ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
    idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
    for i in idx_sorted:
        ang = angles[i]
        # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
        x_out = np.cos(np.deg2rad(ang)) * outside_r
        y_out = np.sin(np.deg2rad(ang)) * outside_r
        # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
        x_edge = np.cos(np.deg2rad(ang)) * 1.0
        y_edge = np.sin(np.deg2rad(ang)) * 1.0

        # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
        txt_str = texts[i].get_text()
        texts[i].set_visible(False)

        # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
        ha = 'left' if x_out >= 0 else 'right'
        ax.annotate(
            txt_str,
            xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
            xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
            ha=ha, va='center', fontsize=9, color='black',
            arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
        )
    ax.set_title("êµ­ê°€ë³„ COST ë¹„ì¤‘", pad=24)
    plt.tight_layout()


    filepath1_dailySales = "graph3_costByCountry.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'


def merge_contry_graph(joyplegameid: int, gameidx: str):
    p1=by_country_revenue_graph_draw(joyplegameid, gameidx)
    p2=by_country_cost_graph_draw(joyplegameid, gameidx)

    # 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
    blob1 = bucket.blob(p1)
    blob2 = bucket.blob(p2)

    im1 = blob1.download_as_bytes()
    im2 = blob2.download_as_bytes()

    im1 = Image.open(BytesIO(im1))
    im2 = Image.open(BytesIO(im2))

    # ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
    target_h = max(im1.height, im2.height)

    def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas

    im1_p = pad_to_height(im1, target_h)
    im2_p = pad_to_height(im2, target_h)

    gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
    bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

    out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
    out.paste(im1_p, (0, 0), im1_p)
    out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

    # 3) GCSì— ì €ì¥
    output_buffer = BytesIO()
    out.save(output_buffer, format='PNG')
    output_buffer.seek(0)

    # GCS ê²½ë¡œ
    gcs_path = f'{gameidx}/graph3_revAndCostByCountry.png'
    blob = bucket.blob(gcs_path)
    blob.upload_from_string(output_buffer.getvalue(), content_type='image/png')

    return gcs_path

### OS ë³„ ë§¤ì¶œ
def os_rev_graph_draw(joyplegameid: int, gameidx: str, **context):

    query_result3_revByOs = context['task_instance'].xcom_pull(
        task_ids='os_rev',
        key='os_rev_df'
    )

    sizes = query_result3_revByOs["rev"].to_numpy()
    labels = query_result3_revByOs["os"].to_numpy()
    total  = sizes.sum()


    fig, ax = plt.subplots(figsize=(5,5))
    wedges, _ = ax.pie(sizes, labels=None, startangle=90)

    # ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
    angles = [(p.theta1 + p.theta2)/2 for p in wedges]
    inside_r, outside_r = 0.6, 1.28

    # 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
    texts = []
    for ang, size, name in zip(angles, sizes, labels):
        percent = size / total * 100
        txt = f"{name} ({percent:.1f}%)"
        x_in = np.cos(np.deg2rad(ang)) * inside_r
        y_in = np.sin(np.deg2rad(ang)) * inside_r
        t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
        texts.append(t)

    # 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
    def any_overlaps(texts, renderer):
        bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
        overlaps = set()
        for i in range(len(bboxes)):
            for j in range(i+1, len(bboxes)):
                if bboxes[i].overlaps(bboxes[j]):
                    overlaps.add(i); overlaps.add(j)
        return overlaps

    # 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
    fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
    over_idx = any_overlaps(texts, fig.canvas.get_renderer())

    # ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
    idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
    for i in idx_sorted:
        ang = angles[i]
        # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
        x_out = np.cos(np.deg2rad(ang)) * outside_r
        y_out = np.sin(np.deg2rad(ang)) * outside_r
        # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
        x_edge = np.cos(np.deg2rad(ang)) * 1.0
        y_edge = np.sin(np.deg2rad(ang)) * 1.0

        # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
        txt_str = texts[i].get_text()
        texts[i].set_visible(False)

        # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
        ha = 'left' if x_out >= 0 else 'right'
        ax.annotate(
            txt_str,
            xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
            xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
            ha=ha, va='center', fontsize=9, color='black',
            arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
        )

    ax.set_title("OSë³„ ë§¤ì¶œ ë¹„ì¤‘", pad=24)
    plt.tight_layout()

    filepath1_dailySales = "graph3_revByOs.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'
    

### os ë³„ Cost
def os_cost_graph_draw(joyplegameid: int, gameidx: str, **context):

    query_result3_costByOs = context['task_instance'].xcom_pull(
        task_ids='os_cost',
        key='os_cost_df'
    )

    sizes = query_result3_costByOs["cost"].to_numpy()
    labels = query_result3_costByOs["os"].to_numpy()
    total  = sizes.sum()
    
    fig, ax = plt.subplots(figsize=(5,5))
    wedges, _ = ax.pie(sizes, labels=None, startangle=90)

    # ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
    angles = [(p.theta1 + p.theta2)/2 for p in wedges]
    inside_r, outside_r = 0.6, 1.28

    # 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
    texts = []
    for ang, size, name in zip(angles, sizes, labels):
        percent = size / total * 100
        txt = f"{name} ({percent:.1f}%)"
        x_in = np.cos(np.deg2rad(ang)) * inside_r
        y_in = np.sin(np.deg2rad(ang)) * inside_r
        t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
        texts.append(t)

    # 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
    def any_overlaps(texts, renderer):
        bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
        overlaps = set()
        for i in range(len(bboxes)):
            for j in range(i+1, len(bboxes)):
                if bboxes[i].overlaps(bboxes[j]):
                    overlaps.add(i); overlaps.add(j)
        return overlaps

    # 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
    fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
    over_idx = any_overlaps(texts, fig.canvas.get_renderer())

    # ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
    idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
    for i in idx_sorted:
        ang = angles[i]
        # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
        x_out = np.cos(np.deg2rad(ang)) * outside_r
        y_out = np.sin(np.deg2rad(ang)) * outside_r
        # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
        x_edge = np.cos(np.deg2rad(ang)) * 1.0
        y_edge = np.sin(np.deg2rad(ang)) * 1.0

        # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
        txt_str = texts[i].get_text()
        texts[i].set_visible(False)

        # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
        ha = 'left' if x_out >= 0 else 'right'
        ax.annotate(
            txt_str,
            xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
            xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
            ha=ha, va='center', fontsize=9, color='black',
            arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
        )

    ax.set_title("OSë³„ COST ë¹„ì¤‘", pad=24)
    plt.tight_layout()

    filepath1_dailySales = "graph3_costByOs.png"
    plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
    plt.close()

    blob = bucket.blob(f'{gameidx}/{filepath1_dailySales}')
    blob.upload_from_filename(filepath1_dailySales)

    # ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°„ ì´ë¯¸ì§€ íŒŒì¼ ì‚­ì œ
    os.remove(filepath1_dailySales)

    return f'{gameidx}/{filepath1_dailySales}'


def merge_os_graph(joyplegameid: int, gameidx: str):
    p1 = os_rev_graph_draw(joyplegameid, gameidx)
    p2 = os_cost_graph_draw(joyplegameid, gameidx)

    # 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
    blob1 = bucket.blob(p1)
    blob2 = bucket.blob(p2)

    im1 = blob1.download_as_bytes()
    im2 = blob2.download_as_bytes()

    im1 = Image.open(BytesIO(im1))
    im2 = Image.open(BytesIO(im2))

    # ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
    target_h = max(im1.height, im2.height)

    def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
        if img.height == h:
            return img
        canvas = Image.new("RGBA", (img.width, h), bg)
        # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
        y = (h - img.height) // 2
        canvas.paste(img, (0, y))
        return canvas

    im1_p = pad_to_height(im1, target_h)
    im2_p = pad_to_height(im2, target_h)

    gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
    bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

    out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
    out.paste(im1_p, (0, 0), im1_p)
    out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

    # 3) GCSì— ì €ì¥
    output_buffer = BytesIO()
    out.save(output_buffer, format='PNG')
    output_buffer.seek(0)

    # GCS ê²½ë¡œ
    gcs_path = f'{gameidx}/graph3_revAndCostByOs.png'
    blob = bucket.blob(gcs_path)
    blob.upload_from_string(output_buffer.getvalue(), content_type='image/png')

    return gcs_path


#### ë…¸ì…˜ì— ì—…ë¡œë“œ

def country_data_upload_to_notion(joyplegameid: int, gameidx: str, **context):

    PAGE_INFO=context['task_instance'].xcom_pull(
        task_ids = 'make_gameframework_notion_page',
        key='page_info'
    )

    ########### (1) ì œëª©
    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {
                    "rich_text": [{"type": "text", "text": {"content": "3. ê¸€ë¡œë²Œ ëª¨ê° ì§€í‘œ " }}]
                },
            }
        ],
    )

    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_3",
                "heading_3": {
                    "rich_text": [{"type": "text", "text": {"content": "(1) êµ­ê°€ë³„ ë§ˆì¼€íŒ…ë¹„ìš©ê³¼ ë§¤ì¶œë¹„ì¤‘" }}]
                },
            }
        ],
    )

    query_result3_revByCountry=context['task_instance'].xcom_pull(
        task_ids='cohort_by_country_revenue',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='cohort_by_country_revenue_df'
    )
    query_result3_costByCountry=context['task_instance'].xcom_pull(
        task_ids='cohort_by_country_cost',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='cohort_by_country_cost_df'
    )

    filePath3_revAndCostByCountry = merge_contry_graph(joyplegameid, gameidx)
    ########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
    ## IAP+ìœ ê°€ì ¬
    # 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
    create_url = "https://api.notion.com/v1/file_uploads"
    payload = {
        "filename": os.path.basename(filePath3_revAndCostByCountry),
        "content_type": "image/png"
    }
    headers_json = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }
    resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
    resp.raise_for_status()
    file_upload = resp.json()
    file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
    # file_upload["upload_url"] ë„ ì‘ë‹µì— í¬í•¨ë¨

    # 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data)
    send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
    with open(filePath3_revAndCostByCountry, "rb") as f:
        files = {"file": (os.path.basename(filePath3_revAndCostByCountry), f, "image/png")}
        headers_send = {
            "Authorization": f"Bearer {NOTION_TOKEN}",
            "Notion-Version": NOTION_VERSION
            # Content-Typeì€ filesë¡œ ìë™ ì„¤ì •ë¨
        }
        send_resp = requests.post(send_url, headers=headers_send, files=files)
        send_resp.raise_for_status()


    # 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
    append_url = f"https://api.notion.com/v1/blocks/{PAGE_INFO['id']}/children"
    append_payload = {
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "file_upload",
                    "file_upload": {"id": file_upload_id},
                    # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
                }
            }
        ]
    }

    headers_json_patch = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }
    append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
    append_resp.raise_for_status()

    ### ë¡œë°ì´í„° ì œê³µ
    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result3_revByCountry,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - êµ­ê°€ë³„ ë§¤ì¶œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )
    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result3_costByCountry,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - êµ­ê°€ë³„ COST  ",
        max_first_batch_rows=90,
        batch_size=100,
    )


    ### êµ­ê°€ë³„ cost rev ì½”ë©˜íŠ¸
    ########### (3) ì œë¯¸ë‚˜ì´ í•´ì„

    text = cohort_by_gemini(joyplegameid)
    blocks = md_to_notion_blocks(text)
    notion.blocks.children.append(
        block_id=PAGE_INFO['id'],
        children=blocks
    )


    ## ë¶€ì œëª©
    notion.blocks.children.append(
        PAGE_INFO['id'],
        children=[
            {
                "object": "block",
                "type": "heading_3",
                "heading_3": {
                    "rich_text": [{"type": "text", "text": {"content": "(2) OSë³„ ë§ˆì¼€íŒ…ë¹„ìš©ê³¼ ë§¤ì¶œë¹„ì¤‘" }}]
                },
            }
        ],
    )




## osë³„ cost, rev ê·¸ë˜í”„
########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
## IAP+ìœ ê°€ì ¬
def country_data_upload_to_notion(joyplegameid: int, gameidx: str, **context):

    PAGE_INFO=context['task_instance'].xcom_pull(
        task_ids = 'make_gameframework_notion_page',
        key='page_info'
    )

    query_result3_revByOs=context['task_instance'].xcom_pull(
        task_ids='cohort_by_country_revenue',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='cohort_by_country_revenue_df'
    )
    query_result3_costByOs=context['task_instance'].xcom_pull(
        task_ids='cohort_by_country_cost',  # â† ì²« ë²ˆì§¸ Taskì˜ task_id
        key='cohort_by_country_cost_df'
    )


    # 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
    create_url = "https://api.notion.com/v1/file_uploads"
    payload = {
        "filename": os.path.basename(filePath3_revAndCostByOs),
        "content_type": "image/png"
    }
    headers_json = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }
    resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
    resp.raise_for_status()
    file_upload = resp.json()
    file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
    # file_upload["upload_url"] ë„ ì‘ë‹µì— í¬í•¨ë¨

    # 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data)
    send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
    with open(filePath3_revAndCostByOs, "rb") as f:
        files = {"file": (os.path.basename(filePath3_revAndCostByOs), f, "image/png")}
        headers_send = {
            "Authorization": f"Bearer {NOTION_TOKEN}",
            "Notion-Version": NOTION_VERSION
            # Content-Typeì€ filesë¡œ ìë™ ì„¤ì •ë¨
        }
        send_resp = requests.post(send_url, headers=headers_send, files=files)
        send_resp.raise_for_status()


    # 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
    append_url = f"https://api.notion.com/v1/blocks/{PAGE_INFO['id']}/children"
    append_payload = {
        "children": [
            {
                "object": "block",
                "type": "image",
                "image": {
                    "type": "file_upload",
                    "file_upload": {"id": file_upload_id},
                    # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                    # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
                }
            }
        ]
    }

    headers_json_patch = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json"
    }
    append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
    append_resp.raise_for_status()

    ### ë¡œë°ì´í„° ì œê³µ
    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result3_revByOs,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¥ê¸° ìì²´ê²°ì œ ë§¤ì¶œ ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    resp = df_to_notion_table_under_toggle(
        notion=notion,
        page_id=PAGE_INFO['id'],
        df=query_result3_costByOs,
        toggle_title="ğŸ“Š ë¡œë°ì´í„° - OSë³„ COST ",
        max_first_batch_rows=90,
        batch_size=100,
    )

    ## osë³„ cost, rev ì½”ë©˜íŠ¸
    ########### (3) ì œë¯¸ë‚˜ì´ í•´ì„
    blocks = md_to_notion_blocks(response3_revAndCostByOs.text)
    notion.blocks.children.append(
        block_id=PAGE_INFO['id'],
        children=blocks
    )







