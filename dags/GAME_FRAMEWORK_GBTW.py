import time
import pandas as pd
from google.cloud import bigquery
from google import genai
from google.genai import types
from vertexai import rag
import vertexai
from google.genai import Client
from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore

# ì¸ì¦ê´€ë ¨
import google.auth
from google.auth.transport.requests import Request

# ê·¸ë˜í”„ ê´€ë ¨ íŒ¨í‚¤ì§€
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter, StrMethodFormatter, PercentFormatter, MultipleLocator
import matplotlib as mpl
import matplotlib.font_manager as fm
from matplotlib import cm
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont # 2ê°€ì§€ íŒŒì¼ í•©ì¹˜ê¸°
import matplotlib.dates as mdates
import nest_asyncio
from jinja2 import Template
from playwright.async_api import async_playwright
import asyncio
import IPython.display as IPd
from bs4 import BeautifulSoup

# ì „ì²˜ë¦¬ ê´€ë ¨ íŒ¨í‚¤ì§€
import numpy as np
import re

import os 
import math
import time
import pandas as pd
from notion_client import Client
import requests
import json
from datetime import datetime, timezone, timedelta
from adjustText import adjust_text
from airflow.models import Variable
from zoneinfo import ZoneInfo  # Python 3.9 ì´ìƒ

# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
def get_var(key: str, default: str = None) -> str:
    """í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Airflow Variable ì¡°íšŒ"""
    return os.environ.get(key) or Variable.get(key, default_var=default)

# ë³€ìˆ˜ ìƒì„±
t0 = time.time()
PROJECT_ID = "data-science-division-216308"
LOCATION = "us-central1"
MODEL_NAME = "gemini-2.5-flash"

NOTION_TOKEN=get_var("MS_TEAM_NOTION_TOKEN") # MSíŒ€ API í‚¤
NOTION_VERSION=get_var("NOTION_API_VERSION")
DATABASE_ID=get_var("GAMEFRAMEWORK_GBTW_NOTION_DB_ID")


credentials, project_id = google.auth.default(
    scopes=["https://www.googleapis.com/auth/cloud-platform"]
)
credentials.refresh(Request())

# í´ë¼ì´ì–¸íŠ¸ ëª¨ìŒ
genai_client = Client(vertexai=True,project=PROJECT_ID,location=LOCATION)
bigquery_client = bigquery.Client(project=PROJECT_ID, credentials=credentials)# location=LOCATION ## us-central1 ë¡œ í•  ê²½ìš° í—ˆë¸Œ ì¡°íšŒë¶ˆê°€ëŠ¥
notion = Client(auth=NOTION_TOKEN)





## í˜ì´ì§€ ìƒì„± í•¨ìˆ˜ //////////// task í•¨ìˆ˜
def make_gameframework_notion_page(game_id):

    url = "https://api.notion.com/v1/pages"
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }

    # íƒ€ì„ì¡´ ì§€ì •
    kst = ZoneInfo("Asia/Seoul")
    # ì˜¤ëŠ˜
    today_kst = datetime.now(kst).date()
    # ì–´ì œ
    yesterday_kst = today_kst - timedelta(days=1)

    # ì´ë²ˆ ë‹¬ 1ì¼ (ì–´ì œ ë‚ ì§œ ê¸°ì¤€)
    first_day = yesterday_kst.replace(day=1)

    # íƒ€ì´í‹€ ë¬¸ìì—´ ë§Œë“¤ê¸°
    title = f"{yesterday_kst.strftime('%y')}ë…„ {yesterday_kst.month}ì›” ë§¤ì¶œí˜„í™©( ~ {yesterday_kst})"
    print(f"{title} : {game_id}")

    # í˜ì´ì§€ ìƒì„± ìš”ì²­ ë°”ë””
    data = {
        "parent": {"database_id": DATABASE_ID},
        "properties": {
            "ì´ë¦„": {
                "title": [
                    {"text": {"content": title }}
                ]
            },
            "ë“±ë¡ ë‚ ì§œ": {
                "date": {"start": today_kst.isoformat() }
            },
            "í”„ë¡œì íŠ¸": {
                "multi_select": [
                    {"name": {game_id}}   # ë‹¤ì¤‘ ì„ íƒ ì˜µì…˜
                ]
            },
            "ë¦¬í¬íŠ¸ ì¢…ë¥˜": {
                "multi_select": [
                    {"name": "ê²Œì„ë¶„ì„"}   # ë‹¤ì¤‘ ì„ íƒ ì˜µì…˜
                ]
            },
            "ì‘ì„±ì": {
                "people": [
                    {"id": "ce95f16a-6b6b-447d-a996-a9c5f0cc0113"},  # Notion user_id
                    {"id": "662575bc-731c-481c-afc7-13b2fdf5482a"}  # Notion user_id
                ]
            }
        }
    }

    res = requests.post(url, headers=headers, json=data)

    if res.status_code == 200:
        page_info = res.json()
        PAGE_ID = page_info["id"]   # âœ… í˜ì´ì§€ ID
        print(f"âœ… í˜ì´ì§€ ìƒì„± ì„±ê³µ âœ… í˜ì´ì§€ ID : {PAGE_ID}")
    else:
        print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {res.status_code} >> {res.text}")

    notion.blocks.children.append(
        block_id=PAGE_ID,
        children=[
            {
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [
                        {
                            "type": "text",
                            "text": {"content": " â—¾ ëª©ì°¨"},
                            "annotations": {"bold": True}
                        }
                    ]
                }
            }
        ]
    )

    # ëª©ì°¨ ë¸”ë¡ ì¶”ê°€
    notion.blocks.children.append(
        block_id=PAGE_ID,
        children=[
            {
                "object": "block",
                "type": "table_of_contents",
                "table_of_contents": {
                    "color": "default"  # "gray", "brown", "orange", "yellow", "green", "blue", "purple", "pink", "red" ê°€ëŠ¥
                }
            }
        ],
    )

    return True




# ğŸ‘‰ Markdown ë‚´ **êµµê²Œ** ì²˜ë¦¬ ë³€í™˜
def parse_rich_text(md_text):
    """
    '**êµµê²Œ**' â†’ Notion rich_text [{"text": {...}, "annotations": {"bold": True}}]
    """
    parts = re.split(r"(\*\*.*?\*\*)", md_text)  # **...** ê¸°ì¤€ split
    rich_text = []
    for part in parts:
        if part.startswith("**") and part.endswith("**"):
            rich_text.append({
                "type": "text",
                "text": {"content": part[2:-2]},
                "annotations": {"bold": True}
            })
        else:
            if part:
                rich_text.append({
                    "type": "text",
                    "text": {"content": part}
                })
    return rich_text



# ğŸ‘‰ Markdownì„ Notion Blocksë¡œ ë³€í™˜
def md_to_notion_blocks(md_text, blank_blocks=3):
    blocks = []
    lines = md_text.splitlines()
    stack = [blocks]  # í˜„ì¬ ê³„ì¸µ ì¶”ì 

    def detect_indent_unit(lines):
        indents = []
        for line in lines:
            if line.lstrip().startswith(("* ", "- ", "+ ")):  # ë¦¬ìŠ¤íŠ¸ ë¬¸ë²• ê°ì§€
                indent = len(line) - len(line.lstrip())
                if indent > 0:
                    indents.append(indent)
        return min(indents) if indents else 4  # fallback = 4ì¹¸
    indent_unit = detect_indent_unit(lines)

    i = 0
    while i < len(lines):
        line = lines[i].rstrip()
        if not line:
            i += 1
            continue

        # Heading ì²˜ë¦¬
        if line.startswith("# "):
            stack = [blocks]
            stack[-1].append({
                "object": "block",
                "type": "heading_1",
                "heading_1": {"rich_text": parse_rich_text(line[2:])}
            })
        elif line.startswith("## "):
            stack = [blocks]
            stack[-1].append({
                "object": "block",
                "type": "heading_2",
                "heading_2": {"rich_text": parse_rich_text(line[3:])}
            })
        elif line.startswith("### "):
            stack = [blocks]
            stack[-1].append({
                "object": "block",
                "type": "heading_3",
                "heading_3": {"rich_text": parse_rich_text(line[4:])}
            })

        # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        elif line.lstrip().startswith("* "):
            indent = len(line) - len(line.lstrip())  # ë“¤ì—¬ì“°ê¸° ë ˆë²¨
            content = line.strip()[2:].strip()

            block = {
                "object": "block",
                "type": "bulleted_list_item",
                "bulleted_list_item": {
                    "rich_text": parse_rich_text(content),
                    "children": []
                }
            }

            # indent ê¸°ë°˜ ê³„ì¸µ ì²˜ë¦¬
            level = indent // indent_unit + 1
            while len(stack) > level:
                stack.pop()
            stack[-1].append(block)
            stack.append(block["bulleted_list_item"]["children"])
        else:
            stack = [blocks]
            # ì¼ë°˜ ë¬¸ë‹¨
            stack[-1].append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {"rich_text": parse_rich_text(line.strip())}
            })

        i += 1

    # âœ… ë§ˆì§€ë§‰ì— ë¹ˆ ë¸”ë¡ ì¶”ê°€ (ê°œìˆ˜ëŠ” íŒŒë¼ë¯¸í„° blank_blocksë¡œ ì œì–´)
    for _ in range(blank_blocks):
        blocks.append({
            "object": "block",
            "type": "paragraph",
            "paragraph": {"rich_text": []}
        })

    return blocks


def df_to_notion_table_under_toggle(
    notion: Client,
    page_id: str,
    df: pd.DataFrame,
    toggle_title: str = "ğŸ“Š Data Table",
    max_first_batch_rows: int = 90,
    batch_size: int = 100,
    has_column_header: bool = True,
    has_row_header: bool = False,
):
    """
    Notion í˜ì´ì§€ì— í† ê¸€ì„ ë§Œë“¤ê³ , ê·¸ ì•„ë˜ì— Pandas DataFrameì„ í‘œ(Table)ë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    - ìµœì´ˆ ìƒì„± ì‹œ í…Œì´ë¸”ì˜ header + ì´ˆê¸° í–‰ë“¤ì„ table.children ì•ˆì— í¬í•¨
    - ì´í›„ ë‚¨ì€ í–‰ë“¤ì€ table_rowë¡œ ë°°ì¹˜ append

    Parameters
    ----------
    notion : notion_client.Client
        Notion SDK í´ë¼ì´ì–¸íŠ¸ (Client(auth=...) ë¡œ ìƒì„±)
    page_id : str
        í…Œì´ë¸”ì„ ì¶”ê°€í•  í˜ì´ì§€(í˜¹ì€ ë¸”ë¡) ID
    df : pandas.DataFrame
        ì—…ë¡œë“œí•  ë°ì´í„°í”„ë ˆì„
    toggle_title : str
        í† ê¸€ íƒ€ì´í‹€
    max_first_batch_rows : int
        í…Œì´ë¸” ìµœì´ˆ ìƒì„± ì‹œ í¬í•¨í•  ì´ˆê¸° í–‰ ê°œìˆ˜(Too many children ë°©ì§€ìš©)
    batch_size : int
        ì´í›„ ë°°ì¹˜ append ì‹œ ë¬¶ìŒ í¬ê¸°
    has_column_header : bool
        Notion í…Œì´ë¸” ì˜µì…˜ - ì»¬ëŸ¼ í—¤ë” ì‚¬ìš© ì—¬ë¶€
    has_row_header : bool
        Notion í…Œì´ë¸” ì˜µì…˜ - í–‰ í—¤ë” ì‚¬ìš© ì—¬ë¶€

    Returns
    -------
    dict : {"toggle_id": str, "table_id": str, "rows_created": int}
    """
    # 1) í† ê¸€ ìƒì„±
    toggle_resp = notion.blocks.children.append(
        page_id,
        children=[
            {
                "object": "block",
                "type": "toggle",
                "toggle": {
                    "rich_text": [
                        {
                            "type": "text",
                            "text": {"content": toggle_title[:2000]},
                            "annotations": {
                                "bold": True,
                                "italic": False,
                                "underline": False,
                                "strikethrough": False,
                                "code": False,
                                "color": "blue"   # â† ìƒ‰ìƒ ì§€ì •
                            },
                        }
                    ]
                },
            }
        ],
    )
    toggle_id = toggle_resp["results"][0]["id"]

    # 2) í—¤ë”/ì´ˆê¸°í–‰ ì¤€ë¹„
    table_width = len(df.columns)

    # í—¤ë”(ì»¬ëŸ¼ëª…)
    header_cells = []
    for col in df.columns.astype(str).tolist():
        header_cells.append([{"type": "text", "text": {"content": str(col)[:2000]}}])

    # ì´ˆê¸° ë°ì´í„° í–‰
    first_rows_blocks = []
    row_count = 0
    for _, row in df.iterrows():
        if row_count >= max_first_batch_rows:
            break
        row_cells = []
        for col in df.columns:
            val = row[col]
            #s = "" if (val is None or (isinstance(val, float) and math.isnan(val))) else str(val)
            s = "" if pd.isna(val) else str(val)
            row_cells.append([{"type": "text", "text": {"content": s[:2000]}}])

        # ì—´ ìˆ˜ ì•ˆì „ì¥ì¹˜(íŒ¨ë”©/ì ˆë‹¨)
        if len(row_cells) < table_width:
            row_cells += [[{"type": "text", "text": {"content": ""}}]] * (table_width - len(row_cells))
        elif len(row_cells) > table_width:
            row_cells = row_cells[:table_width]

        first_rows_blocks.append(
            {"object": "block", "type": "table_row", "table_row": {"cells": row_cells}}
        )
        row_count += 1

    # 3) í…Œì´ë¸” ë¸”ë¡ ìƒì„±: table.children ì•ˆì— header + ì´ˆê¸°í–‰ í¬í•¨(ì¤‘ìš”)
    table_block = {
        "object": "block",
        "type": "table",
        "table": {
            "table_width": table_width,
            "has_column_header": has_column_header,
            "has_row_header": has_row_header,
            "children": (
                [
                    {
                        "object": "block",
                        "type": "table_row",
                        "table_row": {"cells": header_cells},
                    }
                ]
                + first_rows_blocks
            ),
        },
    }

    table_create_resp = notion.blocks.children.append(toggle_id, children=[table_block])
    table_id = table_create_resp["results"][0]["id"]

    # 4) ë‚¨ì€ í–‰ë“¤ ë°°ì¹˜ ì¶”ê°€
    total = len(df)
    start = row_count
    while start < total:
        end = min(start + batch_size, total)
        batch_children = []

        for _, row in df.iloc[start:end].iterrows():
            row_cells = []
            for col in df.columns:
                val = row[col]
                s = "" if (val is None or (isinstance(val, float) and math.isnan(val))) else str(val)
                row_cells.append([{"type": "text", "text": {"content": s[:2000]}}])

            if len(row_cells) < table_width:
                row_cells += [[{"type": "text", "text": {"content": ""}}]] * (table_width - len(row_cells))
            elif len(row_cells) > table_width:
                row_cells = row_cells[:table_width]

            batch_children.append(
                {"object": "block", "type": "table_row", "table_row": {"cells": row_cells}}
            )

        notion.blocks.children.append(table_id, children=batch_children)
        start = end

    return {"toggle_id": toggle_id, "table_id": table_id, "rows_created": total}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ìš© ì˜ˆì‹œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# from notion_client import Client
# notion = Client(auth=NOTION_TOKEN)
# resp = df_to_notion_table_under_toggle(
#     notion=notion,
#     page_id=PAGE_ID,
#     df=query_result1_dailySales,
#     toggle_title="ğŸ“Š Daily Sales (DataFrame Table)",
#     max_first_batch_rows=90,
#     batch_size=100,
# )
# print(resp)

### ì¼ìë³„ ë§¤ì¶œ
# ì¿¼ë¦¬ & ì œë¯¸ë‚˜ì´ í”„ë¡¬í”„íŠ¸

def Daily_revenue(query):
    RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
    LABELS = {"datascience_division_service": "gameinsight_framework",
            "run_id": RUN_ID,
            "datascience_division_service_sub" : "1_daily_sales"} ## ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë¶™ì¼ ìˆ˜ ìˆìŒ.
    print("ğŸ“§ RUN_ID=", RUN_ID, "ğŸ“§ LABEL_ID=", LABELS)

    query_result = bigquery_client.query(query, job_config=bigquery.QueryJobConfig(labels=LABELS)).to_dataframe()
    return query_result

## ì¼ìë³„ ë§¤ì¶œ
def Daily_revenue_query(**context):
    query = """

    select day
    , cast(sum(if(monthtype = 'ì§€ë‚œë‹¬' , pricekrw, null ))as int64) as `ì§€ë‚œë‹¬`
    , cast(sum(if(monthtype = 'ì´ë²ˆë‹¬' , pricekrw, null ))as int64) as `ì´ë²ˆë‹¬`

    from
    (select *
    , format_date('%Y-%m',  logdatekst ) as Month
    , case when logdatekst >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH), INTERVAL 1 MONTH)
    and logdatekst< DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH) then 'ì§€ë‚œë‹¬'
    when logdatekst >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst <= LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH) then 'ì´ë²ˆë‹¬'
    else 'etc' end as monthtype
    , format_date('%d',  logdatekst ) as day
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = 133
    and logdateKst>= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH), INTERVAL 1 MONTH)
    #and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    )
    group by 1
    order by 1

    """
    query_result = Daily_revenue(query)
    return query_result
    
#### ì „ë…„ ëŒ€ë¹„ ì›” ë§¤ì¶œ ì¶”ì´
def Daily_revenue_YOY_query(**context):
    query = """

    select month
    , cast(sum(if(yeartype = 'ì‘ë…„' , pricekrw, null ))as int64) as `ì‘ë…„`
    , cast(sum(if(yeartype = 'ì˜¬í•´' , pricekrw, null ))as int64) as `ì˜¬í•´`

    from
    (select *
    , case
    when logdatekst >= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR), INTERVAL 1 YEAR)
    and logdatekst< DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR) then 'ì‘ë…„'

    when logdatekst >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR)
    and logdatekst <= LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR) then 'ì˜¬í•´'
    else 'etc' end as yeartype
    , format_date('%m',  logdatekst ) as month
    , format_date('%Y',  logdatekst ) as year

    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = 133
    and logdateKst>= DATE_SUB(DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR), INTERVAL 1 YEAR)
    and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), YEAR)
    )
    group by 1
    order by 1

    """
    query_result = Daily_revenue(query)
    return query_result


## í˜„ì¬ ë§¤ì¶œê³¼ ëª©í‘œ ë§¤ì¶œ
def Daily_revenue_target_revenue_query(**context):
    query = """
    ### 1> ì´ë²ˆë‹¬ ì¼ìë³„ ë§¤ì¶œ ì‹¤ì¸¡ì¹˜
    with thismonthRev as (
    select day ## ì¼ì
    , lastDay ## ì´ë²ˆë‹¬ ë§ˆì§€ë§‰ë‚  (ex - 30)
    , sum(pricekrw) as rev ## ë§¤ì¶œì•¡
    from
    (select *
    , cast(format_date('%d',  logdatekst ) as int64) as day ## ì¼ì
    , EXTRACT(DAY FROM LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)) as lastDay
    from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
    where joyplegameid = 133
    and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
    and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY)
    )
    group by day,lastDay
    order by day
    ),

    ### 2> ëª©í‘œë§¤ì¶œ í…Œì´ë¸”
    salesGoal as (
    select
        CAST(REPLACE(sales, ',', '') AS INT64) as salesGoalMonthly # ì‰¼í‘œ í¬í•¨í•œ string í˜•íƒœë¡œ ì ì¬ë˜ì–´ìˆì–´ì„œ int64 í˜•íƒœë¡œ ì „ì²˜ë¦¬
    , CAST(REPLACE(sales, ',', '') AS INT64)/cast(num_of_days as int64) as salesGoalDaily # ì¼í‰ê·  ëª©í‘œë§¤ì¶œ
    from `data-science-division-216308.gameInsightFramework.slgMonthlyGoal`
    where idx = 'GBTW'
    and month = FORMAT_DATE('%Y-%m', DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
    ),

    ### 3> í•©ì¹˜ê¸°
    thismonthRev2 as (


    select
        a.day, a.lastDay, a.rev
    , b.salesGoalDaily
    , c.maxDay ## ì´ë²ˆë‹¬ ë©°ì¹ ê¹Œì§€ ê¸°ê°„ ì°¼ëŠ”ì§€
    #, case when maxDay >5 then rev ## 5ì¼ì¹˜ ì´ìƒì˜ ë§¤ì¶œì´ ìˆìœ¼ë©´ ê·¸ëƒ¥ ì¼í• ê³„ì‚°
    #       when maxDay<=5 and day=1 then salesGoalDaily ## 5ì¼ì¹˜ ì´í•˜ì˜ ë§¤ì¶œë§Œ ìˆë‹¤ë©´ , 1ì¼ì ë§¤ì¶œì„ ë³´ì •ì¹˜ ì ìš©
    #       else rev end as rev2
    , a.rev as rev2
    from
    ## ì¼ìë³„ ë§¤ì¶œ ì‹¤ì¸¡
    (select * from thismonthRev) as a

    ## ëª©í‘œë§¤ì¶œ (ì›”ë³„, ì¼ë³„)
    cross join
    (select *
    from salesGoal
    ) as b

    ## í˜„ì¬ ë©°ì¹ ê¹Œì§€ ë§¤ì¶œ ìˆëŠ”ì§€ -> 5ì¼ ì´ì „ì¸ì§€ ì´í›„ì¸ì§€ í™•ì¸ìš©ë„
    cross join
    (select cast(max(day) as int64) as maxDay from thismonthRev) as c

    )

    #select * from thismonthRev_and_revGoal order by day

    ### 4> ì „ì²˜ë¦¬
    select cast(current_sales as int64) as current_sales, b.salesGoalMonthly
    from
    (select (rev/maxDay)*lastDay as current_sales
    from
    (select sum(rev2) as rev, max(maxDay) as maxDay, max(lastDay) as lastDay
    from thismonthRev2)
    ) as a
    cross join
    (select * from salesGoal) as b

    """

    query_result = Daily_revenue(query)
    return query_result


## ì „ë…„ ëŒ€ë¹„ ì›” ë§¤ì¶œ ì¶”ì´ ìˆ˜ì • - ë‹¹ì›”ì€ ì¼í• ê³„ì‚° ë§¤ì¶œ
def merge_daily_revenue():
    s_total = Daily_revenue_YOY_query()
    val_total = Daily_revenue_target_revenue_query()
    val = val_total.iat[0, 0]
    s = s_total.iloc[:, 2]
    try:
        idx = s.dropna().index[-1]                 # ë§ˆì§€ë§‰ non-null ë¼ë²¨ ì¸ë±ìŠ¤
        s_total.loc[idx, s_total.columns[2]] = val
    except IndexError:
        pass  # ëª¨ë‘ nullì¸ ê²½ìš°

    return s_total


## í”„ë¡¬í”„íŠ¸ 
### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸

response1_salesComment = genai_client.models.generate_content(
model='gemini-2.5-flash',

contents = f"""
ë‹¹ì›” ë§¤ì¶œì€ ì¼í• ê³„ì‚°ì‹œ {f"{int((query_result1_salesGoal.iat[0,0])):,}"}ì´ê³  ëª©í‘œëŠ” {f"{int((query_result1_salesGoal.iat[0,1])):,}"}ì´ì•¼.
ë‹¹ì›” ë§¤ì¶œì€ ì¼í• ê³„ì‚°ì‹œ ~~ì´ê³  ëª©í‘œë§¤ì¶œì€ ~~ ìœ¼ë¡œ, ëª©í‘œëŒ€ë¹„ ì–¼ë§ˆ ë‹¬ì„±í–ˆë‹¤ì˜ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.
ê·¸ë¦¬ê³  ì¶”ê°€ë¡œ ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•´ ì•„ì£¼ ê°„ë‹¨íˆ ì½”ë©˜íŠ¸ë¥¼ í•´ì¤˜.
~ìŠµë‹ˆë‹¤ ì²´ë¡œ ì•Œë ¤ì¤˜

ê·¸ë¦¬ê³  ì „ë…„ë™ì›”ëŒ€ë¹„ì–´ë–¤ì§€ 3ì¤„ì´ë‚´ë¡œ ê°„ë‹¨íˆ ì•Œë ¤ì¤˜.

ì•ìœ¼ë¡œ ì–´ë–»ê²Œ í•´ì•¼ê² ë‹¤ëŠ” ì‚¬ê²¬ì€ ì“°ì§€ë§ˆ.
í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.
<ì¼ìë³„ ì´ ë§¤ì¶œ>
{query_result1_dailySales}

< ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ>
{query_result1_monthlySales}
""",
config=types.GenerateContentConfig(
        system_instruction=[
            "You're a Game Data Analyst.",
            "Your task is to analyze the metrics of a given mobile game and identify the causes of any changes.",
            "Your answers must be in Korean.",
            "The unit of amount in the Sales or Revenue, Cost Data is Korean Won.",
            "You must answer in Notion's Markdown format, but do not use title syntax.",
        ],
        # tools=[RAG],
        temperature=0.5,
        labels=LABELS
    )

)
# ì½”ë©˜íŠ¸ ì¶œë ¥
print(response1_salesComment.text)

# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
if Path(font_path).exists():
    fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
    mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
    mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
else:
    print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

## ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
x  = query_result1_dailySales.iloc[:, 0]
y1 = pd.to_numeric(query_result1_dailySales.iloc[:, 1], errors='coerce')
y2 = pd.to_numeric(query_result1_dailySales.iloc[:, 2], errors='coerce')

fig, ax = plt.subplots(figsize=(10, 5))
ax.plot(x, y2, marker='o',
        markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
        label=query_result1_dailySales.columns[2])
ax.plot(x, y1, marker='o',
        markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
        linestyle='--', label=query_result1_dailySales.columns[1])  # ê²¹ì³ì„œ í‘œì‹œ

# ì˜µì…˜
plt.title("ì¼ìë³„ ë§¤ì¶œ")
#plt.xlabel(query_result1_dailySales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
#plt.ylabel(query_result1_dailySales.columns[1])

# yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

# xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
plt.xticks(query_result1_dailySales[query_result1_dailySales.columns[0]][::2], rotation=45)

# ë²”ë¡€ í‘œì‹œ - ê·¸ë˜í”„ë‘ ì•ˆê²¹ì¹˜ê²Œ
plt.legend(
    bbox_to_anchor=(1.05, 1),   # ê·¸ë˜í”„ ì˜¤ë¥¸ìª½ ë°”ê¹¥ (x=1.05, y=1)
    loc='upper left',           # ì•µì»¤ ê¸°ì¤€ ìœ„ì¹˜
    borderaxespad=0.             # ì¶•ê³¼ ê°„ê²©
)

# yì¶• 0ë¶€í„° ì‹œì‘ (ì•ˆí•˜ë©´ ëˆˆê¸ˆ ìµœì†Œê°’ ìì¢… ì¡°ì •)
plt.ylim(0, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§

# yì¶• ë³´ì¡°ì„ 
plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„
#plt.grid(axis='x', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

#plt.xlabel("ë‚ ì§œ")
#plt.ylabel("ë§¤ì¶œ")

#plt.show()
# ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
plt.tight_layout()


# í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
# #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
# ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
filepath1_dailySales = "/content/graph1_dailySales.png"
plt.savefig(filepath1_dailySales, dpi=160) # dpi : í•´ìƒë„
plt.close()

## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
if Path(font_path).exists():
    fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
    mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
    mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
else:
    print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

## ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
x  = query_result1_monthlySales.iloc[:, 0]
y1 = pd.to_numeric(query_result1_monthlySales.iloc[:, 1], errors='coerce')
y2 = pd.to_numeric(query_result1_monthlySales.iloc[:, 2], errors='coerce')

fig, ax = plt.subplots(figsize=(10, 5))
ax.plot(x, y2, marker='o',
        markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
        label=query_result1_monthlySales.columns[2])
ax.plot(x, y1, marker='o',
        markersize=3, linewidth=1, # ë§ˆì»¤ í¬ê¸° ì‘ê²Œ
        linestyle='--', label=query_result1_monthlySales.columns[1])  # ê²¹ì³ì„œ í‘œì‹œ

# ì˜µì…˜
plt.title("ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ")
#plt.xlabel(query_result1_monthlySales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
#plt.ylabel(query_result1_monthlySales.columns[1])

# yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

# xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
plt.xticks(query_result1_monthlySales[query_result1_monthlySales.columns[0]][::1], rotation=45)

# ë²”ë¡€ í‘œì‹œ - ê·¸ë˜í”„ë‘ ì•ˆê²¹ì¹˜ê²Œ
plt.legend(
    bbox_to_anchor=(1.05, 1),   # ê·¸ë˜í”„ ì˜¤ë¥¸ìª½ ë°”ê¹¥ (x=1.05, y=1)
    loc='upper left',           # ì•µì»¤ ê¸°ì¤€ ìœ„ì¹˜
    borderaxespad=0.             # ì¶•ê³¼ ê°„ê²©
)

# y ì¶• ì¡°ì • (20ì–µë¶€í„°)
plt.ylim(2000000000, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§

# yì¶• ë³´ì¡°ì„ 
plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„
#plt.grid(axis='x', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

#plt.xlabel("month")
#plt.ylabel("ë§¤ì¶œ")

#plt.show()
# ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
plt.tight_layout()


# í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
# #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
# ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
filePath1_monthlySales = "/content/graph1_monthlySales.png"
plt.savefig(filePath1_monthlySales, dpi=160) # dpi : í•´ìƒë„
plt.close()

# 1) íŒŒì¼ ê²½ë¡œ
p1 = "/content/graph1_dailySales.png"   # ì²« ë²ˆì§¸ ì´ë¯¸ì§€
p2 = "/content/graph1_monthlySales.png"   # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€
save_to = "/content/graph1_dailySales_monthlySales.png"  # ì €ì¥ ê²½ë¡œ

# 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
im1 = Image.open(p1).convert("RGBA")
im2 = Image.open(p2).convert("RGBA")

# ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
target_h = max(im1.height, im2.height)

def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
    if img.height == h:
        return img
    canvas = Image.new("RGBA", (img.width, h), bg)
    # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
    y = (h - img.height) // 2
    canvas.paste(img, (0, y))
    return canvas

im1_p = pad_to_height(im1, target_h)
im2_p = pad_to_height(im2, target_h)

gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
out.paste(im1_p, (0, 0), im1_p)
out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

# PNGë¡œ ì €ì¥
out.save(save_to)
print("Saved:", save_to)
filePath1_dailySales_monthlySales = "/content/graph1_dailySales_monthlySales.png"

notion.blocks.children.append(
    PAGE_ID,
    children=[
        {
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "\n\n1. ì¼ìë³„ ë§¤ì¶œ" }}]
            },
        }
    ],
)


# 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
create_url = "https://api.notion.com/v1/file_uploads"
payload = {
    "filename": os.path.basename(filePath1_dailySales_monthlySales),
    "content_type": "image/png"
}
headers_json = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json"
}
resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
resp.raise_for_status()
file_upload = resp.json()
file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
# file_upload["upload_url"] ë„ ì‘ë‹µì— í¬í•¨ë¨

# 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data)
send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
with open(filePath1_dailySales_monthlySales, "rb") as f:
    files = {"file": (os.path.basename(filePath1_dailySales_monthlySales), f, "image/png")}
    headers_send = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION
        # Content-Typeì€ filesë¡œ ìë™ ì„¤ì •ë¨
    }
    send_resp = requests.post(send_url, headers=headers_send, files=files)
    send_resp.raise_for_status()


# 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
append_url = f"https://api.notion.com/v1/blocks/{PAGE_ID}/children"
append_payload = {
    "children": [
        {
            "object": "block",
            "type": "image",
            "image": {
                "type": "file_upload",
                "file_upload": {"id": file_upload_id},
                # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
            }
        }
    ]
}


headers_json_patch = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,

    "Content-Type": "application/json"
}
append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
append_resp.raise_for_status()

resp = df_to_notion_table_under_toggle(
    notion=notion,
    page_id=PAGE_ID,
    df=query_result1_dailySales,
    toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¼ìë³„ ë§¤ì¶œ",
    max_first_batch_rows=90,
    batch_size=100,
)

resp = df_to_notion_table_under_toggle(
    notion=notion,
    page_id=PAGE_ID,
    df=query_result1_monthlySales,
    toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì „ë…„ ë™ì›”ëŒ€ë¹„ ë§¤ì¶œ",
    max_first_batch_rows=90,
    batch_size=100,
)

## ì œë¯¸ë‚˜ì´
blocks = md_to_notion_blocks(response1_salesComment.text)
notion.blocks.children.append(
    block_id=PAGE_ID,
    children=blocks
)

# 2. ìì²´ê²°ì œ ë§¤ì¶œ

RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
LABELS = {"datascience_division_service": "gameinsight_framework",
          "run_id": RUN_ID,
          "datascience_division_service_sub" : "2_inhouse_sales"} ## ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë¶™ì¼ ìˆ˜ ìˆìŒ.
print("RUN_ID=", RUN_ID, "LABEL_ID=", LABELS)

query = """

select logdatekst, cast(sum(pgpricekrw) as int64) as rev
from
(SELECT t1.*,
	t2.PGRole,
	t2.PlatformDeviceTypeName,
	t2.PGName,
	t2.PGBuyCount,
	t2.PGPriceKRW
FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V` AS t1,
  UNNEST(t1.PaymentDetailArrayStruct) AS t2
where joyplegameid = 133
and pgrole = 'ìì²´ê²°ì œ'
and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
)
group by 1 order by 1

"""

query_result2_dailySelfPaymentSales = bigquery_client.query(query, job_config=bigquery.QueryJobConfig(labels=LABELS)).to_dataframe()

### 2> 24ë…„ë¶€í„° ì›”ë³„ ìì²´ê²°ì œ ë§¤ì¶œ
query = """


select a.month
, cast(a.rev_all as int64) as rev_all
, cast(b.rev as int64) as rev_self
, safe_divide(b.rev,a.rev_all) as self_per
from
(select month, sum(pricekrw) as rev_all
from
(select *,format_date('%Y-%m', logdatekst ) as month
FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V`
where joyplegameid = 133
and logdatekst>='2024-01-01'
and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
group by 1
) as a

left join
(select month, cast(sum(pgpricekrw) as int64) as rev
from
(SELECT t1.*,
	t2.PGRole,
	t2.PlatformDeviceTypeName,
	t2.PGName,
	t2.PGBuyCount,
	t2.PGPriceKRW,
	format_date('%Y-%m', logdatekst ) as month
FROM `dataplatform-reporting.DataService.T_0317_0000_AuthAccountPerformance_V` AS t1,
  UNNEST(t1.PaymentDetailArrayStruct) AS t2
where joyplegameid = 133
and pgrole = 'ìì²´ê²°ì œ'
and logdatekst>='2024-01-01'
and logdatekst<=DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY))
group by 1) as b
on a.month = b.month

order by month

"""

## 129.93MB
query_result2_monthlySelfPaymentSales = bigquery_client.query(query, job_config=bigquery.QueryJobConfig(labels=LABELS)).to_dataframe()

prompt_2 = f"""

1. ì•„ë˜ëŠ” ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œê³¼ ê³¼ê±°ë¶€í„° ì¥ê¸°ì ì¸ ìì²´ê²°ì œ ë§¤ì¶œì´ì•¼.ê°„ë‹¨í•˜ê²Œ í•´ì„í•´ì¤˜.
2. ìì²´ê²°ì œì— ëŒ€í•œ ì •ì˜ë¥¼ ì“¸ í•„ìš”ëŠ” ì—†ì–´.
3. ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ê³ , ì¥ê¸°ì ì¸ ìì²´ê²°ì œ íŠ¸ë Œë“œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì¤˜.
4. ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œì™€ ì¥ê¸°ì ì¸ ìì²´ê²°ì œ íŠ¸ë Œë“œ ë‹¨ë½ì„ ë‚˜ëˆ ì¤˜. ì˜ˆ) <ì¼ìë³„ ìì²´ê²°ì œ íŠ¸ë Œë“œ> , <ì¥ê¸°ì  ìì²´ê²°ì œ íŠ¸ë Œë“œ>
5. ë‚´ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì“°ì§€ë§ˆ.
6. ë³€ìˆ˜ëª…ì— ëŒ€í•´ì„  ì–¸ê¸‰í•˜ì§€ë§ˆ.
7. ìì²´ê²°ì œë€, êµ¬ê¸€ì´ë‚˜ ì• í”Œì˜ ë§ˆì¼“ ìˆ˜ìˆ˜ë£Œë¥¼ ì ˆê°í•˜ê¸° ìœ„í•´ ìˆ˜ìˆ˜ë£Œê°€ ë‚®ì€ ê²°ì œ í”Œë«í¼ì—ì„œ ê²°ì œí•˜ëŠ” ê²ƒì„ ë§í•´.
8. ë‹¤ìŒì€ ìì²´ê²°ì œì— ëŒ€í•œ ë¶„ì„ì…ë‹ˆë‹¤ ì´ëŸ° ì‚¬ì „ì— ë§ í•˜ì§€ë§ê³  ê·¸ëƒ¥ ë¶„ì„ê²°ê³¼ë¥¼ ì•Œë ¤ì¤˜
9. ì‚¬ê²¬ì„ ì“°ì§€ë§ê³  ê·¸ëƒ¥ í˜„ì¬ ìƒí™©ì— ëŒ€í•´ íŒ©íŠ¸ë§Œ ì•Œë ¤ì¤˜.


< ì„œì‹ ìš”êµ¬ì‚¬í•­ >
í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.

<ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ>
{query_result2_dailySelfPaymentSales}

< ì¥ê¸°ì  ìì²´ê²°ì œ ë§¤ì¶œ>
{query_result2_monthlySelfPaymentSales}

"""

response2_selfPaymentSales = genai_client.models.generate_content(
    model=MODEL_NAME,
    contents=prompt_2,
    config=types.GenerateContentConfig(

        # ì˜ì–´ë¡œ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì˜ ì´í•´í•  ìˆ˜ ìˆìŒ.
        system_instruction=[
            "You're a Game Data Analyst.",
            "Your task is to analyze the metrics of a given mobile game and identify the causes of any changes.",
            "Your answers must be in Korean.",
            "The unit of amount in the Sales or Revenue, Cost Data is Korean Won.",
            "You must answer in Notion's Markdown format, but do not use title syntax.",
            "Put each instruction on a new line."

        ],
        #tools=[rag_retrieval_tool_test],
        temperature=0.5
        ,labels=LABELS
        # max_output_tokens=2048
    )
)
print(response2_selfPaymentSales.text)

## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
if Path(font_path).exists():
    fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
    mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
    mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
else:
    print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

# Seaborn ì„  ê·¸ë˜í”„
sns.lineplot(x= query_result2_dailySelfPaymentSales.columns[0],
             y=query_result2_dailySelfPaymentSales.columns[1],
             data=query_result2_dailySelfPaymentSales,
             marker="o")

# ì˜µì…˜
plt.title("ì´ë²ˆë‹¬ ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ")
#plt.xlabel(query_result2_dailySelfPaymentSales.columns[0])   # ìë™ìœ¼ë¡œ ì»¬ëŸ¼ëª… í‘œì‹œ ê°€ëŠ¥
#plt.ylabel(query_result2_dailySelfPaymentSales.columns[1])

# yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f"{int(x):,}"))

# xì¶• ëˆˆê¸ˆì„ 7ê°œ ë‹¨ìœ„ë¡œë§Œ í‘œì‹œ (ì˜ˆ: 1ì£¼ì¼ ê°„ê²©)
plt.xticks(query_result2_dailySelfPaymentSales[query_result2_dailySelfPaymentSales.columns[0]][::1], rotation=45)

# yì¶• 0ë¶€í„° ì‹œì‘
plt.ylim(0, None)   # Noneì´ë©´ ìµœëŒ€ê°’ì€ ìë™ìœ¼ë¡œ ë§ì¶°ì§
# yì¶• ë³´ì¡°ì„ 
plt.grid(axis='y', linestyle='--', alpha=0.7) # alpha=íˆ¬ëª…ë„

# x,yì¶• ì œê±°
plt.xlabel(None)
plt.ylabel(None)

#plt.show()
# ê·¸ë˜í”„ ì•ˆì˜ë¦¬ê²Œ
plt.tight_layout()


# í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
# #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
# ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
file_path2_dailySelfPaymentSales = "/content/graph2_dailySelfPaymentSales.png"
plt.savefig(file_path2_dailySelfPaymentSales, dpi=160) # dpi : í•´ìƒë„
plt.close()


## í•œê¸€ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ í°íŠ¸ ì§€ì •
font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
if Path(font_path).exists():
    fm.fontManager.addfont(font_path)       # ìˆ˜ë™ ë“±ë¡
    mpl.rc('font', family='NanumGothic')    # ê¸°ë³¸ í°íŠ¸ ì§€ì •
    mpl.rc('axes', unicode_minus=False)     # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
else:
    print("âš ï¸ NanumGothic ì„¤ì¹˜ ì‹¤íŒ¨. ë‹¤ë¥¸ í°íŠ¸ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.")

# Figure & Axes ìƒì„±
fig, ax1 = plt.subplots(figsize=(10,5))

# ì˜µì…˜
plt.title("ì›”ë³„ ìì²´ê²°ì œ ë§¤ì¶œ & ìì²´ê²°ì œ ë§¤ì¶œ ë¹„ì¤‘ (24ë…„1ì›”~) ")

# ì²« ë²ˆì§¸ yì¶• (ì™¼ìª½, ë§‰ëŒ€ê·¸ë˜í”„)
ax1.bar(query_result2_monthlySelfPaymentSales["month"],
        query_result2_monthlySelfPaymentSales["rev_self"],
        color="#5B9BD5",
        #label="Sales"
        )
#ax1.set_ylabel("Sales", color="black")
ax1.tick_params(axis="y", labelcolor="black")

# ë‘ ë²ˆì§¸ yì¶• (ì˜¤ë¥¸ìª½, ì„ ê·¸ë˜í”„)
ax2 = ax1.twinx()
ax2.plot(query_result2_monthlySelfPaymentSales["month"],
         query_result2_monthlySelfPaymentSales["self_per"],
         color="#ED7D31",
         marker="o",
         #label="Users"
         )
#ax2.set_ylabel("Users", color="black")
ax2.tick_params(axis="y", labelcolor="black")

# ğŸ‘‰ ì„  ìœ„ì— ë°ì´í„° ë ˆì´ë¸” í‘œì‹œ
for x, y in zip(query_result2_monthlySelfPaymentSales["month"],
                query_result2_monthlySelfPaymentSales["self_per"]):
    ax2.annotate(f"{y:.0%}",  # 0.23 â†’ "23%"
                 xy=(x, y),
                 xytext=(0, 5),  # ì‚´ì§ ìœ„ë¡œ
                 textcoords="offset points",
                 ha="center", color="black"
                 )


# yì¶• ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸ ë„£ê¸°
ax1.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))

# í¼ì„¼íŠ¸ í¬ë§· ìë™ ì ìš© (self_perê°€ 0~1ì´ë©´ 1.0, 0~100ì´ë©´ 100)
maxv = float(query_result2_monthlySelfPaymentSales["self_per"].max())
ax2.yaxis.set_major_formatter(PercentFormatter(1.0 if maxv <= 1.5 else 100))

# xì¶• ëˆˆê¸ˆ(ê°’) ì„¸ë¡œ íšŒì „ â€” ì¶• ê°ì²´ì— ì§ì ‘ ì ìš©
for tick in ax1.get_xticklabels():
    tick.set_rotation(90)
    tick.set_ha("center")  # ë˜ëŠ” "right"ë¡œ ë°”ê¿”ë„ ë¨

# ì œëª© & ê²©ì
ax1.grid(axis="y", linestyle="--", alpha=0.7)

plt.tight_layout()

# í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
# #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
# ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
file_path2_monthlySelfPaymentSales = "/content/graph2_monthlySelfPaymentSales.png"
plt.savefig(file_path2_monthlySelfPaymentSales, dpi=160) # dpi : í•´ìƒë„
plt.close()


## ê·¸ë˜í”„ í•©ì¹˜ê¸°
### ìì²´ê²°ì œ ì¼ìë³„ + ìì²´ê²°ì œ ì›”ë³„

### Rê·¸ë£¹ë³„ ë§¤ì¶œê·¸ë˜í”„ì™€ PU ê·¸ë˜í”„ í•©ì¹˜ê¸°


# 1) íŒŒì¼ ê²½ë¡œ
p1 = "/content/graph2_dailySelfPaymentSales.png"   # ì²« ë²ˆì§¸ ì´ë¯¸ì§€
p2 = "/content/graph2_monthlySelfPaymentSales.png"   # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€
save_to = "/content/graph2_selfPaymentSales.png"  # ì €ì¥ ê²½ë¡œ

# 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
im1 = Image.open(p1).convert("RGBA")
im2 = Image.open(p2).convert("RGBA")

# ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
target_h = max(im1.height, im2.height)

def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
    if img.height == h:
        return img
    canvas = Image.new("RGBA", (img.width, h), bg)
    # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
    y = (h - img.height) // 2
    canvas.paste(img, (0, y))
    return canvas

im1_p = pad_to_height(im1, target_h)
im2_p = pad_to_height(im2, target_h)

gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
out.paste(im1_p, (0, 0), im1_p)
out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

# PNGë¡œ ì €ì¥
out.save(save_to)
print("Saved:", save_to)

filePath2_selfPaymentSales = "/content/graph2_selfPaymentSales.png"

########### (1) ì œëª©
notion.blocks.children.append(
    PAGE_ID,
    children=[
        {
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "2. ìì²´ê²°ì œ ë§¤ì¶œ" }}]
            },
        }
    ],
)

########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
# ì¼ìë³„ ìì²´ê²°ì œ



# 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
create_url = "https://api.notion.com/v1/file_uploads"
payload = {
    "filename": os.path.basename(filePath2_selfPaymentSales),
    "content_type": "image/png"
}
headers_json = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json"
}
resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
resp.raise_for_status()
file_upload = resp.json()
file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
# file_upload["upload_url"] ë„ ì‘ë‹µì— í¬í•¨ë¨

# 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data)
send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
with open(filePath2_selfPaymentSales, "rb") as f:
    files = {"file": (os.path.basename(filePath2_selfPaymentSales), f, "image/png")}
    headers_send = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION
        # Content-Typeì€ filesë¡œ ìë™ ì„¤ì •ë¨
    }
    send_resp = requests.post(send_url, headers=headers_send, files=files)
    send_resp.raise_for_status()


# 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
append_url = f"https://api.notion.com/v1/blocks/{PAGE_ID}/children"
append_payload = {
    "children": [
        {
            "object": "block",
            "type": "image",
            "image": {
                "type": "file_upload",
                "file_upload": {"id": file_upload_id},
                # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
            }
        }
    ]
}

headers_json_patch = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json"
}
append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
append_resp.raise_for_status()

## (3) ë¡œë°ì´í„°
resp = df_to_notion_table_under_toggle(
    notion=notion,
    page_id=PAGE_ID,
    df=query_result2_dailySelfPaymentSales,
    toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¼ìë³„ ìì²´ê²°ì œ ë§¤ì¶œ ",
    max_first_batch_rows=90,
    batch_size=100,
)

resp = df_to_notion_table_under_toggle(
    notion=notion,
    page_id=PAGE_ID,
    df=query_result2_monthlySelfPaymentSales,
    toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¥ê¸° ìì²´ê²°ì œ ë§¤ì¶œ ",
    max_first_batch_rows=90,
    batch_size=100,
)

## (4) ì œë¯¸ë‚˜ì´ í•´ì„

blocks = md_to_notion_blocks(response2_selfPaymentSales.text)

notion.blocks.children.append(
    block_id=PAGE_ID,
    children=blocks
)


## OSë³„ í˜„í™©
RUN_ID = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
LABELS = {"datascience_division_service": "gameinsight_framework",
          "run_id": RUN_ID,
          "datascience_division_service_sub" : "3_global_ua"} ## ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë¶™ì¼ ìˆ˜ ìˆìŒ.
print("RUN_ID=", RUN_ID, "LABEL_ID=", LABELS)

## ì´ë²ˆë‹¬ ê°€ì… ìœ ì €ì˜ êµ­ê°€ë³„ ë§¤ì¶œ
query = """

with countryRev as (

select country2 as country, rev_rank2 as rev_rank, sum(rev) as rev
from
(select country, rev
, case when rev_rank <= 9 then country  when rev_rank > 9 then 'etc' end as country2 # rev ê¸°ì¤€ 10ìœ„ë¶€í„°ëŠ” etc ë¡œ í‘œê¸°
, case when rev_rank <= 9 then rev_rank when rev_rank > 9 then 10 end as rev_rank2
from
(select country, rev, row_number() OVER (ORDER BY rev desc ) AS rev_rank # rev ìˆœì„œëŒ€ë¡œ ë­í¬
from
(select countrycode as country, cast(sum(pricekrw) as int64) as rev
from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
where joyplegameid = 133
and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
group by 1)
)
)
group by 1,2
order by rev_rank # etc êµ­ê°€ê°€ ë§¨ ë’¤ë¡œ ê°€ì•¼í•¨
),

allRev as  (
  select cast(sum(pricekrw) as int64) as rev
  from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
  where joyplegameid = 133
  and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
  and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
  and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
  and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
)

select a.*, safe_divide(a.rev,b.rev) as rev_percent
from
(select * from countryRev ) as a
cross join
(select * from allRev) as b
order by rev_rank

"""

## 129.93MB
query_result3_revByCountry = bigquery_client.query(query, job_config=bigquery.QueryJobConfig(labels=LABELS)).to_dataframe()

## ì´ë²ˆë‹¬ êµ­ê°€ë³„ COST
query = """

with countryCost as (

  select country2 as country, cost_rank2 as cost_rank, sum(cost) as cost
  from
  (select country, cost
  , case when cost_rank <= 9 then country when cost_rank > 9 then 'etc' end as country2 # cost ìˆœì„œëŒ€ë¡œ 10ìœ„ ë¶€í„°ëŠ” etc ë¡œ
  , case when cost_rank <= 9 then cost_rank else 10 end as cost_rank2
  from
  (select country, cost, row_number() OVER (ORDER BY cost desc ) AS cost_rank # cost ìˆœì„œë¡œ rank
  from
  (select countrycode as country, cast(sum(cost) as int64) cost
  from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
  where joyplegameid = 133
  and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
  and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
  group by countrycode))
  )
  group by 1,2
  order by cost_rank # etc êµ­ê°€ê°€ ë§¨ ë’¤ë¡œ ê°€ì•¼í•¨
),

allCost as (
  select cast(sum(cost) as int64) cost
  from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
  where joyplegameid = 133
  and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
  and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
)

select a.*, safe_divide(a.cost,b.cost) as cost_percent
from
(select * from countryCost) as a
cross join
(select * from allCost) as b
order by cost_rank


"""

## 129.93MB
query_result3_costByCountry = bigquery_client.query(query, job_config=bigquery.QueryJobConfig(labels=LABELS)).to_dataframe()


## êµ­ê°€ë³„ rev, cost í”„ë¡¬í”„íŠ¸
### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸

#client = genai.Client(api_key="AIzaSyAVv2B6DM6w9jd1MxiP3PbzAEMkl97SCGY")
response3_revAndCostByCountry = genai_client.models.generate_content(
model='gemini-2.5-flash',

contents = f"""
ì´ë²ˆë‹¬ì— ì–´ë–¤ êµ­ê°€ì— ë§ˆì¼€íŒ…í–ˆê³ , ì–´ë–¤ êµ­ê°€ì—ì„œ ì‹ ê·œìœ ì €ì˜ ë§¤ì¶œì´ ë‚˜ì™”ëŠ”ì§€ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì¤„ê²Œ.
ê°„ë‹¨í•˜ê²Œ í˜„í™© ìš”ì•½í•´ì¤˜.

ë‹¹ì›” ë§ˆì¼€íŒ…ë¹„ìš©ì€ ì–¼ë§ˆì´ë©° ë‹¹ì›” ì‹ ê·œìœ ì € ë§¤ì¶œì€ ì–¼ë§ˆì…ë‹ˆë‹¤ë¥¼ ë¨¼ì € í•œì¤„ë¡œ ì„œë‘ì— ì–¸ê¸‰í•´ì¤˜.
ì´ë²ˆë‹¬ COSTë§ì´ ì“´ êµ­ê°€ë“¤ ê°ê° COST ë¹„ì¤‘ì´ ëª‡% ì¸ì§€ í•œì¤„ì— ì¨ì£¼ê³ ,
ì‹ ê·œìœ ì € ë§¤ì¶œ ë†’ì€ êµ­ê°€ë“¤ ê°ê° ëª‡% ë§¤ì¶œ ë¹„ì¤‘ì¸ì§€ í•œì¤„ì— ì¨ì¤˜ ì•Œë ¤ì¤˜.
ê·¸ë¦¬ê³  ì£¼ìš” êµ­ê°€ë“¤ì— ëŒ€í•´ì„œ COST ë¹„ì¤‘ê³¼ ë§¤ì¶œë¹„ì¤‘ì„ ë¹„êµí•´ì„œ íŠ¹ì´í•œì ì´ ìˆëŠ”ê²ƒë§Œ ì•Œë ¤ì¤˜.

ë§¤ì¶œê³¼ COST ì˜ ì•¡ìˆ˜ ì ˆëŒ“ê°’ì„ ë¹„êµí•˜ì§€ ë§ê³  ë¹„ì¤‘ì„ ë¹„êµí•´ì¤˜.
etc ëŠ” ê¸°íƒ€ êµ­ê°€ë“¤ ì´ í•© í•œ ê°’ì´ë¼ì„œ etc ì— ëŒ€í•´ì„œëŠ” ì–¸ê¸‰í•˜ì§€ ë§ì•„ì¤˜.
ë§ˆì¼€íŒ… íš¨ìœ¨ê°œì„ ì´ í•„ìš”í•˜ë‹¤ëŠ”ë§ì€ í•˜ì§€ë§ì•„ì¤˜.

<ì›í•˜ëŠ” ì„œì‹>
1. ìš”ì•½í•´ì£¼ê² ë‹¤ ë§ í•˜ì§€ë§ê³  ìš”ì•½í•œ ë‚´ìš©ì— ëŒ€í•´ì„œë§Œ ì ì–´ì£¼ë©´ ë¼.
2. ìŠµë‹ˆë‹¤. ì²´ë¡œ ì¨ì¤˜
3. í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.

<ë°ì´í„° ì„¤ëª…>
ë§¤ì¶œì´ë‘ ë§ˆì¼€íŒ… ë¹„ìš©ì´ë‘ ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ 9ê°œ êµ­ê°€ì™€ ê·¸ ì´í›„ 10ë²ˆì§¸ êµ­ê°€ë¶€í„°ëŠ” ì „ë¶€ etc êµ­ê°€ë¡œ ì²˜ë¦¬í–ˆì–´.
etc ëŠ” êµ­ê°€ê°€ ì•„ë‹ˆë¼ ë‚˜ë¨¸ì§€ êµ­ê°€ ì´í•©ì´ì•¼.

<ì´ë²ˆë‹¬ ê°€ì…ìœ ì €ì˜ êµ­ê°€ë³„ ë§¤ì¶œ>
{query_result3_revByCountry}

<ì´ë²ˆë‹¬ êµ­ê°€ë³„ ë§ˆì¼€íŒ… ë¹„ìš©>
{query_result3_costByCountry}


""",
config=types.GenerateContentConfig(
        system_instruction=[
            "You're a Game Data Analyst.",
            "Your task is to analyze the metrics of a given mobile game and identify the causes of any changes.",
            "Your answers must be in Korean.",
            "The unit of amount in the Sales or Revenue, Cost Data is Korean Won.",
            "You must answer in Notion's Markdown format, but do not use title syntax.",
        ],
        # tools=[RAG],
        temperature=0.5
        ,labels=LABELS
    )

)
# ì½”ë©˜íŠ¸ ì¶œë ¥
print(response3_revAndCostByCountry.text)

# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

## OSë³„ cost
query = """
with osCost as (
select os, cast(sum(cost) as int64) cost
from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
where joyplegameid = 133
and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
group by os
),

allCost as (
select cast(sum(cost) as int64) cost
from `dataplatform-reporting.DataService.V_0410_0000_CostCampaignRule_V`
where joyplegameid = 133
and cmpgndate >= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and cmpgndate <=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
)

select a.*, safe_divide(a.cost,b.cost) as cost_percent
from
(select * from osCost) as a
cross join
(select * from allCost) as b
"""

## 129.93MB
query_result3_costByOs = bigquery_client.query(query, job_config=bigquery.QueryJobConfig(labels=LABELS)).to_dataframe()

## OSë³„ ë§¤ì¶œ
query = """
with osRev as (

select os, rev from (
select os, cast(sum(pricekrw) as int64) as rev
from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
where joyplegameid = 133
and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
group by 1)
where rev>0
),

allRev as (
select cast(sum(pricekrw) as int64) as rev
from `dataplatform-reporting.DataService.V_0317_0000_AuthAccountPerformance_V`
where joyplegameid = 133
and logdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and logdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and authaccountregdatekst>= DATE_TRUNC(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
and authaccountregdatekst<=LAST_DAY(DATE_SUB(CURRENT_DATE('Asia/Seoul'), INTERVAL 1 DAY), MONTH)
)


select a.*, safe_divide(a.rev,b.rev) as rev_percent
from
(select * from osRev) as a
cross join
(select * from allRev) as b
"""

## 129.93MB
query_result3_revByOs = bigquery_client.query(query, job_config=bigquery.QueryJobConfig(labels=LABELS)).to_dataframe()

### 4> ì¼ìë³„ ë§¤ì¶œì— ëŒ€í•œ ì œë¯¸ë‚˜ì´ ì½”ë©˜íŠ¸

#client = genai.Client(api_key="AIzaSyAVv2B6DM6w9jd1MxiP3PbzAEMkl97SCGY")
response3_revAndCostByOs = genai_client.models.generate_content(
model='gemini-2.5-flash',

contents = f"""

ì´ë²ˆë‹¬ì— IOS ì— ëª‡ % ë§ˆì¼€íŒ… ë¹„ìš© ì‚¬ìš©í–ˆìœ¼ë©° IOS ì˜ ë§¤ì¶œë¹„ì¤‘ì€ ëª‡% ì…ë‹ˆë‹¤.
ì˜ í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì¤˜.


<ì›í•˜ëŠ” ì„œì‹>
1. ìš”ì•½í•´ì£¼ê² ë‹¤ ë§ í•˜ì§€ë§ê³  ìš”ì•½í•œ ë‚´ìš©ì— ëŒ€í•´ì„œë§Œ ì ì–´ì£¼ë©´ ë¼.
2. ìŠµë‹ˆë‹¤. ì²´ë¡œ ì¨ì¤˜
3. í•œ ë¬¸ì¥ë§ˆë‹¤ ë…¸ì…˜ì˜ ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ ë¬¸ë²•ì„ ì‚¬ìš©í•´ì¤˜. e.g. * ë‹¹ì›” ë§¤ì¶œì€ ì´ë ‡ìŠµë‹ˆë‹¤.


<ë°ì´í„° ì„¤ëª…>


<ì´ë²ˆë‹¬ ê°€ì…ìœ ì €ì˜ OSë³„ ë§¤ì¶œ>
{query_result3_revByOs}

<ì´ë²ˆë‹¬ OSë³„ ë§ˆì¼€íŒ… ë¹„ìš©>
{query_result3_costByOs}


""",
config=types.GenerateContentConfig(
        system_instruction=[
            "You're a Game Data Analyst.",
            "Your task is to analyze the metrics of a given mobile game and identify the causes of any changes.",
            "Your answers must be in Korean.",
            "The unit of amount in the Sales or Revenue, Cost Data is Korean Won.",
            "You must answer in Notion's Markdown format, but do not use title syntax.",
        ],
        # tools=[RAG],
        temperature=0.5
        ,labels=LABELS
    )

)
# ì½”ë©˜íŠ¸ ì¶œë ¥
print(response3_revAndCostByOs.text)

# ì½”ë©˜íŠ¸ ì •ë¦¬ ( í–¥í›„ ìš”ì•½ì— ì‚¬ìš©í•˜ê¸° ìš©ë„ )
#gemini_result.loc[len(gemini_result)] = response.text

### ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
## êµ­ê°€ë³„ ë§¤ì¶œ

sizes = query_result3_revByCountry["rev"].to_numpy()
labels = query_result3_revByCountry["country"].to_numpy()
total  = sizes.sum()

fig, ax = plt.subplots(figsize=(5,5))
wedges, _ = ax.pie(sizes, labels=None, startangle=90)

# ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
angles = [(p.theta1 + p.theta2)/2 for p in wedges]
inside_r, outside_r = 0.6, 1.28

# 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
texts = []
for ang, size, name in zip(angles, sizes, labels):
    percent = size / total * 100
    txt = f"{name} ({percent:.1f}%)"
    x_in = np.cos(np.deg2rad(ang)) * inside_r
    y_in = np.sin(np.deg2rad(ang)) * inside_r
    t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
    texts.append(t)

# 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
def any_overlaps(texts, renderer):
    bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
    overlaps = set()
    for i in range(len(bboxes)):
        for j in range(i+1, len(bboxes)):
            if bboxes[i].overlaps(bboxes[j]):
                overlaps.add(i); overlaps.add(j)
    return overlaps

# 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
over_idx = any_overlaps(texts, fig.canvas.get_renderer())

# ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
for i in idx_sorted:
    ang = angles[i]
    # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
    x_out = np.cos(np.deg2rad(ang)) * outside_r
    y_out = np.sin(np.deg2rad(ang)) * outside_r
    # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
    x_edge = np.cos(np.deg2rad(ang)) * 1.0
    y_edge = np.sin(np.deg2rad(ang)) * 1.0

    # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
    txt_str = texts[i].get_text()
    texts[i].set_visible(False)

    # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
    ha = 'left' if x_out >= 0 else 'right'
    ax.annotate(
        txt_str,
        xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
        xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
        ha=ha, va='center', fontsize=9, color='black',
        arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
    )
ax.set_title("êµ­ê°€ë³„ ë§¤ì¶œ ë¹„ì¤‘", pad=24)
#plt.title("êµ­ê°€ë³„ ë§¤ì¶œ ë¹„ì¤‘")
plt.tight_layout()

# í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
# #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
# ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
filepath3_revByCountry = "/content/graph3_revByCountry.png"
plt.savefig(filepath3_revByCountry, dpi=110) # dpi : í•´ìƒë„
plt.close()

### êµ­ê°€ë³„ Cost
sizes = query_result3_costByCountry["cost"].to_numpy()
labels = query_result3_costByCountry["country"].to_numpy()
total  = sizes.sum()


fig, ax = plt.subplots(figsize=(5,5))
wedges, _ = ax.pie(sizes, labels=None, startangle=90)

# ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
angles = [(p.theta1 + p.theta2)/2 for p in wedges]
inside_r, outside_r = 0.6, 1.28

# 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
texts = []
for ang, size, name in zip(angles, sizes, labels):
    percent = size / total * 100
    txt = f"{name} ({percent:.1f}%)"
    x_in = np.cos(np.deg2rad(ang)) * inside_r
    y_in = np.sin(np.deg2rad(ang)) * inside_r
    t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
    texts.append(t)

# 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
def any_overlaps(texts, renderer):
    bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
    overlaps = set()
    for i in range(len(bboxes)):
        for j in range(i+1, len(bboxes)):
            if bboxes[i].overlaps(bboxes[j]):
                overlaps.add(i); overlaps.add(j)
    return overlaps

# 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
over_idx = any_overlaps(texts, fig.canvas.get_renderer())

# ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
for i in idx_sorted:
    ang = angles[i]
    # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
    x_out = np.cos(np.deg2rad(ang)) * outside_r
    y_out = np.sin(np.deg2rad(ang)) * outside_r
    # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
    x_edge = np.cos(np.deg2rad(ang)) * 1.0
    y_edge = np.sin(np.deg2rad(ang)) * 1.0

    # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
    txt_str = texts[i].get_text()
    texts[i].set_visible(False)

    # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
    ha = 'left' if x_out >= 0 else 'right'
    ax.annotate(
        txt_str,
        xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
        xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
        ha=ha, va='center', fontsize=9, color='black',
        arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
    )
ax.set_title("êµ­ê°€ë³„ COST ë¹„ì¤‘", pad=24)
plt.tight_layout()

# í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
# #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
# ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
filepath3_costByCountry = "/content/graph3_costByCountry.png"
plt.savefig(filepath3_costByCountry, dpi=110) # dpi : í•´ìƒë„
plt.close()



### êµ­ê°€ë³„ ê·¸ë˜í”„ë“¤ ì´ë¯¸ì§€ í•©ì¹˜ê¸°
p1 = "/content/graph3_revByCountry.png"   # ì²« ë²ˆì§¸ ì´ë¯¸ì§€
p2 = "/content/graph3_costByCountry.png"   # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€
save_to = "/content/graph3_revAndCostByCountry.png"  # ì €ì¥ ê²½ë¡œ

# 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
im1 = Image.open(p1).convert("RGBA")
im2 = Image.open(p2).convert("RGBA")

# ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
target_h = max(im1.height, im2.height)

def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
    if img.height == h:
        return img
    canvas = Image.new("RGBA", (img.width, h), bg)
    # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
    y = (h - img.height) // 2
    canvas.paste(img, (0, y))
    return canvas

im1_p = pad_to_height(im1, target_h)
im2_p = pad_to_height(im2, target_h)

gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
out.paste(im1_p, (0, 0), im1_p)
out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

# PNGë¡œ ì €ì¥
out.save(save_to)
print("Saved:", save_to)

filePath3_revAndCostByCountry = "/content/graph3_revAndCostByCountry.png"


### OS ë³„ ë§¤ì¶œ

sizes = query_result3_revByOs["rev"].to_numpy()
labels = query_result3_revByOs["os"].to_numpy()
total  = sizes.sum()


fig, ax = plt.subplots(figsize=(5,5))
wedges, _ = ax.pie(sizes, labels=None, startangle=90)

# ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
angles = [(p.theta1 + p.theta2)/2 for p in wedges]
inside_r, outside_r = 0.6, 1.28

# 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
texts = []
for ang, size, name in zip(angles, sizes, labels):
    percent = size / total * 100
    txt = f"{name} ({percent:.1f}%)"
    x_in = np.cos(np.deg2rad(ang)) * inside_r
    y_in = np.sin(np.deg2rad(ang)) * inside_r
    t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
    texts.append(t)

# 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
def any_overlaps(texts, renderer):
    bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
    overlaps = set()
    for i in range(len(bboxes)):
        for j in range(i+1, len(bboxes)):
            if bboxes[i].overlaps(bboxes[j]):
                overlaps.add(i); overlaps.add(j)
    return overlaps

# 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
over_idx = any_overlaps(texts, fig.canvas.get_renderer())

# ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
for i in idx_sorted:
    ang = angles[i]
    # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
    x_out = np.cos(np.deg2rad(ang)) * outside_r
    y_out = np.sin(np.deg2rad(ang)) * outside_r
    # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
    x_edge = np.cos(np.deg2rad(ang)) * 1.0
    y_edge = np.sin(np.deg2rad(ang)) * 1.0

    # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
    txt_str = texts[i].get_text()
    texts[i].set_visible(False)

    # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
    ha = 'left' if x_out >= 0 else 'right'
    ax.annotate(
        txt_str,
        xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
        xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
        ha=ha, va='center', fontsize=9, color='black',
        arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
    )

ax.set_title("OSë³„ ë§¤ì¶œ ë¹„ì¤‘", pad=24)
plt.tight_layout()

# í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
# #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
# ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
filepath3_revByOs = "/content/graph3_revByOs.png"
plt.savefig(filepath3_revByOs, dpi=110) # dpi : í•´ìƒë„
plt.close()


### os ë³„ Cost

sizes = query_result3_costByOs["cost"].to_numpy()
labels = query_result3_costByOs["os"].to_numpy()
total  = sizes.sum()


fig, ax = plt.subplots(figsize=(5,5))
wedges, _ = ax.pie(sizes, labels=None, startangle=90)

# ê° ì›¨ì§€ì˜ ì¤‘ì•™ê°(ë„), ë‚´ë¶€/ì™¸ë¶€ ì¢Œí‘œ ê³„ì‚°
angles = [(p.theta1 + p.theta2)/2 for p in wedges]
inside_r, outside_r = 0.6, 1.28

# 1) ë¼ë²¨ì„ "ì´ë¦„ (x.x%)" í˜•ì‹ìœ¼ë¡œ ìš°ì„  ë‚´ë¶€ì— ë°°ì¹˜
texts = []
for ang, size, name in zip(angles, sizes, labels):
    percent = size / total * 100
    txt = f"{name} ({percent:.1f}%)"
    x_in = np.cos(np.deg2rad(ang)) * inside_r
    y_in = np.sin(np.deg2rad(ang)) * inside_r
    t = ax.text(x_in, y_in, txt, ha='center', va='center', fontsize=9, color="black")
    texts.append(t)

# 2) ê²¹ì¹¨ ê°ì§€ í•¨ìˆ˜ (ë””ìŠ¤í”Œë ˆì´ ì¢Œí‘œì—ì„œ bbox ê²¹ì¹¨ í™•ì¸)
def any_overlaps(texts, renderer):
    bboxes = [t.get_window_extent(renderer=renderer).expanded(1.05, 1.2) for t in texts]
    overlaps = set()
    for i in range(len(bboxes)):
        for j in range(i+1, len(bboxes)):
            if bboxes[i].overlaps(bboxes[j]):
                overlaps.add(i); overlaps.add(j)
    return overlaps

# 3) ê²¹ì¹˜ëŠ” ê²ƒë§Œ ì™¸ë¶€ë¡œ ì¬ë°°ì¹˜ + í™”ì‚´í‘œ ì—°ê²° (ì‘ì€ íŒŒì´ì¼ìˆ˜ë¡ ìš°ì„  ì´ë™)
fig.canvas.draw()  # ë Œë”ëŸ¬ ì¤€ë¹„
over_idx = any_overlaps(texts, fig.canvas.get_renderer())

# ê²¹ì¹˜ëŠ” í…ìŠ¤íŠ¸ ì¤‘, ì›¨ì§€ ë©´ì (=sizes) ì‘ì€ ê²ƒë¶€í„° ë°”ê¹¥ìœ¼ë¡œ
idx_sorted = sorted(list(over_idx), key=lambda i: sizes[i])
for i in idx_sorted:
    ang = angles[i]
    # ì› ë°– ë¼ë²¨ ìœ„ì¹˜
    x_out = np.cos(np.deg2rad(ang)) * outside_r
    y_out = np.sin(np.deg2rad(ang)) * outside_r
    # ì› ê²½ê³„ ìª½(í™”ì‚´í‘œ ê¸°ì¤€ì )
    x_edge = np.cos(np.deg2rad(ang)) * 1.0
    y_edge = np.sin(np.deg2rad(ang)) * 1.0

    # ê¸°ì¡´ ë‚´ë¶€ í…ìŠ¤íŠ¸ ìˆ¨ê¸°ê³ (ë˜ëŠ” ì œê±°) ë°”ê¹¥ì— ìƒˆë¡œ ë°°ì¹˜
    txt_str = texts[i].get_text()
    texts[i].set_visible(False)

    # ì¢Œìš° ì •ë ¬ì€ ë°˜ëŒ€ìª½ìœ¼ë¡œ ë§ì¶”ë©´ ë³´ê¸° ì¢‹ìŒ
    ha = 'left' if x_out >= 0 else 'right'
    ax.annotate(
        txt_str,
        xy=(x_edge, y_edge), xycoords='data',           # í™”ì‚´í‘œ ë„ì°©ì (íŒŒì´ ê²½ê³„)
        xytext=(x_out, y_out), textcoords='data',       # í…ìŠ¤íŠ¸ ìœ„ì¹˜(ì› ë°–)
        ha=ha, va='center', fontsize=9, color='black',
        arrowprops=dict(arrowstyle='-', color='gray', shrinkA=0, shrinkB=0)
    )

ax.set_title("OSë³„ COST ë¹„ì¤‘", pad=24)
plt.tight_layout()

# í–¥í›„ ë…¸ì…˜ì—…ë¡œë“œí•˜ê¸° ìœ„í•´ ì €ì¥
# #print(os.getcwd()) ì´ ê³³ì— ì €ì¥ë˜ê³ , colab í™˜ê²½ì´ë¼ ì¢Œì¸¡ í´ë”ëª¨ì–‘ ëˆ„ë¥´ë©´ png ìˆìŒ.
# ì„¸ì…˜ ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì‚­ì œë¨
filepath3_costByOs = "/content/graph3_costByOs.png"
plt.savefig(filepath3_costByOs, dpi=110) # dpi : í•´ìƒë„
plt.close()


## OSë³„ ê·¸ë˜í”„ë“¤ ì´ë¯¸ì§€ í•©ì¹˜ê¸°
# 1) íŒŒì¼ ê²½ë¡œ
p1 = "/content/graph3_revByOs.png"   # ì²« ë²ˆì§¸ ì´ë¯¸ì§€
p2 = "/content/graph3_costByOs.png"   # ë‘ ë²ˆì§¸ ì´ë¯¸ì§€
save_to = "/content/graph3_revAndCostByOs.png"  # ì €ì¥ ê²½ë¡œ

# 2) ì´ë¯¸ì§€ ì—´ê¸° (íˆ¬ëª… ë³´ì¡´ ìœ„í•´ RGBA)
im1 = Image.open(p1).convert("RGBA")
im2 = Image.open(p2).convert("RGBA")

# ---- [ì˜µì…˜ A] ì›ë³¸ í¬ê¸° ìœ ì§€ + ì„¸ë¡œ íŒ¨ë”©ìœ¼ë¡œ ë†’ì´ ë§ì¶”ê¸° (ê¶Œì¥: ì™œê³¡ ì—†ìŒ) ----
target_h = max(im1.height, im2.height)

def pad_to_height(img, h, bg=(255, 255, 255, 0)):  # íˆ¬ëª… ë°°ê²½: ì•ŒíŒŒ 0
    if img.height == h:
        return img
    canvas = Image.new("RGBA", (img.width, h), bg)
    # ê°€ìš´ë° ì •ë ¬ë¡œ ë¶™ì´ê¸° (ìœ„ì— ë§ì¶”ë ¤ë©´ y=0)
    y = (h - img.height) // 2
    canvas.paste(img, (0, y))
    return canvas

im1_p = pad_to_height(im1, target_h)
im2_p = pad_to_height(im2, target_h)

gap = 0  # ì´ë¯¸ì§€ ì‚¬ì´ ì—¬ë°±(px). í•„ìš”í•˜ë©´ 20 ë“±ìœ¼ë¡œ ë³€ê²½
bg = (255, 255, 255, 0)  # ì „ì²´ ë°°ê²½(íˆ¬ëª…). í°ìƒ‰ ì›í•˜ë©´ (255,255,255,255)

out = Image.new("RGBA", (im1_p.width + gap + im2_p.width, target_h), bg)
out.paste(im1_p, (0, 0), im1_p)
out.paste(im2_p, (im1_p.width + gap, 0), im2_p)

# PNGë¡œ ì €ì¥
out.save(save_to)
print("Saved:", save_to)

filePath3_revAndCostByOs = "/content/graph3_revAndCostByOs.png"


#### ë…¸ì…˜ì— ì—…ë¡œë“œ
########### (1) ì œëª©
notion.blocks.children.append(
    PAGE_ID,
    children=[
        {
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "3. ê¸€ë¡œë²Œ ëª¨ê° ì§€í‘œ " }}]
            },
        }
    ],
)


########### (3) ì œë¯¸ë‚˜ì´ í•´ì„

notion.blocks.children.append(
    PAGE_ID,
    children=[
        {
            "object": "block",
            "type": "heading_3",
            "heading_3": {
                "rich_text": [{"type": "text", "text": {"content": "(1) êµ­ê°€ë³„ ë§ˆì¼€íŒ…ë¹„ìš©ê³¼ ë§¤ì¶œë¹„ì¤‘" }}]
            },
        }
    ],
)

########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
## IAP+ìœ ê°€ì ¬


# 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
create_url = "https://api.notion.com/v1/file_uploads"
payload = {
    "filename": os.path.basename(filePath3_revAndCostByCountry),
    "content_type": "image/png"
}
headers_json = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json"
}
resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
resp.raise_for_status()
file_upload = resp.json()
file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
# file_upload["upload_url"] ë„ ì‘ë‹µì— í¬í•¨ë¨

# 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data)
send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
with open(filePath3_revAndCostByCountry, "rb") as f:
    files = {"file": (os.path.basename(filePath3_revAndCostByCountry), f, "image/png")}
    headers_send = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION
        # Content-Typeì€ filesë¡œ ìë™ ì„¤ì •ë¨
    }
    send_resp = requests.post(send_url, headers=headers_send, files=files)
    send_resp.raise_for_status()


# 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
append_url = f"https://api.notion.com/v1/blocks/{PAGE_ID}/children"
append_payload = {
    "children": [
        {
            "object": "block",
            "type": "image",
            "image": {
                "type": "file_upload",
                "file_upload": {"id": file_upload_id},
                # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
            }
        }
    ]
}

headers_json_patch = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json"
}
append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
append_resp.raise_for_status()

### ë¡œë°ì´í„° ì œê³µ
resp = df_to_notion_table_under_toggle(
    notion=notion,
    page_id=PAGE_ID,
    df=query_result3_revByCountry,
    toggle_title="ğŸ“Š ë¡œë°ì´í„° - êµ­ê°€ë³„ ë§¤ì¶œ ",
    max_first_batch_rows=90,
    batch_size=100,
)
resp = df_to_notion_table_under_toggle(
    notion=notion,
    page_id=PAGE_ID,
    df=query_result3_costByCountry,
    toggle_title="ğŸ“Š ë¡œë°ì´í„° - êµ­ê°€ë³„ COST  ",
    max_first_batch_rows=90,
    batch_size=100,
)


### êµ­ê°€ë³„ cost rev ì½”ë©˜íŠ¸
########### (3) ì œë¯¸ë‚˜ì´ í•´ì„
blocks = md_to_notion_blocks(response3_revAndCostByCountry.text)
notion.blocks.children.append(
    block_id=PAGE_ID,
    children=blocks
)


## ë¶€ì œëª©
notion.blocks.children.append(
    PAGE_ID,
    children=[
        {
            "object": "block",
            "type": "heading_3",
            "heading_3": {
                "rich_text": [{"type": "text", "text": {"content": "(2) OSë³„ ë§ˆì¼€íŒ…ë¹„ìš©ê³¼ ë§¤ì¶œë¹„ì¤‘" }}]
            },
        }
    ],
)


## osë³„ cost, rev ê·¸ë˜í”„
########### (2) ê·¸ë˜í”„ ì—…ë¡œë“œ
## IAP+ìœ ê°€ì ¬


# 1) ì—…ë¡œë“œ ê°ì²´ ìƒì„± (file_upload ìƒì„±)
create_url = "https://api.notion.com/v1/file_uploads"
payload = {
    "filename": os.path.basename(filePath3_revAndCostByOs),
    "content_type": "image/png"
}
headers_json = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json"
}
resp = requests.post(create_url, headers=headers_json, data=json.dumps(payload))
resp.raise_for_status()
file_upload = resp.json()
file_upload_id = file_upload["id"]   # ì—…ë¡œë“œ ID
# file_upload["upload_url"] ë„ ì‘ë‹µì— í¬í•¨ë¨

# 2) íŒŒì¼ ë°”ì´ë„ˆë¦¬ ì „ì†¡ (multipart/form-data)
send_url = f"https://api.notion.com/v1/file_uploads/{file_upload_id}/send"
with open(filePath3_revAndCostByOs, "rb") as f:
    files = {"file": (os.path.basename(filePath3_revAndCostByOs), f, "image/png")}
    headers_send = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": NOTION_VERSION
        # Content-Typeì€ filesë¡œ ìë™ ì„¤ì •ë¨
    }
    send_resp = requests.post(send_url, headers=headers_send, files=files)
    send_resp.raise_for_status()


# 3) ì´ë¯¸ì§€ ë¸”ë¡ìœ¼ë¡œ í˜ì´ì§€ì— ì²¨ë¶€
append_url = f"https://api.notion.com/v1/blocks/{PAGE_ID}/children"
append_payload = {
    "children": [
        {
            "object": "block",
            "type": "image",
            "image": {
                "type": "file_upload",
                "file_upload": {"id": file_upload_id},
                # ìº¡ì…˜ì„ ë‹¬ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
                # "caption": [{"type": "text", "text": {"content": "ìë™ ì—…ë¡œë“œëœ ê·¸ë˜í”„"}}]
            }
        }
    ]
}

headers_json_patch = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json"
}
append_resp = requests.patch(append_url, headers=headers_json_patch, data=json.dumps(append_payload))
append_resp.raise_for_status()

### ë¡œë°ì´í„° ì œê³µ
resp = df_to_notion_table_under_toggle(
    notion=notion,
    page_id=PAGE_ID,
    df=query_result3_revByOs,
    toggle_title="ğŸ“Š ë¡œë°ì´í„° - ì¥ê¸° ìì²´ê²°ì œ ë§¤ì¶œ ",
    max_first_batch_rows=90,
    batch_size=100,
)

resp = df_to_notion_table_under_toggle(
    notion=notion,
    page_id=PAGE_ID,
    df=query_result3_costByOs,
    toggle_title="ğŸ“Š ë¡œë°ì´í„° - OSë³„ COST ",
    max_first_batch_rows=90,
    batch_size=100,
)

## osë³„ cost, rev ì½”ë©˜íŠ¸
########### (3) ì œë¯¸ë‚˜ì´ í•´ì„
blocks = md_to_notion_blocks(response3_revAndCostByOs.text)
notion.blocks.children.append(
    block_id=PAGE_ID,
    children=blocks
)







