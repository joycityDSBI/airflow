"""
ìˆ˜ì •ëœ notion_utils.py
- Notion ì„¤ì • ê²€ì¦ ê°•í™”
- ì—ëŸ¬ ì²˜ë¦¬ ê°œì„  (raise ì¶”ê°€)
- ë¡œê¹… ê°•í™”
"""

import os
import time
import json
import random
import logging
from datetime import datetime
from typing import Dict, Set, Tuple, List
import requests
import pandas as pd
from airflow.models import Variable

logging.basicConfig(level=logging.INFO)


def get_var(key: str, default: str = None) -> str:
    """í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Airflow Variable ì¡°íšŒ"""
    return os.environ.get(key) or Variable.get(key, default_var=default)


# ===== Notion ENV (ì´ 4ê°œë§Œ í™˜ê²½ë³€ìˆ˜ë¡œ ì‚¬ìš©) =====
NOTION_TOKEN = get_var("NOTION_TOKEN")
DB_A_ID = get_var("NOTION_DB_A")  # í…Œì´ë¸” ì •ë³´ìš© (í‚¤: Hub í…Œì´ë¸”ëª…)
DB_B_ID = get_var("NOTION_DB_B")  # ì»¬ëŸ¼ ì •ë³´ìš© (í‚¤: Hub ì»¬ëŸ¼ëª…)
DB_C_ID = get_var("NOTION_DB_C")  # í…Œì´ë¸”-ì»¬ëŸ¼ ë§¤í•‘ìš© (relation: A/B)

# ğŸ“Œ ì„¤ì • ê²€ì¦ í•¨ìˆ˜
def validate_notion_config() -> bool:
    """Notion ì„¤ì • ê²€ì¦"""
    if not NOTION_TOKEN:
        logging.error("âŒ NOTION_TOKENì´ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    if not DB_A_ID:
        logging.error("âŒ NOTION_DB_Aê°€ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    if not DB_B_ID:
        logging.error("âŒ NOTION_DB_Bê°€ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    if not DB_C_ID:
        logging.error("âŒ NOTION_DB_Cê°€ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    logging.info("âœ… Notion ì„¤ì • ê²€ì¦ ì™„ë£Œ")
    logging.info(f"   Token: {NOTION_TOKEN[:20]}...")
    logging.info(f"   DB_A: {DB_A_ID[:20]}...")
    logging.info(f"   DB_B: {DB_B_ID[:20]}...")
    logging.info(f"   DB_C: {DB_C_ID[:20]}...")
    
    return True


# ì´ˆê¸°í™” ì‹œ ê²€ì¦
if not (NOTION_TOKEN and DB_A_ID and DB_B_ID and DB_C_ID):
    logging.error("âš ï¸ Notion ì„¤ì • ëˆ„ë½! update_notion_databases í˜¸ì¶œ ì‹œ ì‹¤íŒ¨í•©ë‹ˆë‹¤.")

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}" if NOTION_TOKEN else "Bearer INVALID",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28",
}

# ===== ê³ ì • íŒŒë¼ë¯¸í„°(í•˜ë“œì½”ë”©) =====
PAGE_SIZE        = 100      # Notion API ìµœëŒ€ 100
MAX_PAGES_SCAN   = 200      # 100 * 200 = ìµœëŒ€ 20,000ê±´ ìŠ¤ìº”
MAX_RETRY        = 5        # 429/5xx ì¬ì‹œë„ íšŸìˆ˜
RATE_LIMIT_SLEEP = 0.35     # 3 rps ê°€ë“œ
REQ_TIMEOUT      = 30       # ìš”ì²­ íƒ€ì„ì•„ì›ƒ(ì´ˆ)


# ===== ê³µí†µ HTTP ìš”ì²­ (ì¬ì‹œë„/ë°±ì˜¤í”„) =====
def request_with_retry(method: str, url: str, **kwargs) -> requests.Response:
    """HTTP ìš”ì²­ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    if "headers" not in kwargs:
        kwargs["headers"] = HEADERS
    if "timeout" not in kwargs:
        kwargs["timeout"] = REQ_TIMEOUT

    last = None
    for attempt in range(1, MAX_RETRY + 1):
        try:
            res = requests.request(method, url, **kwargs)
        except requests.RequestException as e:
            wait = min(2 ** attempt, 16) + random.random()
            logging.warning(f"â³ ìš”ì²­ ì˜ˆì™¸ ì¬ì‹œë„ {attempt}/{MAX_RETRY}: {e} â€” {wait:.1f}s ëŒ€ê¸°")
            time.sleep(wait)
            continue

        # ğŸ“Œ ìƒíƒœ ì½”ë“œë³„ ì²˜ë¦¬
        if res.status_code in (429, 500, 502, 503, 504):
            wait = min(2 ** attempt, 16) + random.random()
            logging.warning(f"â³ {res.status_code} ì¬ì‹œë„ {attempt}/{MAX_RETRY}: {res.text[:200]} â€” {wait:.1f}s ëŒ€ê¸°")
            time.sleep(wait)
            last = res
            continue
        
        # ğŸ“Œ 4xx ì—ëŸ¬ (401/403/404 ë“±) - ëª…ì‹œì  ë¡œê¹…
        if 400 <= res.status_code < 500:
            logging.error(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {res.status_code} {method} {url[:60]}...")
            logging.error(f"   ì‘ë‹µ: {res.text[:500]}")
        
        return res
    
    # ğŸ“Œ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
    if last:
        logging.error(f"âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ({MAX_RETRY}íšŒ): {last.status_code}")
    return last


# ===== í…ìŠ¤íŠ¸ ì¶”ì¶œ ìœ í‹¸ =====
def extract_text(prop: dict) -> str | None:
    """Notion ì†ì„±ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    arr = prop.get("title") or prop.get("rich_text")
    if not arr:
        return None
    parts = []
    for item in arr:
        t = item.get("text", {})
        if "content" in t:
            parts.append(t["content"])
    txt = "".join(parts).strip()
    return txt or None


# ===== DB í˜ì´ì§• =====
def notion_paginate(database_id: str, page_size: int = PAGE_SIZE, max_pages: int = MAX_PAGES_SCAN):
    """Notion DB í˜ì´ì§• ì¡°íšŒ"""
    next_cursor = None
    pages = 0
    while True:
        body = {"page_size": page_size}
        if next_cursor:
            body["start_cursor"] = next_cursor

        res = request_with_retry("POST", f"https://api.notion.com/v1/databases/{database_id}/query", json=body)
        if not res or res.status_code != 200:
            logging.error(f"âŒ DB ì¡°íšŒ ì‹¤íŒ¨: {res.status_code if res else 'ERR'} - {res.text[:200] if res else ''}")
            break

        data = res.json()
        for page in data.get("results", []):
            yield page

        if not data.get("has_more"):
            break
        next_cursor = data.get("next_cursor")
        pages += 1
        if pages >= max_pages:
            logging.warning(f"âš ï¸ í˜ì´ì§€ ìƒí•œ ë„ë‹¬(max_pages={max_pages})")
            break
        time.sleep(RATE_LIMIT_SLEEP)


# ===== A/B ID ë§µ ì¡°íšŒ =====
def notion_query_id_map(database_id: str, target_column: str, *, silent: bool = False, label: str = "") -> dict:
    """Notion DBì—ì„œ ID ë§µ ì¡°íšŒ (í‚¤: ì»¬ëŸ¼ê°’, ê°’: page_id)"""
    id_map: dict[str, str] = {}
    for page in notion_paginate(database_id):
        pid = page["id"]
        prop = page["properties"].get(target_column, {})
        key = extract_text(prop)
        if key:
            id_map[key] = pid
    if not silent:
        suffix = f" {label}" if label else ""
        logging.info(f"ğŸ” ID ë§µ ë¡œë“œ{suffix}: {target_column} {len(id_map)}ê±´")
    return id_map


# ===== ë‹¨ì¼ Insert =====
def notion_insert(database_id: str, field_name: str, value: str, is_title: bool = True) -> bool:
    """Notion DBì— í•­ëª© ì¶”ê°€"""
    field_type = "title" if is_title else "rich_text"
    payload = {
        "parent": {"database_id": database_id},
        "properties": {
            field_name: {field_type: [{"text": {"content": value}}]}
        }
    }
    res = request_with_retry("POST", "https://api.notion.com/v1/pages", json=payload)
    if res and res.status_code == 200:
        logging.info(f"âœ… Insert ì„±ê³µ: {value}")
        return True
    logging.error(f"âŒ Insert ì‹¤íŒ¨: {res.status_code if res else 'ERR'} - {res.text[:200] if res else ''}")
    return False


# ===== ê´€ê³„(Relation) í—¬í¼ =====
def get_relation_ids(page_props: dict, prop_name: str) -> List[str]:
    """Relation ì†ì„±ì—ì„œ page ID ì¶”ì¶œ"""
    rel = page_props.get(prop_name, {})
    return [r.get("id") for r in rel.get("relation", []) if "id" in r]


def archive_page(page_id: str) -> bool:
    """í˜ì´ì§€ ì•„ì¹´ì´ë¸Œ"""
    res = request_with_retry("PATCH", f"https://api.notion.com/v1/pages/{page_id}", json={"archived": True})
    code = res.status_code if res else "ERR"
    logging.info(f"ğŸ—„ï¸ archive page {page_id} -> {code}")
    return bool(res and res.status_code == 200)


def _parse_iso8601_to_ts(s: str) -> float:
    """ISO8601 â†’ epoch seconds"""
    try:
        if s.endswith("Z"):
            s = s[:-1] + "+00:00"
        return datetime.fromisoformat(s).timestamp()
    except Exception:
        return 0.0


def cleanup_db_c_orphans(a_id_map: Dict[str, str], b_id_map: Dict[str, str], *, dry_run: bool = False) -> dict:
    """
    C í…Œì´ë¸” ì‚¬ì „ ì •ë¦¬:
    1) relation ë¹„ì—ˆìœ¼ë©´ â†’ archive
    2) relation idê°€ A/Bì˜ ìœ íš¨ id ì§‘í•©ì— ì—†ìœ¼ë©´ â†’ archive
    3) (a_id, b_id) ì¤‘ë³µì´ ì—¬ëŸ¬ ê±´ì´ë©´ ê°€ì¥ ì˜¤ë˜ëœ 1ê±´ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ â†’ archive
    """
    valid_a: Set[str] = set(a_id_map.values())
    valid_b: Set[str] = set(b_id_map.values())

    orphan: List[str] = []      # relation ë¹„ì–´ìˆëŠ” C í˜ì´ì§€
    invalid: List[str] = []     # A/Bì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” idë¥¼ ì°¸ì¡°í•˜ëŠ” C í˜ì´ì§€
    dedup: List[str] = []       # (a,b) ì¤‘ë³µ ì œê±° ëŒ€ìƒ

    best_for_pair: Dict[Tuple[str, str], Tuple[str, float]] = {}

    # ì „ì²´ C ìŠ¤ìº”
    for page in notion_paginate(DB_C_ID):
        pid = page["id"]
        props = page["properties"]
        a_list = get_relation_ids(props, "Hub í…Œì´ë¸”ëª…")
        b_list = get_relation_ids(props, "Hub ì»¬ëŸ¼ëª…")

        # 1) orphan
        if not a_list or not b_list:
            orphan.append(pid)
            continue

        a_pid, b_pid = a_list[0], b_list[0]

        # 2) invalid ref
        if a_pid not in valid_a or b_pid not in valid_b:
            invalid.append(pid)
            continue

        # 3) dedup
        pair = (a_pid, b_pid)
        created_ts = _parse_iso8601_to_ts(page.get("created_time", "1970-01-01T00:00:00Z"))
        if pair not in best_for_pair:
            best_for_pair[pair] = (pid, created_ts)
        else:
            keep_pid, keep_ts = best_for_pair[pair]
            if created_ts < keep_ts:
                dedup.append(keep_pid)
                best_for_pair[pair] = (pid, created_ts)
            else:
                dedup.append(pid)

    # ìµœì¢… ì•„ì¹´ì´ë¸Œ ëŒ€ìƒ
    to_archive = set(orphan) | set(invalid) | set(dedup)
    logging.info(
        f"ğŸ§¹ C pre-clean: orphan={len(orphan)}, invalid_ref={len(invalid)}, "
        f"dedup={len(dedup)}, unique_archive={len(to_archive)}"
    )

    if dry_run:
        logging.info("ğŸŸ¡ DRY-RUN: archive ì‹¤í–‰ ì•ˆ í•¨")
        return {
            "orphan": len(orphan),
            "invalid_ref": len(invalid),
            "dedup": len(dedup),
            "archived": 0
        }

    # ì‹¤ì œ ì•„ì¹´ì´ë¸Œ
    archived = 0
    for pid in to_archive:
        if archive_page(pid):
            archived += 1
        time.sleep(0.2)

    logging.info(f"âœ… C pre-clean archived: {archived}")
    return {
        "orphan": len(orphan),
        "invalid_ref": len(invalid),
        "dedup": len(dedup),
        "archived": archived
    }


# ===== C í…Œì´ë¸” UPSERT(diff) =====
def sync_db_c(df: pd.DataFrame, a_id_map: Dict[str, str], b_id_map: Dict[str, str]):
    """C í…Œì´ë¸” UPSERT"""
    # ì—­ë§¤í•‘
    a_pid_to_name = {pid: name for name, pid in a_id_map.items()}
    b_pid_to_name = {pid: name for name, pid in b_id_map.items()}

    # íƒ€ê¹ƒ ìŒ ìƒì„±
    unique_pairs = df.drop_duplicates(subset=["full_table_id", "column_name"])
    desired: Set[Tuple[str, str]] = set()
    for row in unique_pairs.itertuples():
        tid = row.full_table_id
        cname = row.column_name
        if tid in a_id_map and cname in b_id_map:
            desired.add((a_id_map[tid], b_id_map[cname]))

    # í˜„ì¬ ì¡´ì¬í•˜ëŠ” ìŒ ìˆ˜ì§‘
    existing: Set[Tuple[str, str]] = set()
    page_by_pair: Dict[Tuple[str, str], str] = {}
    for page in notion_paginate(DB_C_ID):
        pid = page["id"]
        props = page["properties"]
        a_list = get_relation_ids(props, "Hub í…Œì´ë¸”ëª…")
        b_list = get_relation_ids(props, "Hub ì»¬ëŸ¼ëª…")
        if a_list and b_list:
            pair = (a_list[0], b_list[0])
            existing.add(pair)
            page_by_pair[pair] = pid

    to_add = desired - existing
    to_remove = existing - desired
    logging.info(f"ğŸ“Š C diff â€” add:{len(to_add)} / remove:{len(to_remove)} / keep:{len(existing & desired)}")

    # ì¶”ê°€
    idx_base = len(existing & desired) + 1
    for i, (a_pid, b_pid) in enumerate(to_add, start=idx_base):
        tname = a_pid_to_name.get(a_pid, "UNKNOWN_TABLE")
        cname = b_pid_to_name.get(b_pid, "UNKNOWN_COLUMN")

        payload = {
            "parent": {"database_id": DB_C_ID},
            "properties": {
                "idx": {"title": [{"text": {"content": str(i)}}]},
                "Hub í…Œì´ë¸”ëª…": {"relation": [{"id": a_pid}]},
                "Hub ì»¬ëŸ¼ëª…": {"relation": [{"id": b_pid}]}
            }
        }
        res = request_with_retry("POST", "https://api.notion.com/v1/pages", json=payload)
        code = res.status_code if res else "ERR"
        logging.info(f"â• C add [{tname}] Ã— [{cname}] -> {code}")
        time.sleep(0.25)

    # ì œê±°(archive)
    for pair in to_remove:
        pid = page_by_pair.get(pair)
        res = request_with_retry("PATCH", f"https://api.notion.com/v1/pages/{pid}", json={"archived": True})
        code = res.status_code if res else "ERR"
        tname = a_pid_to_name.get(pair[0], "UNKNOWN_TABLE")
        cname = b_pid_to_name.get(pair[1], "UNKNOWN_COLUMN")
        logging.info(f"â– C remove [{tname}] Ã— [{cname}] -> {code}")
        time.sleep(0.2)


# ===== ì „ì²´ ë™ê¸°í™” ì—”íŠ¸ë¦¬ =====
def update_notion_databases(df: pd.DataFrame) -> bool:
    """
    BigQuery ë©”íƒ€ë°ì´í„°ë¥¼ Notionì— ë™ê¸°í™”
    
    Parameters:
    -----------
    df : pd.DataFrame
        ì»¬ëŸ¼: full_table_id, column_name, ... (ê¸°íƒ€ëŠ” ë¬´ì‹œë¨)
    
    Returns:
    --------
    bool : ì„±ê³µ ì—¬ë¶€
    
    Raises:
    -------
    ValueError : ì„¤ì • ë˜ëŠ” ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨
    """
    
    logging.info("=" * 70)
    logging.info("ğŸ§  Notion DB ì—…ë°ì´íŠ¸ ì‹œì‘")
    logging.info("=" * 70)
    
    try:
        # ğŸ“Œ Step 1: Notion ì„¤ì • ê²€ì¦
        logging.info("ğŸ“Œ Step 1: Notion ì„¤ì • ê²€ì¦")
        if not validate_notion_config():
            raise ValueError("Notion ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        # ğŸ“Œ Step 2: DataFrame ê²€ì¦
        logging.info("ğŸ“Œ Step 2: DataFrame ê²€ì¦")
        if df is None or df.empty:
            raise ValueError("DataFrameì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        required_cols = ["full_table_id", "column_name"]
        for col in required_cols:
            if col not in df.columns:
                raise ValueError(
                    f"í•„ìˆ˜ ì»¬ëŸ¼ '{col}'ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                    f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {df.columns.tolist()}"
                )
        
        logging.info(f"  âœ… DataFrame: {len(df)} rows Ã— {len(df.columns)} cols")
        logging.info(f"     ì»¬ëŸ¼: {df.columns.tolist()}")
        logging.info(f"     ìƒ˜í”Œ:\n{df[['full_table_id', 'column_name']].head(3).to_string()}")
        
        # ğŸ“Œ Step 3: A ë“±ë¡ (í…Œì´ë¸”)
        logging.info("ğŸ“Œ Step 3: DB_A (í…Œì´ë¸”) ë“±ë¡")
        table_ids = sorted(set(df["full_table_id"]))
        logging.info(f"  ë“±ë¡í•  í…Œì´ë¸”: {len(table_ids)}ê°œ")
        
        a_id_map = notion_query_id_map(DB_A_ID, "Hub í…Œì´ë¸”ëª…", label="DB_A ì´ˆê¸°")
        
        new_tables = 0
        for tid in table_ids:
            if tid not in a_id_map:
                if notion_insert(DB_A_ID, "Hub í…Œì´ë¸”ëª…", tid):
                    new_tables += 1
                time.sleep(0.15)
        
        a_id_map = notion_query_id_map(DB_A_ID, "Hub í…Œì´ë¸”ëª…", label="DB_A ì—…ë°ì´íŠ¸")
        logging.info(f"  âœ… DB_A ì™„ë£Œ: {len(a_id_map)}ê°œ (ì‹ ê·œ: {new_tables}ê°œ)")
        
        # ğŸ“Œ Step 4: B ë“±ë¡ (ì»¬ëŸ¼)
        logging.info("ğŸ“Œ Step 4: DB_B (ì»¬ëŸ¼) ë“±ë¡")
        column_names = sorted(set(df["column_name"]))
        logging.info(f"  ë“±ë¡í•  ì»¬ëŸ¼: {len(column_names)}ê°œ")
        
        b_id_map = notion_query_id_map(DB_B_ID, "Hub ì»¬ëŸ¼ëª…", label="DB_B ì´ˆê¸°")
        
        new_columns = 0
        for cname in column_names:
            if cname not in b_id_map:
                if notion_insert(DB_B_ID, "Hub ì»¬ëŸ¼ëª…", cname):
                    new_columns += 1
                time.sleep(0.15)
        
        b_id_map = notion_query_id_map(DB_B_ID, "Hub ì»¬ëŸ¼ëª…", label="DB_B ì—…ë°ì´íŠ¸")
        logging.info(f"  âœ… DB_B ì™„ë£Œ: {len(b_id_map)}ê°œ (ì‹ ê·œ: {new_columns}ê°œ)")
        
        # ğŸ“Œ Step 5: C ì‚¬ì „ ì •ë¦¬
        logging.info("ğŸ“Œ Step 5: DB_C pre-clean (ê³ ì•„/ë¬´íš¨ì°¸ì¡°/ì¤‘ë³µ ì œê±°)")
        stats = cleanup_db_c_orphans(a_id_map, b_id_map, dry_run=False)
        logging.info(f"  âœ… Pre-clean ì™„ë£Œ: {stats}")
        
        # ğŸ“Œ Step 6: C UPSERT(diff)
        logging.info("ğŸ“Œ Step 6: DB_C (í…Œì´ë¸”-ì»¬ëŸ¼ ê´€ê³„) UPSERT")
        sync_db_c(df, a_id_map, b_id_map)
        logging.info(f"  âœ… DB_C ì™„ë£Œ")
        
        logging.info("=" * 70)
        logging.info("âœ… Notion DB ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        logging.info("=" * 70)
        
        return True  # ğŸ“Œ ì„±ê³µ!
        
    except Exception as e:
        logging.error("=" * 70)
        logging.exception(f"ğŸ”¥ Notion ì ì¬ ì‹¤íŒ¨: {e}")
        logging.error("=" * 70)
        # ğŸ“Œ raiseí•˜ë©´ DAGì—ì„œ ì‹¤íŒ¨ë¡œ ê°ì§€ë¨!
        raise ValueError(f"Notion ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}") from e