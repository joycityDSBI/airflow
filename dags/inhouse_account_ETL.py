import gspread
import pandas as pd
import os
from airflow.models import Variable
from google.oauth2.service_account import Credentials
from google.oauth2 import service_account
from google.cloud import bigquery
import json
import pandas_gbq # ìµœì‹  ë°©ì‹ ê¶Œì¥
from datetime import datetime, timedelta
from airflow import DAG, Dataset
from airflow.operators.python import PythonOperator
import requests
import time

WWMC_SPREADSHEET_ID = '1D7WghN05AOW6HRNscOnjW9JJ4P2-uWlGDK8bMcoAqKk'
WWMC_SHEET_NAME = 'TEST_ACCOUNT'

DRSG_SPREADSHEET_ID = '1CRbDxfF8pdGPxcvY-1-LHwsrN4xfXu-7LoEfce6_6-U'
DRSG_SHEET_NAME = 'TEST_ACCOUNT'

POTC_SPREADSHEET_ID = '16nZ8P-cxlARLoHwtXxDCr_awpqi9mCKG1R2s9AyYKkk'
POTC_SHEET_NAME = 'TEST_ACCOUNT' ### ì‹œíŠ¸ê°€ ì ê¸ˆì´ ëœ ìƒíƒœ


PROJECT_ID = "datahub-478802"
LOCATION = "US"

################### ìœ í‹¸í•¨ìˆ˜ #####################


def get_gcp_credentials():
    """Airflow Variableì—ì„œ GCP ìê²© ì¦ëª…ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    credentials_json = Variable.get('GOOGLE_CREDENTIAL_JSON')
    cred_dict = json.loads(credentials_json)
    if 'private_key' in cred_dict:
        cred_dict['private_key'] = cred_dict['private_key'].replace('\\n', '\n')
    
    # [ìˆ˜ì •] ìŠ¤ì½”í”„(Scopes)ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì—¬ëŸ¬ ê°œ ì¶”ê°€í•©ë‹ˆë‹¤.
    SCOPES = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive',
        "https://www.googleapis.com/auth/cloud-platform",
    ]
    
    return service_account.Credentials.from_service_account_info(
        cred_dict,
        scopes=SCOPES
    )


def init_clients():
    """Task ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë˜ì–´ í•„ìš”í•œ í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    creds = get_gcp_credentials()
    
    # 1. GCP Clients
    bq_client = bigquery.Client(project=PROJECT_ID, credentials=creds)
    
    return {
        "bq_client": bq_client
    }



#################### WWMC ì¸í•˜ìš°ìŠ¤ ê³„ì • ETL í•¨ìˆ˜ #####################
def WWMC_from_spreadsheet_df(spreadsheet_id, sheet_name):

    creds = get_gcp_credentials()
    client = gspread.authorize(creds)

    doc = client.open_by_key(spreadsheet_id)
    sheet = doc.worksheet(sheet_name)
    all_data = sheet.get('A:D')

    if not all_data:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    header = all_data[1]
    data = all_data[2:]

    if len(header) == 1:
        header = [f'col_{i}' for i in range(len(data[0]))]

    df = pd.DataFrame(data, columns=header)

    df = df.rename(columns={
        "build":"build",
        "userkey":"userkey",
        "charid":"charid",
        "class":"type"
        })

    selected_df = df[["build",
                      "userkey",
                      "charid",
                      "type"
                      ]]
    
    return selected_df


def WWMC_merge_to_bigquery(project_id, dataset_id, table_id):

    df = WWMC_from_spreadsheet_df(WWMC_SPREADSHEET_ID, WWMC_SHEET_NAME)
    credentials = get_gcp_credentials()
    client = bigquery.Client(project=project_id, credentials=credentials)
    table_full_id = f"{project_id}.{dataset_id}.{table_id}"

    # 1. ë°ì´í„° ë¹„ìš°ê¸° (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ/ì„¤ì • ìœ ì§€)
    truncate_query = f"TRUNCATE TABLE `{table_full_id}`"
    client.query(truncate_query, location=LOCATION).result()
    print(f"ğŸ—‘ï¸ {table_full_id} ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° íƒ€ì… í´ë¦¬ë‹ (Parquet ë³€í™˜ ì—ëŸ¬ ë°©ì§€)
    df_final = df.astype(str)
    
    # 3. ë°ì´í„° ì‚½ì…
    try:
        # TRUNCATEë¥¼ ë¯¸ë¦¬ í–ˆìœ¼ë¯€ë¡œ 'append'ë¥¼ ì¨ì•¼ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ/íŒŒí‹°ì…˜ ì„¤ì •ì´ ìœ ì§€ë©ë‹ˆë‹¤.
        # df.to_gbq ëŒ€ì‹  pandas_gbq.to_gbq ì‚¬ìš© ê¶Œì¥
        pandas_gbq.to_gbq(
            df_final,
            destination_table=f"{dataset_id}.{table_id}",
            project_id=project_id,
            if_exists='append', 
            progress_bar=True,
            credentials=credentials
        )
        print(f"âœ… {len(df_final)}í–‰ ë°ì´í„°ê°€ {table_full_id}ì— ì„±ê³µì ìœ¼ë¡œ Insert ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ BigQuery ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise e # ì—ëŸ¬ ì¶”ì ì„ ìœ„í•´ raise ì¶”ê°€
    

#################### DS ì¸í•˜ìš°ìŠ¤ ê³„ì • ETL í•¨ìˆ˜ #####################
def DRSG_from_spreadsheet_df(spreadsheet_id, sheet_name):

    creds = get_gcp_credentials()
    client = gspread.authorize(creds)

    doc = client.open_by_key(spreadsheet_id)
    sheet = doc.worksheet(sheet_name)
    all_data = sheet.get('A:E')

    if not all_data:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    header = all_data[0]
    data = all_data[1:]

    if len(header) == 1:
        header = [f'col_{i}' for i in range(len(data[0]))]

    df = pd.DataFrame(data, columns=header)

    df = df.rename(columns={
        "build":"ë¹Œë“œ",
        "worldid":"ì„œë²„ëª…",
        "charid":"ê³„ì •ë²ˆí˜¸",
        "class":"êµ¬ë¶„",
        "userkey":"íšŒì›ë²ˆí˜¸"
        })

    selected_df = df[["build",
                      "userkey",
                      "charid",
                      "class",
                      "worldid"
                      ]]
    
    return selected_df


def DRSG_merge_to_bigquery(project_id, dataset_id, table_id):

    df = DRSG_from_spreadsheet_df(DRSG_SPREADSHEET_ID, DRSG_SHEET_NAME)
    credentials = get_gcp_credentials()
    client = bigquery.Client(project=project_id, credentials=credentials)
    table_full_id = f"{project_id}.{dataset_id}.{table_id}"

    # 1. ë°ì´í„° ë¹„ìš°ê¸° (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ/ì„¤ì • ìœ ì§€)
    truncate_query = f"TRUNCATE TABLE `{table_full_id}`"
    client.query(truncate_query, location=LOCATION).result()
    print(f"ğŸ—‘ï¸ {table_full_id} ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° íƒ€ì… í´ë¦¬ë‹ (Parquet ë³€í™˜ ì—ëŸ¬ ë°©ì§€)
    df_final = df.astype(str)
    
    # 3. ë°ì´í„° ì‚½ì…
    try:
        # TRUNCATEë¥¼ ë¯¸ë¦¬ í–ˆìœ¼ë¯€ë¡œ 'append'ë¥¼ ì¨ì•¼ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ/íŒŒí‹°ì…˜ ì„¤ì •ì´ ìœ ì§€ë©ë‹ˆë‹¤.
        # df.to_gbq ëŒ€ì‹  pandas_gbq.to_gbq ì‚¬ìš© ê¶Œì¥
        pandas_gbq.to_gbq(
            df_final,
            destination_table=f"{dataset_id}.{table_id}",
            project_id=project_id,
            if_exists='append', 
            progress_bar=True,
            credentials=credentials
        )
        print(f"âœ… {len(df_final)}í–‰ ë°ì´í„°ê°€ {table_full_id}ì— ì„±ê³µì ìœ¼ë¡œ Insert ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ BigQuery ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise e # ì—ëŸ¬ ì¶”ì ì„ ìœ„í•´ raise ì¶”ê°€


#################### POTC ì¸í•˜ìš°ìŠ¤ ê³„ì • ETL í•¨ìˆ˜ #####################
def POTC_from_spreadsheet_df(spreadsheet_id, sheet_name):

    creds = get_gcp_credentials()
    client = gspread.authorize(creds)

    doc = client.open_by_key(spreadsheet_id)
    sheet = doc.worksheet(sheet_name)
    all_data = sheet.get('A:E')

    if not all_data:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    header = all_data[0]
    data = all_data[1:]

    if len(header) == 1:
        header = [f'col_{i}' for i in range(len(data[0]))]

    df = pd.DataFrame(data, columns=header)

    df = df.rename(columns={
        "build":"ë¹Œë“œ",
        "worldid":"ì„œë²„ëª…",
        "charid":"ê³„ì •ë²ˆí˜¸",
        "class":"êµ¬ë¶„",
        "userkey":"íšŒì›ë²ˆí˜¸"
        })

    selected_df = df[["build",
                      "userkey",
                      "charid",
                      "class",
                      "worldid"
                      ]]
    
    return selected_df


def POTC_merge_to_bigquery(project_id, dataset_id, table_id):

    df = DRSG_from_spreadsheet_df(POTC_SPREADSHEET_ID, POTC_SHEET_NAME)
    credentials = get_gcp_credentials()
    client = bigquery.Client(project=project_id, credentials=credentials)
    table_full_id = f"{project_id}.{dataset_id}.{table_id}"

    # 1. ë°ì´í„° ë¹„ìš°ê¸° (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ/ì„¤ì • ìœ ì§€)
    truncate_query = f"TRUNCATE TABLE `{table_full_id}`"
    client.query(truncate_query, location=LOCATION).result()
    print(f"ğŸ—‘ï¸ {table_full_id} ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° íƒ€ì… í´ë¦¬ë‹ (Parquet ë³€í™˜ ì—ëŸ¬ ë°©ì§€)
    df_final = df.astype(str)
    
    # 3. ë°ì´í„° ì‚½ì…
    try:
        # TRUNCATEë¥¼ ë¯¸ë¦¬ í–ˆìœ¼ë¯€ë¡œ 'append'ë¥¼ ì¨ì•¼ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ/íŒŒí‹°ì…˜ ì„¤ì •ì´ ìœ ì§€ë©ë‹ˆë‹¤.
        # df.to_gbq ëŒ€ì‹  pandas_gbq.to_gbq ì‚¬ìš© ê¶Œì¥
        pandas_gbq.to_gbq(
            df_final,
            destination_table=f"{dataset_id}.{table_id}",
            project_id=project_id,
            if_exists='append', 
            progress_bar=True,
            credentials=credentials
        )
        print(f"âœ… {len(df_final)}í–‰ ë°ì´í„°ê°€ {table_full_id}ì— ì„±ê³µì ìœ¼ë¡œ Insert ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ BigQuery ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise e # ì—ëŸ¬ ì¶”ì ì„ ìœ„í•´ raise ì¶”ê°€






# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(seconds=15),
}

with DAG(
    dag_id='inhouse_account_ETL',
    default_args=default_args,
    description='Inhouse Account ETL',
    schedule='30 19 * * *',  # ë§¤ì¼ ì˜¤ì „ 04ì‹œ 50ë¶„ ì‹¤í–‰
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['ETL', 'inhouse_account', 'bigquery'],
) as dag:

    WWMC_inhouse_account_task = PythonOperator(
        task_id='WWMC_inhouse_account_task',
        python_callable=WWMC_merge_to_bigquery,
        op_kwargs={
            "project_id": "data-science-division-216308",
            "dataset_id": "Account_Info",
            "table_id": "WWM_account_info"
        },
        dag=dag,
    )

    WWMC_inhouse_account_task