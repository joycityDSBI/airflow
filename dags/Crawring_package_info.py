import gspread
import pandas as pd
import os
from airflow.models import Variable
from google.oauth2.service_account import Credentials
from google.oauth2 import service_account
from google.cloud import bigquery
import json
import pandas_gbq # ìµœì‹  ë°©ì‹ ê¶Œì¥
from datetime import datetime, timedelta
from airflow import DAG, Dataset
from airflow.operators.python import PythonOperator
import requests
import time

def get_var(key: str, default: str = None) -> str:
    """í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Airflow Variable ì¡°íšŒ"""
    return os.environ.get(key) or Variable.get(key, default_var=default)

# ì‹œíŠ¸ì •ë³´
GBTW_SPREADSHEET_ID = '1mnsTzSupPOBhtk-rZSnxk4oALPqTDGd3vkGfS7gt8z0'
GBTW_SHEET_NAME = 'ìƒí’ˆìš”ì•½(ì‹ )'

POTC_SPREADSHEET_ID = '121hBk4DKpD2Wfzd59hCPUtVu7zqibmiKhxAr8UkZWJQ'
POTC_SHEET_NAME = 'ë©”íƒ€ë°ì´í„°'

DRSG_SPREADSHEET_ID = '1CRbDxfF8pdGPxcvY-1-LHwsrN4xfXu-7LoEfce6_6-U'
DRSG_SHEET_NAME = 'ë©”íƒ€ë°ì´í„°'

WWMC_SPREADSHEET_ID = '1D7WghN05AOW6HRNscOnjW9JJ4P2-uWlGDK8bMcoAqKk'
WWMC_SHEET_NAME = 'PACKAGE_HISTORY'

NOTION_TOKEN = get_var("NOTION_TOKEN")
NOTION_DATABASE_ID = "23bea67a5681803db3c4f691c143a43d"


PROJECT_ID = "datahub-478802"
LOCATION = "US"

################### ìœ í‹¸í•¨ìˆ˜ #####################


def get_gcp_credentials():
    """Airflow Variableì—ì„œ GCP ìê²© ì¦ëª…ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    credentials_json = Variable.get('GOOGLE_CREDENTIAL_JSON')
    cred_dict = json.loads(credentials_json)
    if 'private_key' in cred_dict:
        cred_dict['private_key'] = cred_dict['private_key'].replace('\\n', '\n')
    
    # [ìˆ˜ì •] ìŠ¤ì½”í”„(Scopes)ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì—¬ëŸ¬ ê°œ ì¶”ê°€í•©ë‹ˆë‹¤.
    SCOPES = [
        'https://www.googleapis.com/auth/spreadsheets',
        'https://www.googleapis.com/auth/drive',
        "https://www.googleapis.com/auth/cloud-platform",
    ]
    
    return service_account.Credentials.from_service_account_info(
        cred_dict,
        scopes=SCOPES
    )


def init_clients():
    """Task ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë˜ì–´ í•„ìš”í•œ í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    creds = get_gcp_credentials()
    
    # 1. GCP Clients
    bq_client = bigquery.Client(project=PROJECT_ID, credentials=creds)
    
    return {
        "bq_client": bq_client
    }


#################### GBTW íŒ¨í‚¤ì§€ ì •ë³´ ETL í•¨ìˆ˜ #####################
def GBTW_get_gsheet_to_df(spreadsheet_id, sheet_name):
    # 1. ì¸ì¦ ì„¤ì • (ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ê²½ë¡œ)

    creds = get_gcp_credentials()
    client = gspread.authorize(creds)

    # 2. ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë° ì‹œíŠ¸ ì˜¤í”ˆ
    doc = client.open_by_key(spreadsheet_id)
    sheet = doc.worksheet(sheet_name)

    # 3. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (A~K ì—´ì˜ ì „ì²´ ë°ì´í„°)
    # get_all_values()ëŠ” ì „ì²´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ë§Œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì´ë¯€ë¡œ ìŠ¬ë¼ì´ì‹±ì´ í•„ìš”í•©ë‹ˆë‹¤.
    all_data = sheet.get('A:Z')

    if not all_data:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    # ì—ëŸ¬ ë°©ì§€ ë¡œì§: í—¤ë”ì™€ ë°ì´í„° ë¶„ë¦¬
    header = all_data[0]
    data = all_data[1:]

    # ë§Œì•½ ì²« ë²ˆì§¸ í–‰(í—¤ë”)ì˜ ê¸¸ì´ê°€ ë°ì´í„° ì—´ ê°œìˆ˜ì™€ ë§ì§€ ì•ŠëŠ” ê²½ìš° ì²˜ë¦¬
    if len(header) == 1:
        # í—¤ë”ê°€ 1ê°œì¸ë° ë°ì´í„°ê°€ 11ê°œë¼ë©´, í—¤ë” ë¦¬ìŠ¤íŠ¸ê°€ ì œëŒ€ë¡œ ì•ˆ ë§Œë“¤ì–´ì§„ ê²ƒì„
        # ì„ì˜ì˜ ì»¬ëŸ¼ëª…ì„ ë¶€ì—¬í•˜ê±°ë‚˜ ë°ì´í„°ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì•¼ í•¨
        header = [f'col_{i}' for i in range(len(data[0]))]

    df = pd.DataFrame(data, columns=header)

    df = df.rename(columns={
        "ì¬í™”êµ¬ë¶„":"goods_type",
        "ìƒì  ì¹´í…Œê³ ë¦¬":"category_shop",
        "ìƒí’ˆ ì¹´í…Œê³ ë¦¬":"category_package",
        "íŒ¨í‚¤ì§€ëª…":"package_name",
        "PackageKind":"package_kind",
        "ê°€ê²©":"price",
        "ê°€ê²©(êµ¬ê¸€)":"price_aos",
        "ê°€ê²©(ì• í”Œ_êµ­ë‚´)":"price_ios",
        "ê°€ê²©(ì›ìŠ¤í† ì–´)":"price_one",
        "IAPì½”ë“œ(êµ¬ê¸€)":"iap_code_google",
        "IAPì½”ë“œ(ì• í”Œ)":"iap_code_apple",
        "IAPì½”ë“œ(ì›ìŠ¤í† ì–´)":"iap_code_one",
        "ìƒí’ˆë°˜ì˜ì¼":"sale_date_start",
        "íŒë§¤ì¢…ë£Œì¼":"sale_date_end"
        })

    selected_df = df[["goods_type",
        "category_shop",
        "category_package",
        "package_name",
        "package_kind",
        "price",
        "price_aos",
        "price_ios",
        "price_one",
        "iap_code_google",
        "iap_code_apple",
        "iap_code_one",
        "sale_date_start",
        "sale_date_end"]]
    
    return selected_df


def GBTW_truncate_and_insert_to_bigquery(project_id, dataset_id, table_id):

    df = GBTW_get_gsheet_to_df(GBTW_SPREADSHEET_ID, GBTW_SHEET_NAME)
    
    credentials = get_gcp_credentials()
    client = bigquery.Client(project=project_id, credentials=credentials)
    table_full_id = f"{project_id}.{dataset_id}.{table_id}"

    # 1. ë°ì´í„° ë¹„ìš°ê¸° (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ/ì„¤ì • ìœ ì§€)
    truncate_query = f"TRUNCATE TABLE `{table_full_id}`"
    client.query(truncate_query, location=LOCATION).result()
    print(f"ğŸ—‘ï¸ {table_full_id} ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° íƒ€ì… í´ë¦¬ë‹ (Parquet ë³€í™˜ ì—ëŸ¬ ë°©ì§€)
    df_final = df.astype(str)
    numeric_columns = ['package_kind'] # ì‹¤ì œ ìˆ«ìí˜• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì •í•˜ì„¸ìš”
    for col in numeric_columns:
        if col in df_final.columns:
            # ìˆ«ìë¡œ ë³€í™˜í•˜ë˜, ë³€í™˜ ì•ˆë˜ëŠ” ê°’(ë¹ˆì¹¸ ë“±)ì€ NaNìœ¼ë¡œ ì²˜ë¦¬ í›„ 0ìœ¼ë¡œ ì±„ì›€
            df_final[col] = pd.to_numeric(df_final[col], errors='coerce').fillna(0).astype(int)
    
    df_final = df_final.replace(['None', 'nan', 'NaN', '<NA>'], '')
    df_final['price_ios_china'] = None

    to_int_list = ['price', 'price_aos', 'price_ios', 'price_one']
    for cl in to_int_list:
        df_final[cl] = df_final[cl].str.replace(r'[â‚©,]', '', regex=True)
        df_final[cl] = pd.to_numeric(df_final[cl], errors='coerce')
        df_final[cl] = df_final[cl].fillna(0).astype(str)
    
    # 3. ë°ì´í„° ì‚½ì…
    try:
        # TRUNCATEë¥¼ ë¯¸ë¦¬ í–ˆìœ¼ë¯€ë¡œ 'append'ë¥¼ ì¨ì•¼ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ/íŒŒí‹°ì…˜ ì„¤ì •ì´ ìœ ì§€ë©ë‹ˆë‹¤.
        # df.to_gbq ëŒ€ì‹  pandas_gbq.to_gbq ì‚¬ìš© ê¶Œì¥
        pandas_gbq.to_gbq(
            df_final,
            destination_table=f"{dataset_id}.{table_id}",
            project_id=project_id,
            if_exists='append', 
            progress_bar=True,
            credentials=credentials
        )
        print(f"âœ… {len(df_final)}í–‰ ë°ì´í„°ê°€ {table_full_id}ì— ì„±ê³µì ìœ¼ë¡œ Insert ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ BigQuery ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise e # ì—ëŸ¬ ì¶”ì ì„ ìœ„í•´ raise ì¶”ê°€


#################### POTC íŒ¨í‚¤ì§€ ì •ë³´ ETL í•¨ìˆ˜ #####################
def POTC_get_gsheet_to_df(spreadsheet_id, sheet_name):

    creds = get_gcp_credentials()
    client = gspread.authorize(creds)

    doc = client.open_by_key(spreadsheet_id)
    sheet = doc.worksheet(sheet_name)
    all_data = sheet.get('A:K')

    if not all_data:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    header = all_data[1]
    data = all_data[2:]

    if len(header) == 1:
        header = [f'col_{i}' for i in range(len(data[0]))]

    df = pd.DataFrame(data, columns=header)

    df = df.rename(columns={
        "ì¬í™”êµ¬ë¶„":"goods_type",
        "ìƒì  ì¹´í…Œê³ ë¦¬":"category_shop",
        "ìƒí’ˆ ì¹´í…Œê³ ë¦¬":"category_package",
        "íŒ¨í‚¤ì§€ëª…":"package_name",
        "PackageKind":"package_kind",
        "ê°€ê²©":"price",
        "IAPì½”ë“œ(êµ¬ê¸€)":"iap_code_google",
        "IAPì½”ë“œ(ì• í”Œ)":"iap_code_apple",
        "IAPì½”ë“œ(ì›ìŠ¤í† ì–´)":"iap_code_one",
        "ìƒí’ˆë°˜ì˜ì¼":"sale_date_start",
        "íŒë§¤ì¢…ë£Œì¼":"sale_date_end"
        })

    selected_df = df[["goods_type",
        "category_shop",
        "category_package",
        "package_name",
        "package_kind",
        "price",
        "iap_code_google",
        "iap_code_apple",
        "iap_code_one",
        "sale_date_start",
        "sale_date_end"]]
    
    return selected_df

def POTC_truncate_and_insert_to_bigquery(project_id, dataset_id, table_id):

    df = POTC_get_gsheet_to_df(POTC_SPREADSHEET_ID, POTC_SHEET_NAME)
    credentials = get_gcp_credentials()
    client = bigquery.Client(project=project_id, credentials=credentials)
    table_full_id = f"{project_id}.{dataset_id}.{table_id}"

    # 1. ë°ì´í„° ë¹„ìš°ê¸° (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ/ì„¤ì • ìœ ì§€)
    truncate_query = f"TRUNCATE TABLE `{table_full_id}`"
    client.query(truncate_query, location=LOCATION).result()
    print(f"ğŸ—‘ï¸ {table_full_id} ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° íƒ€ì… í´ë¦¬ë‹ (Parquet ë³€í™˜ ì—ëŸ¬ ë°©ì§€)
    df_final = df.astype(str)
    numeric_columns = ['package_kind'] # ì‹¤ì œ ìˆ«ìí˜• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì •í•˜ì„¸ìš”
    for col in numeric_columns:
        if col in df_final.columns:
            # ìˆ«ìë¡œ ë³€í™˜í•˜ë˜, ë³€í™˜ ì•ˆë˜ëŠ” ê°’(ë¹ˆì¹¸ ë“±)ì€ NaNìœ¼ë¡œ ì²˜ë¦¬ í›„ 0ìœ¼ë¡œ ì±„ì›€
            df_final[col] = pd.to_numeric(df_final[col], errors='coerce').fillna(0).astype(int)

    to_int_list = ['price']
    for cl in to_int_list:
        df_final[cl] = df_final[cl].str.replace(r'[â‚©,]', '', regex=True)
        df_final[cl] = pd.to_numeric(df_final[cl], errors='coerce')
        df_final[cl] = df_final[cl].fillna(0).astype(str)
    
    # 3. ë°ì´í„° ì‚½ì…
    try:
        # TRUNCATEë¥¼ ë¯¸ë¦¬ í–ˆìœ¼ë¯€ë¡œ 'append'ë¥¼ ì¨ì•¼ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ/íŒŒí‹°ì…˜ ì„¤ì •ì´ ìœ ì§€ë©ë‹ˆë‹¤.
        # df.to_gbq ëŒ€ì‹  pandas_gbq.to_gbq ì‚¬ìš© ê¶Œì¥
        pandas_gbq.to_gbq(
            df_final,
            destination_table=f"{dataset_id}.{table_id}",
            project_id=project_id,
            if_exists='append', 
            progress_bar=True,
            credentials=credentials
        )
        print(f"âœ… {len(df_final)}í–‰ ë°ì´í„°ê°€ {table_full_id}ì— ì„±ê³µì ìœ¼ë¡œ Insert ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ BigQuery ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise e # ì—ëŸ¬ ì¶”ì ì„ ìœ„í•´ raise ì¶”ê°€


#################### DRSG íŒ¨í‚¤ì§€ ì •ë³´ ETL í•¨ìˆ˜ #####################
def DRSG_get_gsheet_to_df(spreadsheet_id, sheet_name):

    creds = get_gcp_credentials()
    client = gspread.authorize(creds)

    doc = client.open_by_key(spreadsheet_id)
    sheet = doc.worksheet(sheet_name)
    all_data = sheet.get('A:K')

    if not all_data:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    header = all_data[1]
    data = all_data[2:]

    if len(header) == 1:
        header = [f'col_{i}' for i in range(len(data[0]))]

    df = pd.DataFrame(data, columns=header)

    df = df.rename(columns={
        "PackageKind":"package_kind",
        "íŒ¨í‚¤ì§€ëª…":"package_name",
        "ìƒì  ì¹´í…Œê³ ë¦¬":"category_shop",
        "IAPì½”ë“œ(êµ¬ê¸€)":"iap_code_google",
        "IAPì½”ë“œ(ì• í”Œ)":"iap_code_apple",
        "ìƒí’ˆ ì¹´í…Œê³ ë¦¬":"category_package",
        "ì¬í™”êµ¬ë¶„":"goods_type",
        "ê°€ê²©":"price",
        "ìƒí’ˆë°˜ì˜ì¼":"sale_date_start",
        "íŒë§¤ì¢…ë£Œì¼":"sale_date_end",
        "IAPì½”ë“œ(ì›ìŠ¤í† ì–´)":"iap_code_one"
        })

    selected_df = df[["goods_type",
        "category_shop",
        "category_package",
        "package_name",
        "package_kind",
        "price",
        "iap_code_google",
        "iap_code_apple",
        "sale_date_start",
        "sale_date_end"]]
    
    return selected_df

def DRSG_truncate_and_insert_to_bigquery(project_id, dataset_id, table_id):

    df = DRSG_get_gsheet_to_df(DRSG_SPREADSHEET_ID, DRSG_SHEET_NAME)
    credentials = get_gcp_credentials()
    client = bigquery.Client(project=project_id, credentials=credentials)
    table_full_id = f"{project_id}.{dataset_id}.{table_id}"

    # 1. ë°ì´í„° ë¹„ìš°ê¸° (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ/ì„¤ì • ìœ ì§€)
    truncate_query = f"TRUNCATE TABLE `{table_full_id}`"
    client.query(truncate_query, location=LOCATION).result()
    print(f"ğŸ—‘ï¸ {table_full_id} ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° íƒ€ì… í´ë¦¬ë‹ (Parquet ë³€í™˜ ì—ëŸ¬ ë°©ì§€)
    df_final = df.astype(str)
    numeric_columns = ['package_kind'] # ì‹¤ì œ ìˆ«ìí˜• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì •í•˜ì„¸ìš”
    for col in numeric_columns:
        if col in df_final.columns:
            # ìˆ«ìë¡œ ë³€í™˜í•˜ë˜, ë³€í™˜ ì•ˆë˜ëŠ” ê°’(ë¹ˆì¹¸ ë“±)ì€ NaNìœ¼ë¡œ ì²˜ë¦¬ í›„ 0ìœ¼ë¡œ ì±„ì›€
            df_final[col] = pd.to_numeric(df_final[col], errors='coerce').fillna(0).astype(int)

    to_int_list = ['price']
    for cl in to_int_list:
        df_final[cl] = df_final[cl].str.replace(r'[â‚©,]', '', regex=True)
        df_final[cl] = pd.to_numeric(df_final[cl], errors='coerce')
        df_final[cl] = df_final[cl].fillna(0).astype(str)
    
    # 3. ë°ì´í„° ì‚½ì…
    try:
        # TRUNCATEë¥¼ ë¯¸ë¦¬ í–ˆìœ¼ë¯€ë¡œ 'append'ë¥¼ ì¨ì•¼ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ/íŒŒí‹°ì…˜ ì„¤ì •ì´ ìœ ì§€ë©ë‹ˆë‹¤.
        # df.to_gbq ëŒ€ì‹  pandas_gbq.to_gbq ì‚¬ìš© ê¶Œì¥
        pandas_gbq.to_gbq(
            df_final,
            destination_table=f"{dataset_id}.{table_id}",
            project_id=project_id,
            if_exists='append', 
            progress_bar=True,
            credentials=credentials
        )
        print(f"âœ… {len(df_final)}í–‰ ë°ì´í„°ê°€ {table_full_id}ì— ì„±ê³µì ìœ¼ë¡œ Insert ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ BigQuery ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise e # ì—ëŸ¬ ì¶”ì ì„ ìœ„í•´ raise ì¶”ê°€


#################### WWMC íŒ¨í‚¤ì§€ ì •ë³´ ETL í•¨ìˆ˜ #####################
def WWMC_get_gsheet_to_df(spreadsheet_id, sheet_name):

    creds = get_gcp_credentials()
    client = gspread.authorize(creds)

    doc = client.open_by_key(spreadsheet_id)
    sheet = doc.worksheet(sheet_name)
    all_data = sheet.get('A:O')

    if not all_data:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    header = all_data[0]
    data = all_data[1:]

    if len(header) == 1:
        header = [f'col_{i}' for i in range(len(data[0]))]

    df = pd.DataFrame(data, columns=header)

    df = df.rename(columns={
        "Pkind":"package_kind",
        "PACKAGE_NAME":"package_name",
        "CATEGORY":"category_shop",
        "PRODUCTCODE_aos":"iap_code_google",
        "PRODUCTCODE_ios":"iap_code_apple",
        "GROUP":"category_package",
        "PRODUCTCODE_onestore":"iap_code_one",
        "ì¬í™”êµ¬ë¶„":"goods_type",
        "ê°€ê²©":"price",
        "ì• í”Œ ë“±ê¸‰":"grade_apple",
        "ìƒí’ˆ ë°˜ì˜ì¼":"sale_date_start",
        "íŒë§¤ ì¢…ë£Œì¼":"sale_date_end",
        })

    selected_df = df[["goods_type",
        "category_shop",
        "category_package",
        "package_name",
        "package_kind",
        "price",
        "iap_code_google",
        "iap_code_apple",
        "iap_code_one",
        "sale_date_start",
        "sale_date_end"]]
    
    return selected_df

def WWMC_truncate_and_insert_to_bigquery(project_id, dataset_id, table_id):

    df = WWMC_get_gsheet_to_df(WWMC_SPREADSHEET_ID, WWMC_SHEET_NAME)
    credentials = get_gcp_credentials()
    client = bigquery.Client(project=project_id, credentials=credentials)
    table_full_id = f"{project_id}.{dataset_id}.{table_id}"

    # 1. ë°ì´í„° ë¹„ìš°ê¸° (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ/ì„¤ì • ìœ ì§€)
    truncate_query = f"TRUNCATE TABLE `{table_full_id}`"
    client.query(truncate_query, location=LOCATION).result()
    print(f"ğŸ—‘ï¸ {table_full_id} ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° íƒ€ì… í´ë¦¬ë‹ (Parquet ë³€í™˜ ì—ëŸ¬ ë°©ì§€)
    df_final = df.astype(str)
    numeric_columns = ['package_kind'] # ì‹¤ì œ ìˆ«ìí˜• ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì •í•˜ì„¸ìš”
    for col in numeric_columns:
        if col in df_final.columns:
            # ìˆ«ìë¡œ ë³€í™˜í•˜ë˜, ë³€í™˜ ì•ˆë˜ëŠ” ê°’(ë¹ˆì¹¸ ë“±)ì€ NaNìœ¼ë¡œ ì²˜ë¦¬ í›„ 0ìœ¼ë¡œ ì±„ì›€
            df_final[col] = pd.to_numeric(df_final[col], errors='coerce').fillna(0).astype(int)

    to_int_list = ['price']
    for cl in to_int_list:
        df_final[cl] = df_final[cl].str.replace(r'[â‚©,]', '', regex=True)
        df_final[cl] = pd.to_numeric(df_final[cl], errors='coerce')
        df_final[cl] = df_final[cl].fillna(0).astype(str)
    
    # 3. ë°ì´í„° ì‚½ì…
    try:
        # TRUNCATEë¥¼ ë¯¸ë¦¬ í–ˆìœ¼ë¯€ë¡œ 'append'ë¥¼ ì¨ì•¼ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ/íŒŒí‹°ì…˜ ì„¤ì •ì´ ìœ ì§€ë©ë‹ˆë‹¤.
        # df.to_gbq ëŒ€ì‹  pandas_gbq.to_gbq ì‚¬ìš© ê¶Œì¥
        pandas_gbq.to_gbq(
            df_final,
            destination_table=f"{dataset_id}.{table_id}",
            project_id=project_id,
            if_exists='append', 
            progress_bar=True,
            credentials=credentials
        )
        print(f"âœ… {len(df_final)}í–‰ ë°ì´í„°ê°€ {table_full_id}ì— ì„±ê³µì ìœ¼ë¡œ Insert ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ BigQuery ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise e # ì—ëŸ¬ ì¶”ì ì„ ìœ„í•´ raise ì¶”ê°€


#################### RESU íŒ¨í‚¤ì§€ ì •ë³´ ETL í•¨ìˆ˜ (NOTION DB) #####################
def RESU_extract_notion_data(NOTION_TOKEN, NOTION_DATABASE_ID):
    """Notion ë°ì´í„° ì¶”ì¶œ"""
    url = f"https://api.notion.com/v1/databases/{NOTION_DATABASE_ID}/query"
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Notion-Version": get_var("NOTION_API_VERSION", "2022-06-28"),
        "Content-Type": "application/json"
    }
    
    results = []
    has_more = True
    next_cursor = None

    while has_more:
        payload = {"page_size": 100}
        if next_cursor:
            payload["start_cursor"] = next_cursor

        # 2. API í˜¸ì¶œ
        response = requests.post(url, headers=headers, json=payload)
        
        # ì—ëŸ¬ ë°œìƒ ì‹œ ë©ˆì¶”ì§€ ì•Šê³  í™•ì¸í•˜ë ¤ë©´ try-except ë¸”ë¡ ê³ ë ¤ (ì—¬ê¸°ì„  ë‹¨ìˆœ ì²˜ë¦¬)
        if response.status_code != 200:
            print(f"Error: {response.status_code}, {response.text}")
            break

        data = response.json()

        # 3. ë°ì´í„° ì €ì¥
        # ì´ë²ˆ ìš”ì²­ìœ¼ë¡œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ ì „ì²´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        results.extend(data["results"])

        # 4. ë‹¤ìŒ ë£¨í”„ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
        has_more = data["has_more"]        # ë” ê°€ì ¸ì˜¬ ë°ì´í„°ê°€ ë‚¨ì•˜ëŠ”ì§€ (True/False)
        next_cursor = data["next_cursor"]  # ë‹¤ìŒ ë°ì´í„°ì˜ ì‹œì‘ ìœ„ì¹˜

        print(f"í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ë°ì´í„°: {len(results)}ê°œ")
        
        # (ì„ íƒì‚¬í•­) API í˜¸ì¶œ ì œí•œ(Rate Limit) ë°©ì§€ë¥¼ ìœ„í•´ ì•„ì£¼ ì§§ì€ ëŒ€ê¸°
        time.sleep(0.1) 

    print(f"âœ… ì´ {len(results)}ê°œì˜ ë°ì´í„°ë¥¼ ëª¨ë‘ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

    # 2. ê°’ ì¶”ì¶œ í•¨ìˆ˜ (ë°ì´í„°ê°€ ì—†ê±°ë‚˜ Noneì¼ ê²½ìš° ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
    def get_text_value(props, prop_key):
        """rich_text ë˜ëŠ” title íƒ€ì…ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        prop = props.get(prop_key, {})
        # rich_text ë˜ëŠ” title í‚¤ í™•ì¸
        content_list = prop.get('rich_text', []) or prop.get('title', [])
        if content_list:
            return content_list[0].get('plain_text', '')
        return ''

    def get_select_name(props, prop_key):
        """select ë˜ëŠ” status íƒ€ì…ì—ì„œ ì´ë¦„ ì¶”ì¶œ"""
        prop = props.get(prop_key, {})
        # select ë˜ëŠ” status í‚¤ í™•ì¸
        select_obj = prop.get('select') or prop.get('status')
        if select_obj:
            return select_obj.get('name', '')
        return ''

    def get_date_start(props, prop_key):
        """date íƒ€ì…ì—ì„œ ì‹œì‘ì¼ ì¶”ì¶œ"""
        prop = props.get(prop_key, {})
        date_obj = prop.get('date')
        if date_obj:
            return date_obj.get('start', '')
        return ''

    def get_number(props, prop_key):
        """number íƒ€ì…ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        prop = props.get(prop_key, {})
        return prop.get('number', 0)
    
    list_data = []

    for ps in range(0, len(results)):
        props = results[ps].get('properties', {})
            
        # 3. ë°ì´í„° ì¶”ì¶œ ì‹¤í–‰
        result = {
            "Package_Name": get_text_value(props, 'ìƒí’ˆëª…'),
            "Package_Name_ENG": get_text_value(props, 'ìƒí’ˆëª…_ì˜ë¬¸'),
            "ShopBaseKind": get_text_value(props, 'ShopBaseKind'),
            "Package_Kind": get_text_value(props, 'ìƒí’ˆì¹´ì¸ë“œ'),
            "Goods_Type": get_select_name(props, 'ì¬í™”êµ¬ë¶„'),
            "IAP_CODE_GOOGLE": get_text_value(props, 'IAP_CODE_GOOGLE'),
            "IAP_CODE_APPLE": get_text_value(props, 'IAP_CODE_APPLE'),
            "IAP_CODE_ONESTORE": get_text_value(props, 'IAP_CODE_ONESTORE'),
            "Cat_Shop": get_select_name(props, 'ìƒì  ì¹´í…Œê³ ë¦¬'),
            "Cat_Package": get_select_name(props, 'ìƒí’ˆ ì¹´í…Œê³ ë¦¬'),
            "Price": get_number(props, 'ê°€ê²© (ï¿¦)'),
            "Start_Date": get_date_start(props, 'íŒë§¤ ì‹œì‘ì¼'),
            "End_Date": get_date_start(props, 'íŒë§¤ ì¢…ë£Œì¼'),
            "Task_State": get_select_name(props, 'ìƒíƒœ'),
            }
        list_data.append(result)

    df = pd.DataFrame(list_data)
    print(df[["ShopBaseKind", "Package_Kind"]].head(5))

    # ì»¬ëŸ¼ ê°€ê³µ ì „ ë¹ˆ ê°’ ì²˜ë¦¬ (ì•ˆì „ì„± ê°•í™”)
    df["ShopBaseKind"] = df["ShopBaseKind"].fillna("")
    df["Package_Kind"] = df["Package_Kind"].fillna("")
    
    # ì¡°ê±´ë¶€ ê°€ê³µ
    df["Package_Kind"] = df.apply(
        lambda x: f"{x['ShopBaseKind']}_{x['Package_Kind']}" if x['ShopBaseKind'] and x['Package_Kind'] else x['Package_Kind'], 
        axis=1
    )
    print("ì¡°ê±´ë¶€ ê°€ê³µ í›„ ë°ì´í„° í™•ì¸")
    print(df[["ShopBaseKind", "Package_Kind"]].head(5))
    
    # ë¶ˆí•„ìš” í–‰ ì œê±° ë° ì»¬ëŸ¼ ì‚­ì œ
    df = df[df['Package_Kind'] != '']
    df = df.drop(columns=['ShopBaseKind'])

    return df

def RESU_truncate_and_insert_to_bigquery(project_id, dataset_id, table_id):

    df = RESU_extract_notion_data(NOTION_TOKEN=NOTION_TOKEN, NOTION_DATABASE_ID=NOTION_DATABASE_ID)
    credentials = get_gcp_credentials()
    client = bigquery.Client(project=project_id, credentials=credentials)
    table_full_id = f"{project_id}.{dataset_id}.{table_id}"

    # 1. ë°ì´í„° ë¹„ìš°ê¸° (í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ/ì„¤ì • ìœ ì§€)
    truncate_query = f"TRUNCATE TABLE `{table_full_id}`"
    client.query(truncate_query, location=LOCATION).result()
    print(f"ğŸ—‘ï¸ {table_full_id} ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° íƒ€ì… í´ë¦¬ë‹ (Parquet ë³€í™˜ ì—ëŸ¬ ë°©ì§€)
    df_final = df.astype(str)

    to_float_list = ['Price']
    for cl in to_float_list:
        df_final[cl] = df_final[cl].str.replace(r'[â‚©,]', '', regex=True)
        df_final[cl] = pd.to_numeric(df_final[cl], errors='coerce')
        df_final[cl] = df_final[cl].fillna(0).astype(float)

    date_columns = ['Start_Date', 'End_Date']
    
    for col in date_columns:
        if col in df_final.columns:
            # 1. ë¨¼ì € datetime ê°ì²´ë¡œ ë³€í™˜ (ë³€í™˜í•  ìˆ˜ ì—†ëŠ” ê°’ì€ NaTë¡œ ê°•ì œ ë³€í™˜)
            df_final[col] = pd.to_datetime(df_final[col], errors='coerce')
            
            # 2. 'YYYY-MM-DD' í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì‹œê°„ ì •ë³´ ì œê±°)
            # dt.strftimeì„ ì“°ë©´ NaTëŠ” NaNì´ ë©ë‹ˆë‹¤.
            df_final[col] = df_final[col].dt.strftime('%Y-%m-%d')
            
            # 3. ê²°ì¸¡ì¹˜(NaN) ì²˜ë¦¬
            # BigQuery DATE ì»¬ëŸ¼ì— NULLë¡œ ë„£ê¸° ìœ„í•´ Noneìœ¼ë¡œ ì¹˜í™˜
            # (ì£¼ì˜: ë‚ ì§œ ì»¬ëŸ¼ì€ 0ì´ë‚˜ ë¹ˆ ë¬¸ìì—´ ''ë¡œ ì±„ìš°ë©´ ì—…ë¡œë“œ ì‹œ ì—ëŸ¬ê°€ ë‚©ë‹ˆë‹¤)
            df_final[col] = df_final[col].replace({float('nan'): None})
            df_final[col] = df_final[col].replace({'': None})
    
    # 3. ë°ì´í„° ì‚½ì…
    try:
        # TRUNCATEë¥¼ ë¯¸ë¦¬ í–ˆìœ¼ë¯€ë¡œ 'append'ë¥¼ ì¨ì•¼ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ/íŒŒí‹°ì…˜ ì„¤ì •ì´ ìœ ì§€ë©ë‹ˆë‹¤.
        # df.to_gbq ëŒ€ì‹  pandas_gbq.to_gbq ì‚¬ìš© ê¶Œì¥
        pandas_gbq.to_gbq(
            df_final,
            destination_table=f"{dataset_id}.{table_id}",
            project_id=project_id,
            if_exists='append', 
            progress_bar=True,
            credentials=credentials
        )
        print(f"âœ… {len(df_final)}í–‰ ë°ì´í„°ê°€ {table_full_id}ì— ì„±ê³µì ìœ¼ë¡œ Insert ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ BigQuery ì—…ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        raise e # ì—ëŸ¬ ì¶”ì ì„ ìœ„í•´ raise ì¶”ê°€


# DAG ê¸°ë³¸ ì„¤ì •
default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': timedelta(seconds=15),
}

with DAG(
    dag_id='Package_Info_ETL',
    default_args=default_args,
    description='Package Info ETL',
    schedule='00 19 * * *',  # ë§¤ì¼ ì˜¤ì „ 04ì‹œ 50ë¶„ ì‹¤í–‰
    start_date=datetime(2025, 1, 1),
    catchup=False,
    tags=['ETL', 'package_info', 'bigquery'],
) as dag:

    GBTW_package_info_task = PythonOperator(
        task_id='GBTW_package_info_task',
        python_callable=GBTW_truncate_and_insert_to_bigquery,
        op_kwargs={
            "project_id": "data-science-division-216308",
            "dataset_id": "PackageInfo",
            "table_id": "PackageInfo_GBTW"
        },
        dag=dag,
    )

    POTC_package_info_task = PythonOperator(
        task_id='POTC_package_info_task',
        python_callable=POTC_truncate_and_insert_to_bigquery,
        op_kwargs={
            "project_id": "data-science-division-216308",
            "dataset_id": "PackageInfo",
            "table_id": "PackageInfo_POTC"
        },
        dag=dag,
    )

    DRSG_package_info_task = PythonOperator(
        task_id='DRSG_package_info_task',
        python_callable=DRSG_truncate_and_insert_to_bigquery,
        op_kwargs={
            "project_id": "data-science-division-216308",
            "dataset_id": "PackageInfo",
            "table_id": "PackageInfo_DS"
        },
        dag=dag,
    )

    WWMC_package_info_task = PythonOperator(
        task_id='WWMC_package_info_task',
        python_callable=WWMC_truncate_and_insert_to_bigquery,
        op_kwargs={
            "project_id": "data-science-division-216308",
            "dataset_id": "PackageInfo",
            "table_id": "PackageInfo_WWM"
        },
        dag=dag,
    )

    RESU_package_info_task = PythonOperator(
        task_id='RESU_package_info_task',
        python_callable=RESU_truncate_and_insert_to_bigquery,
        op_kwargs={
            "project_id": "data-science-division-216308",
            "dataset_id": "PackageInfo",
            "table_id": "PackageInfo_Notion_RESU"
        },
        dag=dag,
    )

    GBTW_package_info_task >> POTC_package_info_task >> DRSG_package_info_task >> WWMC_package_info_task >> RESU_package_info_task